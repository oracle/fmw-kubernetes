[
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/prepare-oke-environment/",
	"title": "Preparing an OKE environment",
	"tags": [],
	"description": "Running WebLogic Kubernetes Operator managed WebCenter Content domain on Oracle Kubernetes Engine (OKE).",
	"content": "Contents  Create Public SSH Key to access all the Bastion and Worker nodes Create a compartment for OKE Create Container Clusters (OKE) Create Bastion Node to access Cluster Setup OCI CLI to download kubeconfig and access OKE Cluster  Create Public SSH Key to access all the Bastion and Worker nodes Create SSH key using ssh-keygen on linux terminal to access (ssh) the Compute instances (worker/bastion) in OCI.\nssh-keygen -t rsa -N \u0026#34;\u0026#34; -b 2048 -C demokey -f id_rsa Create a compartment for OKE Within your tenancy, there must be a compartment to contain the necessary network resources (VCN, subnets, internet gateway, route table, security lists).\n Go to OCI console, and use the top-left Menu to select the Identity \u0026gt; Compartments option. Click the Create Compartment button. Enter the compartment name(For example, WCCStorage) and description(OKE compartment), the click the Create Compartment button.  Create Container Clusters (OKE)  In the Console, open the navigation menu. Go to Developer Services and click Kubernetes Clusters (OKE).  Choose a Compartment you have permission to work in. Here we will use WCCStorage compartment. On the Cluster List page, select your Compartment and click Create Cluster. In the Create Cluster dialog, select Quick Create and click Launch Workflow.  On the Create Cluster page specify the values as per your environment (like the sample values shown below)  NAME: WCCOKEPHASE1 COMPARTMENT: WCCStorage KUBERNETES VERSION: v1.18.10 CHOOSE VISIBILITY TYPE: Private SHAPE: VM.Standard.E3.Flex (Choose the available shape for worker node pool. The list shows only those shapes available in your tenancy that are supported by Container Engine for Kubernetes. See Supported Images and Shapes for Worker Nodes.) NUMBER OF NODES: 3 (The number of worker nodes to create in the node pool, placed in the regional subnet created for the \u0026lsquo;quick cluster\u0026rsquo;). Click Show Advanced Options and enter PUBLIC SSK KEY: ssh-rsa AA\u0026hellip;\u0026hellip;bmVnWgX/ demokey (The public key id_rsa.pub created at Step1)    Click Next to review the details you entered for the new cluster.\n Click Create Cluster to create the new network resources and the new cluster.  Container Engine for Kubernetes starts creating resources (as shown in the Creating cluster and associated network resources dialog). Click Close to return to the Console.  Initially, the new cluster appears in the Console with a status of Creating. When the cluster has been created, it has a status of Active.  Click on the Node Pools on Resources and then View to view the Node Pool and worker node status  You can view the status of Worker node and make sure all Node State in Active and Kubernetes Node Condition is Ready.The worker node gets listed in the kubectl command once the Kubernetes Node Condition is Ready.  To access the Cluster, Click on Access Cluster on the Cluster WCCOKEPHASE1 page.  We will be creating the bastion node and then access the Cluster.  Create Bastion Node to access Cluster Setup a bastion node for accessing internal resources. We will create the bastion node in same VCN following below steps, so that we can ssh into worker nodes. Here we will choose CIDR Block: 10.0.22.0/24 . You can choose a different block, if you want.\n  Click on the VCN Name from the Cluster Page as shown below   Next Click on Security List and then Create Security List   Create a bastion-private-sec-list security with below Ingress and Egress Rules.\nIngress Rules:\nEgress Rules:   Create a bastion-public-sec-list security with below Ingress and Egress Rules.\nIngress Rules:\nEgress Rules:   Create the bastion-route-table with Internet Gateway, so that we can add to bastion instance for internet access   Next create a Regional Public Subnet for bastion instance with name bastion-subnet with below details:\n CIDR BLOCK: 10.0.22.0/24 ROUTE TABLE: oke-bastion-routetables SUBNET ACCESS: PUBLIC SUBNET Security List: bastion-public-sec-list DHCP OPTIONS: Select the Default DHCP Options     Next Click on the Private Subnet which has Worker Nodes   And then add the bastion-private-sec-list to Worker Private Subnet, so that bastion instance can access the Worker nodes   Next Create Compute Instance oke-bastion with below details\n Name: BastionHost Image: Oracle Linux 7.X Availability Domain: Choose any AD which has limit for creating Instance VIRTUAL CLOUD NETWORK COMPARTMENT: WCCStorage( i.e., OKE Compartment) SELECT A VIRTUAL CLOUD NETWORK: Select VCN created by Quick Cluster SUBNET COMPARTMENT: WCCStorage ( i.e., OKE Compartment) SUBNET: bastion-subnet (create above) SELECT ASSIGN A PUBLIC IP ADDRESS SSH KEYS: Copy content of id_rsa.pub created in Step1     Once bastion Instance BastionHost is created, get the Public IP to ssh into the bastion instance   Login to bastion host as below\nssh -i \u0026lt;your_ssh_bastion.key\u0026gt; opc@123.456.xxx.xxx   Setup OCI CLI  Install OCI CLI bash -c \u0026#34;$(curl -L https://raw.githubusercontent.com/oracle/oci-cli/master/scripts/install/install.sh)\u0026#34;  Respond to the Installation Script Prompts. To download the kubeconfig later after setup, we need to setup the oci config file. Follow the below command and enter the details when prompted $ oci setup config    Click here to see the Sample Output   $ oci setup config This command provides a walkthrough of creating a valid CLI config file. The following links explain where to find the information required by this script: User API Signing Key, OCID and Tenancy OCID: https://docs.cloud.oracle.com/Content/API/Concepts/apisigningkey.htm#Other Region: https://docs.cloud.oracle.com/Content/General/Concepts/regions.htm General config documentation: https://docs.cloud.oracle.com/Content/API/Concepts/sdkconfig.htm Enter a location for your config [/home/opc/.oci/config]: Enter a user OCID: ocid1.user.oc1..aaaaaaaao3qji52eu4ulgqvg3k4yf7xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Enter a tenancy OCID: ocid1.tenancy.oc1..aaaaaaaaf33wodv3uhljnn5etiuafoxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Enter a region (e.g. ap-hyderabad-1, ap-melbourne-1, ap-mumbai-1, ap-osaka-1, ap-seoul-1, ap-sydney-1, ap-tokyo-1, ca-montreal-1, ca-toronto-1, eu-amsterdam-1, eu-frankfurt-1, eu-zurich-1, me-jeddah-1, sa-saopaulo-1, uk-gov-london-1, uk-london-1, us-ashburn-1, us-gov-ashburn-1, us-gov-chicago-1, us-gov-phoenix-1, us-langley-1, us-luke-1, us-phoenix-1): us-phoenix-1 Do you want to generate a new API Signing RSA key pair? (If you decline you will be asked to supply the path to an existing key.) [Y/n]: Y Enter a directory for your keys to be created [/home/opc/.oci]: Enter a name for your key [oci_api_key]: Public key written to: /home/opc/.oci/oci_api_key_public.pem Enter a passphrase for your private key (empty for no passphrase): Private key written to: /home/opc/.oci/oci_api_key.pem Fingerprint: 74:d2:f2:db:62:a9:c4:bd:9b:4f:6c:d8:31:1d:a1:d8 Config written to /home/opc/.oci/config If you haven't already uploaded your API Signing public key through the console, follow the instructions on the page linked below in the section 'How to upload the public key': https://docs.cloud.oracle.com/Content/API/Concepts/apisigningkey.htm#How2     Now you need to upload the created public key in $HOME/.oci (oci_api_key_public.pem) to OCI console Login to OCI Console and navigate to User Settings, which is in the drop down under your OCI userprofile, located at the top-right corner of the page.  On User Details page, Click Api Keys link, located near bottom-left corner of the page and then Click the Add API Key button. Copy the content of oci_api_key_public.pem and Click Add.  Now you can use the oci cli to access the OCI resources. To access the Cluster, Click on Access Cluster on the Cluster WCCOKEPHASE1 page  To access the Cluster from Bastion node perform steps as per the Local Access. $ oci -v $ mkdir -p $HOME/.kube $ oci ce cluster create-kubeconfig --cluster-id ocid1.cluster.oc1.phx.aaaaaaaaae4xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxrqgjtd --file $HOME/.kube/config --region us-phoenix-1 --token-version 2.0.0 $ export KUBECONFIG=$HOME/.kube/config  Install kubectl Client to access the Cluster $ curl -LO https://dl.k8s.io/release/v1.15.7/bin/linux/amd64/kubectl $ sudo mv kubectl /bin/ $ sudo chmod +x /bin/kubectl  Access the Cluster from bastion node $ kubectl get nodes NAME STATUS ROLES AGE VERSION 10.0.10.197 Ready node 14d v1.18.10 10.0.10.206 Ready node 14d v1.18.10 10.0.10.50 Ready node 14d v1.18.10  Install required add-ons for Oracle WebCenter Content Cluster setup  Install helm v3 $ wget https://get.helm.sh/helm-v3.1.1-linux-amd64.tar.gz $ tar -zxvf helm-v3.1.1-linux-amd64.tar.gz $ sudo mv linux-amd64/helm /bin/helm $ helm version version.BuildInfo{Version:\u0026#34;v3.1.1\u0026#34;, GitCommit:\u0026#34;afe70585407b420d0097d07b21c47dc511525ac8\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, GoVersion:\u0026#34;go1.13.8\u0026#34;}  Install git sudo yum install git -y     "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/appendix/wcc-cluster-sizing-info/",
	"title": "Domain resource sizing",
	"tags": [],
	"description": "Describes the resourse sizing information for Oracle WebCenter Content domain setup on Kubernetes cluster.",
	"content": "Oracle WebCenter Content cluster sizing recommendations    Oracle WCC Normal Usage Moderate Usage High Usage     Administration Server No of CPU core(s) : 1, Memory : 4GB No of CPU core(s) : 1, Memory : 4GB No of CPU core(s) : 1, Memory : 4GB   Number of Managed Servers 2 3 5   Configurations per Managed Server No of CPU core(s) : 2, Memory : 16GB No of CPU core(s) : 4, Memory : 16GB No of CPU core(s) : 6, Memory : 16-32GB   PV Storage Minimum 250GB Minimum 250GB Minimum 500GB    "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/configure-load-balancer/",
	"title": "Set up a load balancer",
	"tags": [],
	"description": "Configure different load balancers for Oracle WebCenter Content domains.",
	"content": "WebLogic Kubernetes Operator supports ingress-based load balancers such as Traefik and NGINX (kubernetes/ingress-nginx). It also supports Apache webtier load balancer.\n Traefik  Configure the ingress-based Traefik load balancer for Oracle WebCenter Content domains.\n NGINX  Configure the ingress-based NGINX load balancer for Oracle WebCenter Content domain.\n Apache webtier  Configure the Apache webtier load balancer for Oracle WebCenter Content domain.\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/filesystem/",
	"title": "Preparing a file system",
	"tags": [],
	"description": "Running WebLogic Kubernetes Operator managed Oracle WebCenter Content domains on OKE",
	"content": "Create Filesystem and security list for FSS  Note: Make sure you create the filesystem and security list in the OKE created VCN\n   Login to OCI Console and go to Storage and Click File System   Click Create File System   You can create File System and Mount Targets with the default values. But in case you want to rename the file System and mount targets, follow below steps.\n Note: Make sure the Virtual Cloud Network in Mount Target refers to the one where your OKE Cluster is created and you will be accessing this file system.\n   Edit and change the File System name. You can choose any name of your choice. Following instructions will assume that the File System name chosen is WCCFS.   Edit and change the Mount Target name to WCCFS and make sure the Virtual Cloud Network selected is the one where all the instances are created. Select Public Subnet and Click Create   Once the File System is created, it lands at below page. Click on WCCFS link.   Click on Mount Commands which gives details on how to mount this file system on your instances.   Mount Command pop up gives details on what must be configured on security list to access the mount targets from instances. Note down the mount command which need to be executed on the instance   Note down the mount path and NFS server from the COMMAND TO MOUNT THE FILE SYSTEM. We will use this as NFS for Domain Home with below details. Sample from the above mount command.\n NFSServer: 10.0.20.xxx Mount Path: /WCCFS    Create the security list fss_seclist with below Ingress Rules as given in the Mount commands pop up   Create the Egress rules as below as given in the Mount commands pop up.   Make sure to add the created security list fss_security list to each subnets as shown below: Otherwise the created security list rules will not apply to the instances.   Once the security list fss_security list is added into the subnet, login to the instances and mount the file systems on to Bastion Node.\n Note: Please make sure to replace the sample NFS server address (10.0.20.235, as shown in the example below) according to your environment.\n # Run below command in same order(sequence) as a root user. # login as root sudo su # Install NFS Utils yum install nfs-utils # Create directory where you want the mount the file system sudo mkdir -p /mnt/WCCFS # Mount Command sudo mount 10.0.20.235:/WCCFS /mnt/WCCFS # Alternatively you can use: \u0026quot;mount 10.0.20.235:/WCCFS /mnt/WCCFS\u0026quot;. To persist on reboot add into /etc/fstab echo \u0026quot;10.0.20.235:/WCCFS /mnt/WCCFS nfs nfsvers=3 0 0\u0026quot; \u0026gt;\u0026gt; /etc/fstab mount -a # Change proper permissions so that all users can access the share volume sudo chown -R 1000:0 /mnt/WCCFS   Confirm that /WCCFS is now pointing to created File System\n[root@bastionhost WCCFS]# cd /mnt/WCCFS/ [root@bastionhost WCCFS]# df -h . Filesystem Size Used Avail Use% Mounted on 10.0.20.235:/WCCFS 8.0E 0 8.0E 0% /mnt/WCCFS   "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/ocir/",
	"title": "Preparing OCIR",
	"tags": [],
	"description": "Running WebLogic Kubernetes Operator managed Oracle WebCenter Content domains on OKE",
	"content": "Publish images to OCIR Push all the required images to OCIR and subsequently use from there. Follow the below steps for pushing the images to OCIR\nCreate an \u0026ldquo;Auth token\u0026rdquo; Create an \u0026ldquo;Auth token\u0026rdquo; which will be used as docker password to push and pull images from OCIR. Login to OCI Console and navigate to User Settings, which is in the drop down under your OCI user-profile, located at the top-right corner of the OCI console page.  On User Details page, Click Auth Tokens link located near bottom-left corner of the page and then Click the Generate Token button: Enter a Name and Click \u0026ldquo;Generate Token\u0026rdquo;  Token will get generated  Copy the generated token.  NOTE: It will only be displayed this one time, and you will need to copy it to a secure place for further use.\n   Using the OCIR Using the Docker CLI to login to OCIR ( for phoenix : phx.ocir.io , ashburn: iad.ocir.io etc)\n docker login phx.ocir.io When promoted for username enter docker username as OCIR RepoName/oci username ( eg., axcmmdmzqtqb/oracleidentitycloudservice/myemailid@oracle.com) When prompted for your password, enter the generated Auth Token Now you can tag the WCC Docker image and push to OCIR. Sample steps as below  $ docker login phx.ocir.io $ username - axcmmdmzqtqb/oracleidentitycloudservice/myemailid@oracle.com $ password - abCXYz942,vcde (Token Generated for OCIR using user setting) $ docker tag oracle/wccontent:12.2.1.4.0-20210311104247 phx.ocir.io/axcmmdmzqtqb/oracle/wccontent:12.2.1.4.0-20210311104247 $ docker push phx.ocir.io/axcmmdmzqtqb/oracle/wccontent:12.2.1.4.0-20210311104247 This has to be done on Bastion Node for all the images.\nVerify the OCIR Images Get the OCIR repository name by logging in to Oracle Cloud Infrastructure Console. In the OCI Console, open the Navigation menu. Under Solutions and Platform, go to Developer Services and click Container Registry (OCIR) and select the your Compartment.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/",
	"title": "Oracle Fusion Middleware on Kubernetes",
	"tags": [],
	"description": "This document lists all the Oracle Fusion Middleware products deployment supported on Kubernetes.",
	"content": "Oracle Fusion Middleware on Kubernetes Oracle supports the deployment of the following Oracle Fusion Middleware products on Kubernetes. Click on the appropriate document link below to get started on setting up the product.\n Oracle WebCenter Content  WebLogic Kubernetes Operator (the “operator”) supports deployment of Oracle WebCenter Content servers such as Oracle WebCenter Content(Content Server) and Oracle WebCenter Content(Inbound Refinery Server). Follow the instructions in this guide to set up Oracle WebCenter Content domain on Kubernetes.\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/patch_and_upgrade/patch-an-image/",
	"title": "Patch an image",
	"tags": [],
	"description": "Create a patched Oracle WebCenter Content image using the WebLogic Image Tool.",
	"content": "Oracle aims to release Oracle WebCenter Content images regularly with latest bundle and recommended interim patches in My Oracle Support (MOS). However, if there is a need to create images with new bundle and interim patches, you can build these images using WebLogic Image Tool.\nIf you have access to the Oracle WebCenter Content patches, you can patch an existing Oracle WebCenter Content image with a bundle patch and interim patches. It is recommended to use the WebLogic Image Tool to patch the Oracle WebCenter Content image.\n Recommendations:\n Use the WebLogic Image Tool create feature for patching the Oracle WebCenter Content Docker image with a bundle patch and multiple interim patches. This is the recommended approach because it optimizes the size of the image. Use the WebLogic Image Tool update feature for patching the Oracle WebCenter Content Docker image with a single interim patch. Note that the patched image size may increase considerably due to additional image layers introduced by the patch application tool.   Apply the patched image   Update the image: field in domain.yaml configuration file with the patched image.\n  Apply the updated domain.yaml configuration file:\n$ kubectl apply -f domain.yaml    Note: The server pods will be automatically restarted (rolling restart).\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/release-notes/",
	"title": "Release Notes",
	"tags": [],
	"description": "",
	"content": "Review the latest changes for Oracle WebCenter Content on Kubernetes.\nRecent changes    Date Version Change     March 11, 2022 22.1.3 Supports Oracle WebCenter Content 12.2.1.4 domains deployment using January 2022 PSU and known bug fixes - certified for Oracle WebLogic Kubernetes Operator version 3.3.0. Oracle WebCenter Content 12.2.1.4 container image for this release can be downloaded from My Oracle Support (MOS patch 33771196).   December 7, 2021 21.4.3 Supports Oracle WebCenter Content 12.2.1.4 domains deployment using April 2021 PSU and known bug fixes - certified for Oracle WebLogic Kubernetes Operator version 3.2.5. Oracle WebCenter Content 12.2.1.4 container image for this release can be downloaded from My Oracle Support (MOS patch 32822360).   June 16, 2021 21.2.3 Supports Oracle WebCenter Content 12.2.1.4 domains deployment using April 2021 PSU and known bug fixes. Oracle WebCenter Content 12.2.1.4 container image for this release can be downloaded from My Oracle Support (MOS patch 32822360).   February 28, 2021 21.1.2 Certified Oracle WebLogic Kubernetes Operator version 3.1.1. Kubernetes 1.14.8+, 1.15.7+, 1.16.0+, 1.17.0+, and 1.18.0+ support. Flannel is the only supported CNI in this release. SSL enabling for the Administration Server and Managed Servers is supported. For now, only Oracle WebCenter Content 12.2.1.4 is supported.    "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/installguide/prerequisites/",
	"title": "Requirements and limitations",
	"tags": [],
	"description": "Understand the system requirements and limitations for deploying and running Oracle WebCenter Content with the WebLogic Kubernetes Operator, including the Oracle WebCenter Content cluster sizing recommendations.",
	"content": "This section provides information about the system requirements and limitations for deploying and running Oracle WebCenter Content domains with the WebLogic Kubernetes Operator.\nSystem requirements for Oracle WebCenter Content domains For the current production release 22.1.3:\n Oracle Linux 7 (UL6+) and Red Hat Enterprise Linux 7 (UL3+ only with standalone Kubernetes) are supported. Supported Kubernetes versions are: 1.16.15+, 1.17.13+ and 1.18.10+ (check with kubectl version). Docker 18.09.1ce, 19.03.1 (check with docker version) or CRI-O 1.14.7 (check with crictl version | grep RuntimeVersion). Flannel networking v0.12.0-amd64 or later (check with docker images | grep flannel). Helm 3.4.1 (check with helm version --client --short). Oracle WebLogic Kubernetes Operator 3.3.0 (see WebLogic Kubernetes Operator releases page). Oracle WebCenter Content 12.2.1.4 Docker image downloaded from My Oracle Support (MOS patch 33771196). This image contains the latest bundle patch and one-off patches for Oracle WebCenter Content. You must have the cluster-admin role to install WebLogic Kubernetes Operator. The WebLogic Kubernetes Operator does not need the cluster-admin role at runtime. We do not currently support running Oracle WebCenter Content in non-Linux containers. Additionally, see the Oracle WebCenter Content documentation for other requirements such as database version.  See here for resourse sizing information for Oracle WebCenter Content domains setup on Kubernetes cluster.\nLimitations Compared to running a WebLogic Server domain in Kubernetes using the WebLogic Kubernetes Operator, the following limitations currently exist for Oracle WebCenter Content domains:\n In this release, Oracle WebCenter Content domains are supported using the domain on a persistent volume model only, where the domain home is located in a persistent volume (PV). The \u0026ldquo;domain in image\u0026rdquo; and \u0026ldquo;model in image\u0026rdquo; models are not supported. Also, \u0026ldquo;WebLogic Deploy Tooling (WDT)\u0026rdquo; based deployments are currently not supported. Only configured clusters are supported. Dynamic clusters are not supported for Oracle WebCenter Content domains. Note that you can still use all of the scaling features, but you need to define the maximum size of your cluster at domain creation time. Mixed clusters (configured servers targeted to a dynamic cluster) are not supported. The WebLogic Logging Exporter currently supports WebLogic Server logs only. Other logs will not be sent to Elasticsearch. Note, however, that you can use a sidecar with a log handling tool like Logstash or Fluentd to get logs. The WebLogic Monitoring Exporter currently supports WebLogic MBean trees only. Support for JRF and Oracle WebCenter Content MBeans is not available. Also, a metrics dashboard specific to Oracle WebCenter Content is not available. Instead, use the WebLogic Server dashboard to monitor the Oracle WebCenter Content server metrics in Grafana. Some features such as multicast, multitenancy, production redeployment, and Node Manager (although it is used internally for the liveness probe and to start WebLogic Server instances) are not supported in this release. Features such as Java Messaging Service whole server migration, consensus leasing, and maximum availability architecture (Oracle WebCenter Content setup) are not supported in this release. You can have multiple UCM servers on your domain but you can have only one IBR server. There is a generic limitation with all load-balancers in end-to-end SSL configuration - accessing multiple types of servers (different Managed Servers and/or Administration Server) at the same time, is currently not supported.  For up-to-date information about the features of WebLogic Server that are supported in Kubernetes environments, see My Oracle Support Doc ID 2349228.1.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/configure-load-balancer/traefik/",
	"title": "Traefik",
	"tags": [],
	"description": "Configure the ingress-based Traefik load balancer for Oracle WebCenter Content domains.",
	"content": "This section provides information about how to install and configure the ingress-based Traefik load balancer (version 2.2.1 or later for production deployments) to load balance Oracle WebCenter Content domain clusters. You can configure Traefik for non-SSL, SSL termination and end-to-end SSL access of the application URL.\nFollow these steps to set up Traefik as a load balancer for an Oracle WebCenter Content\tdomain in a Kubernetes cluster:\n  Non-SSL and SSL termination\n Install the Traefik (ingress-based) load balancer Configure Traefik to manage ingresses Create an Ingress for the domain Verify domain application URL access Uninstall the Traefik ingress    End-to-end SSL configuration\n Install the Traefik load balancer for End-to-end SSL Configure Traefik to manage domain Create IngressRouteTCP Verify end-to-end SSL access Uninstall Traefik    Non-SSL and SSL termination Install the Traefik (ingress-based) load balancer   Use Helm to install the Traefik (ingress-based) load balancer. For detailed information, see here. Use the values.yaml file in the sample but set kubernetes.namespaces specifically.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --set \u0026#34;service.type=NodePort\u0026#34; --wait    Click here to see the sample output.   NAME: traefik LAST DEPLOYED: Sun Jan 17 23:30:20 2021 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None    A sample values.yaml for deployment of Traefik 2.2.x:\nimage: name: traefik tag: 2.2.8 pullPolicy: IfNotPresent ingressRoute: dashboard: enabled: true # Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class) annotations: {} # Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels) labels: {} providers: kubernetesCRD: enabled: true kubernetesIngress: enabled: true # IP used for Kubernetes Ingress endpoints ports: traefik: port: 9000 expose: true # The exposed port for this service exposedPort: 9000 # The port protocol (TCP/UDP) protocol: TCP web: port: 8000 # hostPort: 8000 expose: true exposedPort: 30305 nodePort: 30305 # The port protocol (TCP/UDP) protocol: TCP # Use nodeport if set. This is useful if you have configured Traefik in a # LoadBalancer # nodePort: 32080 # Port Redirections # Added in 2.2, you can make permanent redirects via entrypoints. # https://docs.traefik.io/routing/entrypoints/#redirection # redirectTo: websecure websecure: port: 8443 # # hostPort: 8443 expose: true exposedPort: 30443 # The port protocol (TCP/UDP) protocol: TCP nodePort: 30443   Verify the Traefik status and find the port number of the SSL and non-SSL services:\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-f9cf58697-p57nt 1/1 Running 0 22d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik NodePort 10.96.95.253 \u0026lt;none\u0026gt; 9000:32306/TCP,30305:30305/TCP,30443:30443/TCP 22d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 22d NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-f9cf58697 1 1 1 22d      Access the Traefik dashboard through the URL http://$(hostname -f):32306, with the HTTP host traefik.example.com:\n$ curl -H \u0026#34;host: $(hostname -f)\u0026#34; http://$(hostname -f):32306/dashboard/  Note: Make sure that you specify a fully qualified node name for $(hostname -f)\n   Configure Traefik to manage ingresses Configure Traefik to manage ingresses created in this namespace, where traefik is the Traefik namespace and wccns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik --namespace traefik --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik,wccns}\u0026#34;    Click here to see the sample output.   Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Sun Jan 17 23:43:02 2021 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create an ingress for the domain Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK , tls is Non-SSL, and domainType is wccinfra. These values can be overridden by passing values through the command line or can be edited in the sample file values.yaml based on the type of configuration (non-SSL or SSL). If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. The template YAML file for the Traefik (ingress-based) load balancer is located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/traefik-ingress.yaml\n  Install ingress-per-domain using Helm for non-SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --set type=TRAEFIK \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=$(hostname -f)\u0026#34; --set tls=NONSSL Sample output:\nNAME: wcc-traefik-ingress LAST DEPLOYED: Sun Jan 17 23:49:09 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate a Kubernetes secret:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Create Traefik Middleware custom resource\nIn case of SSL termination, Traefik must pass a custom header WL-Proxy-SSL:true to the WebLogic Server endpoints. Create the Middleware using the following command:\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: wls-proxy-ssl namespace: wccns spec: headers: customRequestHeaders: WL-Proxy-SSL: \u0026#34;true\u0026#34; EOF   Create the Traefik TLSStore custom resource.\nIn case of SSL termination, Traefik should be configured to use the user-defined SSL certificate. If the user-defined SSL certificate is not configured, Traefik will create a default SSL certificate. To configure a user-defined SSL certificate for Traefik, use the TLSStore custom resource. The Kubernetes secret created with the SSL certificate should be referenced in the TLSStore object. Run the following command to create the TLSStore:\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: TLSStore metadata: name: default namespace: wccns spec: defaultCertificate: secretName: domain1-tls-cert EOF   Install ingress-per-domain using Helm for SSL configuration.\nThe Kubernetes secret name should be updated in the template file.\nThe template file also contains the following annotations:\ntraefik.ingress.kubernetes.io/router.entrypoints: websecure traefik.ingress.kubernetes.io/router.tls: \u0026#34;true\u0026#34; traefik.ingress.kubernetes.io/router.middlewares: wccns-wls-proxy-ssl@kubernetescrd The entry point for SSL access and the Middleware name should be updated in the annotation. The Middleware name should be in the form \u0026lt;namespace\u0026gt;-\u0026lt;middleware name\u0026gt;@kubernetescrd.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --set type=TRAEFIK \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=$(hostname -f)\u0026#34; \\  --set tls=SSL Sample output:\nNAME: wcc-traefik-ingress LAST DEPLOYED: Mon Jul 20 11:44:13 2020 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For non-SSL access to the Oracle WebCenter Content application, get the details of the services by the ingress:\n$ kubectl describe ingress wccinfra-traefik -n wccns     Click here to see all services supported by the above deployed ingress.    Name: wccinfra-traefik Namespace: wccns Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- domain1.org /console wccinfra-adminserver:7001 (10.244.0.201:7001) /em wccinfra-adminserver:7001 (10.244.0.201:7001) /wls-exporter wccinfra-adminserver:7001 (10.244.0.201:7001) /cs wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /adfAuthentication wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /_ocsh wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /_dav wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /idcws wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /idcnativews wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /wsm-pm wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /ibr wccinfra-cluster-ibr-cluster:16250 (10.244.0.203:16250) /ibr/adfAuthentication wccinfra-cluster-ibr-cluster:16250 (10.244.0.203:16250) /weblogic/ready wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /imaging wccinfra-cluster-ipm-cluster:16000 (10.244.0.206:16000,10.244.0.209:16000,10.244.0.213:16000) /dc-console wccinfra-cluster-capture-cluster:16400 (10.244.0.204:16400,10.244.0.208:16400,10.244.0.212:16400) /dc-client wccinfra-cluster-capture-cluster:16400 (10.244.0.204:16400,10.244.0.208:16400,10.244.0.212:16400) /wcc wccinfra-cluster-wccadf-cluster:16225 (10.244.0.205:16225,10.244.0.210:16225,10.244.0.214:16225) Annotations: kubernetes.io/ingress.class: traefik meta.helm.sh/release-name: wcc-traefik-ingress meta.helm.sh/release-namespace: wccns Events: \u0026lt;none\u0026gt;      For SSL access to the Oracle WebCenter Content application, get the details of the services by the above deployed ingress:\n$ kubectl describe ingress wccinfra-traefik -n wccns     Click here to see all services supported by the above deployed ingress.    Name: wccinfra-traefik Namespace: wccns Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- domain1.org /console wccinfra-adminserver:7001 (10.244.0.201:7001) /em wccinfra-adminserver:7001 (10.244.0.201:7001) /wls-exporter wccinfra-adminserver:7001 (10.244.0.201:7001) /cs wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /adfAuthentication wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /_ocsh wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /_dav wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /idcws wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /idcnativews wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /wsm-pm wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /ibr wccinfra-cluster-ibr-cluster:16250 (10.244.0.203:16250) /ibr/adfAuthentication wccinfra-cluster-ibr-cluster:16250 (10.244.0.203:16250) /weblogic/ready wccinfra-cluster-ucm-cluster:16200 (10.244.0.202:16200,10.244.0.207:16200,10.244.0.211:16200) /imaging wccinfra-cluster-ipm-cluster:16000 (10.244.0.206:16000,10.244.0.209:16000,10.244.0.213:16000) /dc-console wccinfra-cluster-capture-cluster:16400 (10.244.0.204:16400,10.244.0.208:16400,10.244.0.212:16400) /dc-client wccinfra-cluster-capture-cluster:16400 (10.244.0.204:16400,10.244.0.208:16400,10.244.0.212:16400) /wcc wccinfra-cluster-wccadf-cluster:16225 (10.244.0.205:16225,10.244.0.210:16225,10.244.0.214:16225) Annotations: kubernetes.io/ingress.class: traefik meta.helm.sh/release-name: wcc-traefik-ingress meta.helm.sh/release-namespace: wccns Events: \u0026lt;none\u0026gt;     To confirm that the load balancer noticed the new ingress and is successfully routing to the domain server pods, you can send a request to the URL for the \u0026ldquo;WebLogic ReadyApp framework\u0026rdquo;, which should return an HTTP 200 status code, as follows: $ curl -v http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER_PORT}/weblogic/ready * About to connect() to abc.com port 30305 (#0) * Trying 100.111.156.246... * Connected to abc.com (100.111.156.246) port 30305 (#0) \u0026gt; GET /weblogic/ready HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Host: domain1.org:30305 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Content-Length: 0 \u0026lt; Date: Thu, 03 Dec 2020 13:16:19 GMT \u0026lt; Vary: Accept-Encoding \u0026lt; * Connection #0 to host abc.com left intact   Verify domain application URL access For non-SSL configuration After setting up the Traefik (ingress-based) load balancer, verify that the domain application URLs are accessible through the non-SSL load balancer port 30305 for HTTP access. The sample URLs for Oracle WebCenter Content domain of type wcc are:\nhttp://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/imaging http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/dc-console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/wcc\tFor SSL configuration After setting up the Traefik (ingress-based) load balancer, verify that the domain applications are accessible through the SSL load balancer port 30443 for HTTPS access. The sample URLs for Oracle WebCenter Content domain are:\nhttps://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/imaging https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/dc-console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/wcc Uninstall the Traefik ingress Uninstall and delete the ingress deployment:\n$ helm delete wcc-traefik-ingress -n wccns End-to-end SSL configuration Install the Traefik load balancer for end-to-end SSL   Use Helm to install the Traefik (ingress-based) load balancer. For detailed information, see here. Use the values.yaml file in the sample but set kubernetes.namespaces specifically.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --wait    Click here to see the sample output.   NAME: traefik LAST DEPLOYED: Sun Jan 17 23:30:20 2021 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None      Verify the Traefik operator status and find the port number of the SSL and non-SSL services:\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-operator-676fc64d9c-skppn 1/1 Running 0 78d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik-operator NodePort 10.109.223.59 \u0026lt;none\u0026gt; 443:30443/TCP,80:30305/TCP 78d service/traefik-operator-dashboard ClusterIP 10.110.85.194 \u0026lt;none\u0026gt; 80/TCP 78d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik-operator 1/1 1 1 78d NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-operator-676fc64d9c 1 1 1 78d replicaset.apps/traefik-operator-cb78c9dc9 0 0 0 78d      Access the Traefik dashboard through the URL http://$(hostname -f):32306, with the HTTP host traefik.example.com:\n$ curl -H \u0026#34;host: $(hostname -f)\u0026#34; http://$(hostname -f):32306/dashboard/  Note: Make sure that you specify a fully qualified node name for $(hostname -f).\n   Configure Traefik to manage the domain Configure Traefik to manage the domain application service created in this namespace, where traefik is the Traefik namespace and wccns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik --namespace traefik --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik,wccns}\u0026#34;    Click here to see the sample output.   Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Sun Jan 17 23:43:02 2021 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create IngressRouteTCP   To enable SSL passthrough in Traefik, you can configure a TCP router. A sample YAML for IngressRouteTCP is available at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls/traefik-tls.yaml. The following should be updated in traefik-tls.yaml:\n The service name and the SSL port should be updated in the Services. The load balancer hostname should be updated in the HostSNI rule.  Sample traefik-tls.yaml:\n  apiVersion: traefik.containo.us/v1alpha1 kind: IngressRouteTCP metadata: name: wcc-ucm-routetcp namespace: wccns spec: entryPoints: - websecure routes: - match: HostSNI(`${LOADBALANCER_HOSTNAME}`) services: - name: wccinfra-cluster-ucm-cluster port: 16201 weight: 3 TerminationDelay: 400 tls: passthrough: true  Create the IngressRouteTCP:  $ kubectl apply -f traefik-tls.yaml Verify end-to-end SSL access Verify the access to application URLs exposed through the configured service. You should be able to access the following Oracle WebCenter Content domain URLs:\nLOADBALANCER-SSLPORT is 30443\nhttps://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/imaging https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/dc-console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/wcc Uninstall Traefik $ helm delete traefik -n wccns "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/configure-load-balancer/traefik/",
	"title": "Traefik",
	"tags": [],
	"description": "Configure the ingress-based Traefik load balancer for Oracle WebCenter Content domains.",
	"content": "This section provides information about how to install and configure the ingress-based Traefik load balancer (version 2.2.8 or later for production deployments) to load balance Oracle WebCenter Content domain clusters.\nFollow these steps to set up Traefik as a load balancer for an Oracle WebCenter Content\tdomain in a Kubernetes cluster:\nContents  Install the Traefik (ingress-based) load balancer Configure Traefik to manage ingresses Create an Ingress for the domain Verify domain application URL access Uninstall the Traefik ingress  Install the Traefik (ingress-based) load balancer   Use Helm to install the Traefik (ingress-based) load balancer. For detailed information, see here. Use the values.yaml file in the sample but set kubernetes.namespaces specifically.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --set \u0026#34;service.type=LoadBalancer\u0026#34; --wait    Click here to see the sample output.   NAME: traefik-operator LAST DEPLOYED: Mon Jun 1 19:31:20 2020 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: 1. Get Traefik load balancer IP or hostname: NOTE: It may take a few minutes for this to become available. You can watch the status by running: $ kubectl get svc traefik-operator --namespace traefik -w Once \u0026#39;EXTERNAL-IP\u0026#39; is no longer \u0026#39;\u0026lt;pending\u0026gt;\u0026#39;: $ kubectl describe svc traefik-operator --namespace traefik | grep Ingress | awk \u0026#39;{print $3}\u0026#39; 2. Configure DNS records corresponding to Kubernetes ingress resources to point to the load balancer IP or hostname found in step 1    A sample values.yaml for deployment of Traefik 2.2.x:   Click here to see values.yaml   image: name: traefik tag: 2.2.8 pullPolicy: IfNotPresent ingressRoute: dashboard: enabled: true # Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class) annotations: {} # Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels) labels: {} providers: kubernetesCRD: enabled: true kubernetesIngress: enabled: true # IP used for Kubernetes Ingress endpoints ports: traefik: port: 9000 expose: true # The exposed port for this service exposedPort: 9000 # The port protocol (TCP/UDP) protocol: TCP web: port: 8000 # hostPort: 8000 expose: true exposedPort: 30305 nodePort: 30305 # The port protocol (TCP/UDP) protocol: TCP # Use nodeport if set. This is useful if you have configured Traefik in a # LoadBalancer # nodePort: 32080 # Port Redirections # Added in 2.2, you can make permanent redirects via entrypoints. # https://docs.traefik.io/routing/entrypoints/#redirection # redirectTo: websecure websecure: port: 8443 # # hostPort: 8443 expose: true exposedPort: 30443 # The port protocol (TCP/UDP) protocol: TCP nodePort: 30443   \n  Verify the Traefik (load balancer) services:\n  Please note the EXTERNAL-IP of the traefik-operator service. This is the public IP address of the load balancer that you will use to access the WebLogic Server Administration Console and WebCenter Content URLs.\n$ kubectl get service -n traefik NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE traefik LoadBalancer 10.96.8.30 123.456.xx.xx 9000:30734/TCP,30305:30305/TCP,30443:30443/TCP 6d23h To print only the Traefik EXTERNAL-IP, execute this command:\n$ TRAEFIK_PUBLIC_IP=`kubectl describe svc traefik --namespace traefik | grep Ingress | awk \u0026#39;{print $3}\u0026#39;` $ echo $TRAEFIK_PUBLIC_IP 123.456.xx.xx   Verify the helm charts:\n$ helm list -n traefik NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION traefik traefik 2 2021-10-11 12:22:41.122310912 +0000 UTC deployed traefik-9.1.1 2.2.8   Verify the Traefik status and find the port number\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-f9cf58697-xjhpl 1/1 Running 0 7d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik LoadBalancer 10.96.8.30 123.456.xx.xx 9000:30734/TCP,30305:30305/TCP,30443:30443/TCP 7d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 7d NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-f9cf58697 1 1 1 7d      Configure Traefik to manage ingresses Configure Traefik to manage ingresses created in this namespace, where traefik is the Traefik namespace and wccns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik --namespace traefik --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik,wccns}\u0026#34;    Click here to see the sample output.   Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Sun Jan 17 23:43:02 2021 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create an ingress for the domain Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK , tls is Non-SSL, and domainType is wccinfra. These values can be overridden by passing values through the command line or can be edited in the sample file values.yaml based on the type of configuration (non-SSL or SSL). If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. The template YAML file for the Traefik (ingress-based) load balancer is located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/traefik-ingress.yaml\n  Install ingress-per-domain using Helm for non-SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --set type=TRAEFIK \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=\u0026#34; \\  --set tls=NONSSL Sample output:\nNAME: wcc-traefik-ingress LAST DEPLOYED: Sun Jan 17 23:49:09 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   Verify domain application URL access After setting up the Traefik (ingress-based) load balancer, verify that the domain application URLs are accessible through the load balancer port 30305 for HTTP access. The sample URLs for Oracle WebCenter Content domain of type wcc are:\nhttp://${TRAEFIK_PUBLIC_IP}:30305/weblogic/ready http://${TRAEFIK_PUBLIC_IP}:30305/console http://${TRAEFIK_PUBLIC_IP}:30305/cs http://${TRAEFIK_PUBLIC_IP}:30305/ibr\tUninstall the Traefik ingress Uninstall and delete the ingress deployment:\n$ helm delete wcc-traefik-ingress -n wccns "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/installguide/",
	"title": "Install Guide",
	"tags": [],
	"description": "",
	"content": "Install the WebLogic Kubernetes Operator to prepare and deploy Oracle WebCenter Content domain.\n Requirements and limitations  Understand the system requirements and limitations for deploying and running Oracle WebCenter Content with the WebLogic Kubernetes Operator, including the Oracle WebCenter Content cluster sizing recommendations.\n Prepare your environment  Prepare for creating Oracle WebCenter Content domain, including required secrets creation, persistent volume and volume claim creation, database creation, and database schema creation.\n Create Oracle WebCenter Content domain  Create Oracle WebCenter Content domain home on an existing PV or PVC and create the domain resource YAML file for deploying the generated Oracle WebCenter Content domain.\n Launch Oracle Webcenter Content Native Applications in Containers  How to launch Oracle WebCenter Content native binaries from inside containerized environment.\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/prepare-environment-wcc-domain/",
	"title": "Prepare environment for WCC domain",
	"tags": [],
	"description": "Prepare environment for WCC domain on Oracle Kubernetes Engine (OKE).",
	"content": "To create your Oracle WebCenter Content domain in Kubernetes OKE environment, complete the following steps:\nContents   Set up the code repository to deploy Oracle WebCenter Content domain\n  Create a namespace for the Oracle WebCenter Content domain\n  Create the imagePullSecrets\n  Install the WebLogic Kubernetes Operator\n  Prepare the environment for Oracle WebCenter Content domain\na. Upgrade the WebLogic Kubernetes Operator with the Oracle WebCenter Content domain-namespace\nb. Create a persistent storage for the Oracle WebCenter Content domain\nc. Create a Kubernetes secret with domain credentials\nd. Create a Kubernetes secret with the RCU credentials\ne. Install and start the Database\nf. Configure access to your database\ng. Run the Repository Creation Utility to set up your database schemas\n  Create Oracle WebCenter Content domain\n  Set up the code repository to deploy Oracle WebCenter Content domain Oracle WebCenter Content domain deployment on Kubernetes leverages the WebLogic Kubernetes Operator infrastructure. To deploy an Oracle WebCenter Content domain, you must set up the deployment scripts.\n  Create a working directory to set up the source code:\n$ export WORKDIR=$HOME/wcc_3.3.0 $ mkdir ${WORKDIR}   Download the supported version of the WebLogic Kubernetes Operator source code from the WebLogic Kubernetes Operator github project. Currently the supported WebLogic Kubernetes Operator version is 3.3.0:\n$ cd ${WORKDIR} $ git clone https://github.com/oracle/weblogic-kubernetes-operator.git --branch v3.3.0   Download the Oracle WebCenter Content Kubernetes deployment scripts from the WCC repository and copy them to the WebLogic Kubernetes Operator samples location:\n$ git clone https://github.com/oracle/fmw-kubernetes.git $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/create-wcc-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/\t$ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/ingress-per-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/charts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/imagetool-scripts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ ``\n  Create a namespace for the Oracle WebCenter Content domain Create a Kubernetes namespace (for example, wccns) for the domain unless you intend to use the default namespace. Use the new namespace in the remaining steps in this section. For details, see Prepare to run a domain.\n $ kubectl create namespace wccns Create the imagePullSecrets Create the imagePullSecrets (in wccns namespace) so that Kubernetes Deployment can pull the image automatically from OCIR.\n Note: Create the imagePullSecret as per your environement using a sample command like this -\n $ kubectl create secret docker-registry image-secret -n wccns --docker-server=phx.ocir.io --docker-username=axxxxxxxxxxx/oracleidentitycloudservice/\u0026lt;your_user_name\u0026gt; --docker-password='vUv+xxxxxxxxxxx\u0026lt;KN7z' --docker-email=me@oracle.com The parameter values are:\nOCI Region is phoenix phx.ocir.io OCI Tenancy Name axxxxxxxxxxx ImagePullSecret Name image-secret Username and email address me@oracle.com Auth Token Password vUv+xxxxxxxxxxx\u0026lt;KN7z\nInstall the WebLogic Kubernetes Operator The WebLogic Kubernetes Operator supports the deployment of Oracle WebCenter Content domain in the Kubernetes environment.\nIn the following example commands to install the WebLogic Kubernetes Operator, opns is the namespace and op-sa is the service account created for the WebLogic Kubernetes Operator:\nCreating namespace and service account for WebLogic Kubernetes Operator $ kubectl create namespace opns $ kubectl create serviceaccount -n opns op-sa Install WebLogic Kubernetes Operator $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator --namespace opns --set image=phx.ocir.io/xxxxxxxxxxx/oracle/weblogic-kubernetes-operator:3.3.0 --set imagePullSecret=image-secret --set serviceAccount=op-sa --set \u0026quot;domainNamespaces={}\u0026quot; --set \u0026quot;javaLoggingLevel=FINE\u0026quot; --wait Verify the WebLogic Kubernetes Operator pod $ kubectl get pods -n opns NAME READY STATUS RESTARTS AGE weblogic-operator-779965b66c-d8265 1/1 Running 0 11d # Verify the Operator helm Charts $ helm list -n opns NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION weblogic-kubernetes-operator opns 3 2022-02-24 06:50:29.810106777 +0000 UTC deployed weblogic-operator-3.3.0 3.3.0 Prepare the environment for Oracle WebCenter Content domain Upgrade the WebLogic Kubernetes Operator with the Oracle WebCenter Content domain-namespace  $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade --reuse-values --namespace opns --set \u0026quot;domainNamespaces={wccns}\u0026quot; --wait weblogic-kubernetes-operator kubernetes/charts/weblogic-operator Create a persistent storage for the Oracle WebCenter Content domain In the Kubernetes namespace you created, create the PV and PVC for the domain by running the create-pv-pvc.sh script. Follow the instructions for using the script to create a dedicated PV and PVC for the Oracle WebCenter Content domain.\nHere we will use the NFS Server and mount path, created on this page.\n  Review the configuration parameters for PV creation here. Based on your requirements, update the values in the create-pv-pvc-inputs.yaml file located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc/. Sample configuration parameter values for the Oracle WebCenter Content domain are:\n baseName: domain domainUID: wccinfra namespace: wccns weblogicDomainStorageType:: NFS weblogicDomainStorageNFSServer:: \u0026lt;your_nfs_server_ip\u0026gt; weblogicDomainStoragePath: /\u0026lt;your_dir_name\u0026gt;   Note: Make sure to update the \u0026ldquo;weblogicDomainStorageNFSServer:\u0026rdquo; with the NFS Server IP as per your Environment\n   Ensure that the path for the weblogicDomainStoragePath property exists (if not, please refer subsection 4 of this document to create it first) and has correct access permissions, and that the folder is empty.\n  Run the create-pv-pvc.sh script:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ rm -rf output/ $ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output   The create-pv-pvc.sh script will create a subdirectory pv-pvcs under the given /path/to/output-directory directory and creates two YAML configuration files for PV and PVC. Apply these two YAML files to create the PV and PVC Kubernetes resources using the kubectl create -f command:\n$ kubectl create -f output/pv-pvcs/wccinfra-domain-pv.yaml -n wccns $ kubectl create -f output/pv-pvcs/wccinfra-domain-pvc.yaml -n wccns   Get the details of PV and PVC:\n$ kubectl describe pv wccinfra-domain-pv $ kubectl describe pvc wccinfra-domain-pvc -n wccns   Create a Kubernetes secret with domain credentials Create the Kubernetes secrets username and password of the administrative account in the same Kubernetes namespace as the domain:\n $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-credentials $ ./create-weblogic-credentials.sh -u weblogic -p welcome1 -n wccns -d wccinfra -s wccinfra-domain-credentials For more details, see this document.\nYou can check the secret with the kubectl get secret command.\nFor example:\n  Click here to see the sample secret description.   $ kubectl get secret wccinfra-domain-credentials -o yaml -n wccns apiVersion: v1 data: password: d2VsY29tZTE= username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: \u0026quot;2021-07-30T06:04:33Z\u0026quot; labels: weblogic.domainName: wccinfra weblogic.domainUID: wccinfra managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:password: {} f:username: {} f:metadata: f:labels: .: {} f:weblogic.domainName: {} f:weblogic.domainUID: {} f:type: {} manager: kubectl operation: Update time: \u0026quot;2021-07-30T06:04:36Z\u0026quot; name: wccinfra-domain-credentials namespace: wccns resourceVersion: \u0026quot;90770768\u0026quot; selfLink: /api/v1/namespaces/wccns/secrets/wccinfra-domain-credentials uid: 9c5dab09-15f3-4e1f-a40d-457904ddf96b type: Opaque    Create a Kubernetes secret with the RCU credentials You also need to create a Kubernetes secret containing the credentials for the database schemas. When you create your domain, it will obtain the RCU credentials from this secret.\nUse the provided sample script to create the secret:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-rcu-credentials $ ./create-rcu-credentials.sh -u weblogic -p welcome1 -a sys -q welcome1 -d wccinfra -n wccns -s wccinfra-rcu-credentials The parameter values are:\n-u username for schema owner (regular user), required.\n-p password for schema owner (regular user), required.\n-a username for SYSDBA user, required.\n-q password for SYSDBA user, required.\n-d domainUID. Example: wccinfra\n-n namespace. Example: wccns\n-s secretName. Example: wccinfra-rcu-credentials\nYou can confirm the secret was created as expected with the kubectl get secret command.\nFor example:\n  Click here to see the sample secret description.   $ kubectl get secret wccinfra-rcu-credentials -o yaml -n wccns apiVersion: v1 data: password: d2VsY29tZTE= sys_password: d2VsY29tZTE= sys_username: c3lz username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: \u0026#34;2020-09-16T08:23:04Z\u0026#34; labels: weblogic.domainName: wccinfra weblogic.domainUID: wccinfra managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:password: {} f:sys_password: {} f:sys_username: {} f:username: {} f:metadata: f:labels: .: {} f:weblogic.domainName: {} f:weblogic.domainUID: {} f:type: {} manager: kubectl operation: Update time: \u0026#34;2020-09-16T08:23:04Z\u0026#34; name: wccinfra-rcu-credentials namespace: wccns resourceVersion: \u0026#34;3277132\u0026#34; selfLink: /api/v1/namespaces/wccns/secrets/wccinfra-rcu-credentials uid: b75f4e13-84e6-40f5-84ba-0213d85bdf30 type: Opaque    Install and start the Database This step is required only when standalone database was not already setup and the user wanted to use the database in a container. The Oracle Database Docker images are supported only for non-production use. For more details, see My Oracle Support note: Oracle Support for Database Running on Docker (Doc ID 2216342.1). For production usecase it is suggested to use a standalone db. Sample provides steps to create the database in a container.\nThe database in a container can be created with a PV attached for persisting the data or without attaching the PV. In this setup we will be creating database in a container without PV attached.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-oracle-db-service $ ./start-db-service.sh -i phx.ocir.io/xxxxxxxxxxxx/oracle/database/enterprise:x.x.x.x -s image-secret -n wccns    Click here to see the Sample Output   $ ./start-db-service.sh -i phx.ocir.io/xxxxxxxxxxxx/oracle/database/enterprise:x.x.x.x -s image-secret -n wccns Checking Status for NameSpace [wccns] Skipping the NameSpace[wccns] Creation ... NodePort[30011] ImagePullSecret[docker-store] Image[phx.ocir.io/xxxxxxxxxxxx/oracle/database/enterprise:x.x.x.x] NameSpace[wccns] service/oracle-db created deployment.apps/oracle-db created [oracle-db-8598b475c5-cx5nk] already initialized .. Checking Pod READY column for State [1/1] NAME READY STATUS RESTARTS AGE oracle-db-8598b475c5-cx5nk 1/1 Running 0 20s Service [oracle-db] found NAME READY STATUS RESTARTS AGE oracle-db-8598b475c5-cx5nk 1/1 Running 0 25s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE oracle-db LoadBalancer 10.96.74.187 \u0026lt;pending\u0026gt; 1521:30011/TCP 28s [1/30] Retrying for Oracle Database Availability... [2/30] Retrying for Oracle Database Availability... [3/30] Retrying for Oracle Database Availability... [4/30] Retrying for Oracle Database Availability... [5/30] Retrying for Oracle Database Availability... [6/30] Retrying for Oracle Database Availability... [7/30] Retrying for Oracle Database Availability... [8/30] Retrying for Oracle Database Availability... [9/30] Retrying for Oracle Database Availability... [10/30] Retrying for Oracle Database Availability... [11/30] Retrying for Oracle Database Availability... [12/30] Retrying for Oracle Database Availability... [13/30] Retrying for Oracle Database Availability... Done ! The database is ready for use . Oracle DB Service is RUNNING with NodePort [30011] Oracle DB Service URL [oracle-db.wccns.svc.cluster.local:1521/devpdb.k8s]    Once database is created successfully, you can use the database connection string, as an rcuDatabaseURL parameter in the create-domain-inputs.yaml file.\nConfigure access to your database Run a container to create rcu pod\nkubectl run rcu --generator=run-pod/v1 \\  --image phx.ocir.io/xxxxxxxxxxx/oracle/wccontent:x.x.x.x \\  --namespace wccns \\  --overrides=\u0026#39;{ \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;spec\u0026#34;: { \u0026#34;imagePullSecrets\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;image-secret\u0026#34;}] } }\u0026#39; \\  -- sleep infinity # Check the status of rcu pod kubectl get pods -n wccns Run the Repository Creation Utility to set up your database schemas Create or Drop schemas To create the database schemas for Oracle WebCenter Content, run the create-rcu-schema.sh script.\nFor example:\n# Make sure rcu pod status is running before executing this kubectl exec -n wccns -ti rcu /bin/bash # DB details export CONNECTION_STRING=your_db_host:1521/your_db_service export RCUPREFIX=your_schema_prefix echo -e welcome1\u0026#34;\\n\u0026#34;welcome1\u0026gt; /tmp/pwd.txt # Create schemas /u01/oracle/oracle_common/bin/rcu -silent -createRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -useSamePasswordForAllSchemaUsers true -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component CONTENT -component MDS -component STB -component OPSS -component IAU -component IAU_APPEND -component IAU_VIEWER -component WLS -tablespace USERS -tempTablespace TEMP -f \u0026lt; /tmp/pwd.txt # Drop schemas /u01/oracle/oracle_common/bin/rcu -silent -dropRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component CONTENT -component MDS -component STB -component OPSS -component IAU -component IAU_APPEND -component IAU_VIEWER -component WLS -f \u0026lt; /tmp/pwd.txt # Exit from the container exit Create Oracle WebCenter Content domain Now that you have your Docker images and you have created your RCU schemas, you are ready to create your domain. To continue, follow the Step-3 and Step-4.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/installguide/prepare-your-environment/",
	"title": "Prepare your environment",
	"tags": [],
	"description": "Prepare for creating Oracle WebCenter Content domain, including required secrets creation, persistent volume and volume claim creation, database creation, and database schema creation.",
	"content": "To prepare your Oracle WebCenter Content in Kubernetes environment, complete the following steps:\n  Set up your Kubernetes cluster\n  Install Helm\n  Pull dependent images\n  Set up the code repository to deploy Oracle WebCenter Content domain\n  Obtain the Oracle WebCenter Content Docker image\n  Install the WebLogic Kubernetes Operator\n  Prepare the environment for Oracle WebCenter Content domain\na. Create a namespace for the Oracle WebCenter Content domain\nb. Create a persistent storage for the Oracle WebCenter Content domain\nc. Create a Kubernetes secret with domain credentials\nd. Create a Kubernetes secret with the RCU credentials\ne. Configure access to your database\nf. Run the Repository Creation Utility to set up your database schemas\n  Create Oracle WebCenter Content domain\n  Set up your Kubernetes cluster If you need help setting up a Kubernetes environment, check the cheat sheet.\nInstall Helm The WebLogic Kubernetes Operator uses Helm to create and deploy the necessary resources and then run it in a Kubernetes cluster. For Helm installation and usage information, see here.\nPull dependent images Obtain dependent images and add them to your local registry. Dependent images include WebLogic Kubernetes Operator, Traefik. Pull these images and add them to your local registry:\n Pull these docker images and re-tag them as shown:  To pull an image from the Oracle Container Registry, in a web browser, navigate to https://container-registry.oracle.com and log in using the Oracle Single Sign-On authentication service. If you do not already have SSO credentials, at the top of the page, click the Sign In link to create them.\nUse the web interface to accept the Oracle Standard Terms and Restrictions for the Oracle software images that you intend to deploy. Your acceptance of these terms are stored in a database that links the software images to your Oracle Single Sign-On login credentials.\nThen, pull these docker images and re-tag them:\ndocker login https://container-registry.oracle.com (enter your Oracle email Id and password) This step is required once at every node to get access to the Oracle Container Registry. WebLogic Kubernetes Operator image:\n$ docker pull container-registry.oracle.com/middleware/weblogic-kubernetes-operator:3.3.0 $ docker tag container-registry.oracle.com/middleware/weblogic-kubernetes-operator:3.3.0 oracle/weblogic-kubernetes-operator:3.3.0 Pull Traefik Image\n$ docker pull traefik:2.2.8 Set up the code repository to deploy Oracle WebCenter Content domain Oracle WebCenter Content domain deployment on Kubernetes leverages the WebLogic Kubernetes Operator infrastructure. To deploy an Oracle WebCenter Content domain, you must set up the deployment scripts.\n  Create a working directory to set up the source code:\n$ export WORKDIR=$HOME/wcc_3.3.0 $ mkdir ${WORKDIR}   Download the supported version of the WebLogic Kubernetes Operator source code from WebLogic Kubernetes Operator github project. Currently the supported WebLogic Kubernetes Operator version is 3.3.0:\n$ git clone https://github.com/oracle/weblogic-kubernetes-operator.git --branch v3.3.0   Download the Oracle WebCenter Content Kubernetes deployment scripts from the WCC repository and copy them to the WebLogic Kubernetes Operator samples location:\n$ git clone https://github.com/oracle/fmw-kubernetes.git $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/create-wcc-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/\t$ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/ingress-per-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/charts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/imagetool-scripts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ ``\n  Obtain the Oracle WebCenter Content Docker image The Oracle WebCenter Content image with latest bundle patch and required interim patches can be obtained from My Oracle Support (MOS). This is the only image supported for production deployments. Follow the below steps to download the Oracle WebCenter Content image from My Oracle Support.\n  Download patch 33771196 from My Oracle Support (MOS).\n  Unzip the downloaded patch zip file.\nFor example:\n$ unzip p32822360_122140_Linux-x86-64.zip # sample output Archive: p32822360_122140_Linux-x86-64.zip inflating: wccontent-12.2.1.4.0-8-ol7-210507.0906.tar inflating: README.html   Load the image archive using the docker load command.\nFor example:\n$ docker load \u0026lt; wccontent-12.2.1.4.0-8-ol7-210507.0906.tar    Click here to see sample output   d0df970fe76a: Loading layer [==================================================\u0026gt;] 138.3MB/138.3MB 3b64a4bdc552: Loading layer [==================================================\u0026gt;] 13.45MB/13.45MB ee5141cc5c13: Loading layer [==================================================\u0026gt;] 20.99kB/20.99kB 51f637dc720f: Loading layer [==================================================\u0026gt;] 334MB/334MB ffc8b247ad07: Loading layer [==================================================\u0026gt;] 3.98GB/3.98GB cd87862f5c14: Loading layer [==================================================\u0026gt;] 4.608kB/4.608kB 12661fb5186c: Loading layer [==================================================\u0026gt;] 137.2kB/137.2kB f84db83c8dfa: Loading layer [==================================================\u0026gt;] 69.12kB/69.12kB Loaded image: oracle/wccontent:12.2.1.4.0-8-ol7-210507.0906      Run the docker inspect command to verify that the downloaded image is the latest released image. The value of label com.oracle.weblogic.imagetool.buildid must match to 29ff0886-a299-4860-9b13-fd6bb80ec354.\nFor example:\n$ docker inspect --format=\u0026#39;{{ index .Config.Labels \u0026#34;com.oracle.weblogic.imagetool.buildid\u0026#34; }}\u0026#39; oracle/wccontent:12.2.1.4.0-8-ol7-210507.0906 29ff0886-a299-4860-9b13-fd6bb80ec354   Alternatively, if you want to build and use Oracle WebCenter Content Container image, using WebLogic Image Tool, with any additional bundle patch or interim patches, then follow these steps to create the image.\n Note: The default Oracle WebCenter Content image name used for Oracle WebCenter Content domain deployment is oracle/wccontent:12.2.1.4.0. The image created must be tagged as oracle/wccontent:12.2.1.4.0 using the docker tag command. If you want to use a different name for the image, make sure to update the new image tag name in the create-domain-inputs.yaml file and also in other instances where the oracle/wccontent:12.2.1.4.0 image name is used.\n Install the WebLogic Kubernetes Operator The WebLogic Kubernetes Operator supports the deployment of Oracle WebCenter Content domain in the Kubernetes environment. Follow the steps in this document to install WebLogic Kubernetes Operator.\n Note: Optionally, you can execute these steps to send the contents of the operator’s logs to Elasticsearch.\n In the following example commands to install the WebLogic Kubernetes Operator, opns is the namespace and op-sa is the service account created for WebLogic Kubernetes Operator:\nCreating namespace and service account for WebLogic Kubernetes Operator $ kubectl create namespace opns $ kubectl create serviceaccount -n opns op-sa Install WebLogic Kubernetes Operator $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator --namespace opns --set image=oracle/weblogic-kubernetes-operator:3.3.0 --set serviceAccount=op-sa --set \u0026quot;domainNamespaces={}\u0026quot; --set \u0026quot;javaLoggingLevel=FINE\u0026quot; --wait Prepare the environment for Oracle WebCenter Content domain Create a namespace for the Oracle WebCenter Content domain Create a Kubernetes namespace (for example, wccns) for the domain unless you intend to use the default namespace. Use the new namespace in the remaining steps in this section. For details, see Prepare to run a domain.\n $ kubectl create namespace wccns $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade --reuse-values --namespace opns --set \u0026quot;domainNamespaces={wccns}\u0026quot; --wait weblogic-kubernetes-operator kubernetes/charts/weblogic-operator Create a persistent storage for the Oracle WebCenter Content domain In the Kubernetes namespace you created, create the PV and PVC for the domain by running the create-pv-pvc.sh script. Follow the instructions for using the script to create a dedicated PV and PVC for the Oracle WebCenter Content domain.\n  Review the configuration parameters for PV creation here. Based on your requirements, update the values in the create-pv-pvc-inputs.yaml file located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc/. Sample configuration parameter values for the Oracle WebCenter Content domain are:\n baseName: domain domainUID: wccinfra namespace: wccns weblogicDomainStorageType: HOST_PATH weblogicDomainStoragePath: /net/\u0026lt;your_host_name\u0026gt;/scratch/k8s_dir/wcc    Ensure that the path for the weblogicDomainStoragePath property exists (if not, please refer subsection 4 of this document to create it first) and has full access permissions, and that the folder is empty.\n  Run the create-pv-pvc.sh script:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ rm -rf output/ $ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output   The create-pv-pvc.sh script will create a subdirectory pv-pvcs under the given /path/to/output-directory directory and creates two YAML configuration files for PV and PVC. Apply these two YAML files to create the PV and PVC Kubernetes resources using the kubectl create -f command:\n$ kubectl create -f output/pv-pvcs/wccinfra-domain-pv.yaml -n wccns $ kubectl create -f output/pv-pvcs/wccinfra-domain-pvc.yaml -n wccns   Get the details of PV and PVC:\n$ kubectl describe pv wccinfra-domain-pv $ kubectl describe pvc wccinfra-domain-pvc -n wccns   Create a Kubernetes secret with domain credentials Create the Kubernetes secrets username and password of the administrative account in the same Kubernetes namespace as the domain:\n $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-credentials $ ./create-weblogic-credentials.sh -u weblogic -p welcome1 -n wccns -d wccinfra -s wccinfra-domain-credentials For more details, see this document.\nYou can check the secret with the kubectl get secret command.\nFor example:\n  Click here to see the sample secret description.   $ kubectl get secret wccinfra-domain-credentials -o yaml -n wccns apiVersion: v1 data: password: d2VsY29tZTE= username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: \u0026quot;2020-09-16T08:22:50Z\u0026quot; labels: weblogic.domainName: wccinfra weblogic.domainUID: wccinfra managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:password: {} f:username: {} f:metadata: f:labels: .: {} f:weblogic.domainName: {} f:weblogic.domainUID: {} f:type: {} manager: kubectl operation: Update time: \u0026quot;2020-09-16T08:22:50Z\u0026quot; name: wccinfra-domain-credentials namespace: wccns resourceVersion: \u0026quot;3277100\u0026quot; selfLink: /api/v1/namespaces/wccns/secrets/wccinfra-domain-credentials uid: 35a8313f-1ec2-44b0-a2bf-fee381eed57f type: Opaque    Create a Kubernetes secret with the RCU credentials You also need to create a Kubernetes secret containing the credentials for the database schemas. When you create your domain, it will obtain the RCU credentials from this secret.\nUse the provided sample script to create the secret:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-rcu-credentials $ ./create-rcu-credentials.sh -u weblogic -p welcome1 -a sys -q welcome1 -d wccinfra -n wccns -s wccinfra-rcu-credentials The parameter values are:\n-u username for schema owner (regular user), required.\n-p password for schema owner (regular user), required.\n-a username for SYSDBA user, required.\n-q password for SYSDBA user, required.\n-d domainUID. Example: wccinfra\n-n namespace. Example: wccns\n-s secretName. Example: wccinfra-rcu-credentials\nYou can confirm the secret was created as expected with the kubectl get secret command.\nFor example:\n  Click here to see the sample secret description.   $ kubectl get secret wccinfra-rcu-credentials -o yaml -n wccns apiVersion: v1 data: password: d2VsY29tZTE= sys_password: d2VsY29tZTE= sys_username: c3lz username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: \u0026#34;2020-09-16T08:23:04Z\u0026#34; labels: weblogic.domainName: wccinfra weblogic.domainUID: wccinfra managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:password: {} f:sys_password: {} f:sys_username: {} f:username: {} f:metadata: f:labels: .: {} f:weblogic.domainName: {} f:weblogic.domainUID: {} f:type: {} manager: kubectl operation: Update time: \u0026#34;2020-09-16T08:23:04Z\u0026#34; name: wccinfra-rcu-credentials namespace: wccns resourceVersion: \u0026#34;3277132\u0026#34; selfLink: /api/v1/namespaces/wccns/secrets/wccinfra-rcu-credentials uid: b75f4e13-84e6-40f5-84ba-0213d85bdf30 type: Opaque    Configure access to your database Run a container to create rcu pod\nkubectl run rcu --generator=run-pod/v1 --image oracle/wccontent:12.2.1.4 -n wccns -- sleep infinity #check the status of rcu pod kubectl get pods -n wccns Run the Repository Creation Utility to set up your database schemas Create OR Drop schemas To create the database schemas for Oracle WebCenter Content, run the create-rcu-schema.sh script.\nFor example:\n# make sure rcu pod status is running before executing this kubectl exec -n wccns -ti rcu /bin/bash # DB details export CONNECTION_STRING=your_db_host:1521/your_db_service export RCUPREFIX=your_schema_prefix echo -e welcome1\u0026#34;\\n\u0026#34;welcome1\u0026gt; /tmp/pwd.txt # Create schemas /u01/oracle/oracle_common/bin/rcu -silent -createRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -useSamePasswordForAllSchemaUsers true -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component CONTENT -component MDS -component STB -component OPSS -component IAU -component IAU_APPEND -component IAU_VIEWER -component WLS -tablespace USERS -tempTablespace TEMP -f \u0026lt; /tmp/pwd.txt # Drop schemas /u01/oracle/oracle_common/bin/rcu -silent -dropRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component CONTENT -component MDS -component STB -component OPSS -component IAU -component IAU_APPEND -component IAU_VIEWER -component WLS -f \u0026lt; /tmp/pwd.txt #exit from the container exit Create Oracle WebCenter Content domain Now that you have your Docker images and you have created your RCU schemas, you are ready to create your domain. To continue, follow the instructions in Create Oracle WebCenter Content domains.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/appendix/quickstart-deployment-guide/",
	"title": "Quick start deployment guide",
	"tags": [],
	"description": "Describes how to quickly get an Oracle WebCenter Content domain instance running (using the defaults, nothing special) for development and test purposes.",
	"content": "Use this Quick Start to create an Oracle WebCenter Content domain deployment in a Kubernetes cluster (on-premise environments) with WebLogic Kubernetes Operator. Note that this walkthrough is for demonstration purposes only, not for use in production. These instructions assume that you are already familiar with Kubernetes. If you need more detailed instructions, refer to the Install Guide.\nHardware requirements Supported Linux kernel for deploying and running Oracle WebCenter Content domain with the WebLogic Kubernetes Operator is Oracle Linux 7 (UL6+) and Red Hat Enterprise Linux 7 (UL3+ only with standalone Kubernetes). Refer to the prerequisites for more details.\nFor this exercise the minimum hardware requirement to create a single node Kubernetes cluster and deploy Oracle WebCenter Content domain with one UCM and IBR Cluster each.\n   Hardware Size     RAM 32GB   Disk Space 250GB+   CPU core(s) 6    See here for resourse sizing information for Oracle WebCenter Content domain setup on Kubernetes cluster.\nSet up Oracle WebCenter Content in an on-premise environment Perform the steps in this topic to create a single instance on-premise Kubernetes cluster and create an Oracle WebCenter Content domain which deploys Oracle WebCenter Content Server and Oracle WebCenter Inbound Refinery Server.\n Step 1 - Prepare a virtual machine for the Kubernetes cluster Step 2 - Set up a single instance Kubernetes cluster Step 3 - Get scripts and images Step 4 - Install the WebLogic Kubernetes Operator Step 5 - Install the Traefik (ingress-based) load balancer Step 6 - Create and configure an Oracle WebCenter Content Domain  1. Prepare a virtual machine for the Kubernetes cluster For illustration purposes, these instructions are for Oracle Linux 7u6+. If you are using a different flavor of Linux, you will need to adjust the steps accordingly.\nThese steps must be run with the root user, unless specified otherwise. Any time you see YOUR_USERID in a command, you should replace it with your actual userid.\n 1.1 Prerequisites   Choose the directories where your Docker and Kubernetes files will be stored. The Docker directory should be on a disk with a lot of free space (more than 100GB) because it will be used for the Docker file system, which contains all of your images and containers. The Kubernetes directory is used for the /var/lib/kubelet file system and persistent volume storage.\n$ export docker_dir=/u01/docker $ export kubelet_dir=/u01/kubelet $ mkdir -p $docker_dir $kubelet_dir $ ln -s $kubelet_dir /var/lib/kubelet   Verify that IPv4 forwarding is enabled on your host.\nNote: Replace eth0 with the ethernet interface name of your compute resource if it is different.\n$ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.docker0.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.eth0.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.lo.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.ip_nonlocal_bind' For example: Verify that all are set to 1\n$ net.ipv4.conf.docker0.forwarding = 1 $ net.ipv4.conf.eth0.forwarding = 1 $ net.ipv4.conf.lo.forwarding = 1 $ net.ipv4.ip_nonlocal_bind = 1 Solution: Set all values to 1 immediately with the following commands:\n$ /sbin/sysctl net.ipv4.conf.docker0.forwarding=1 $ /sbin/sysctl net.ipv4.conf.eth0.forwarding=1 $ /sbin/sysctl net.ipv4.conf.lo.forwarding=1 $ /sbin/sysctl net.ipv4.ip_nonlocal_bind=1 To preserve the settings post-reboot: Update the above values to 1 in files in /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/\n  Verify the iptables rule for forwarding.\nKubernetes uses iptables to handle many networking and port forwarding rules. A standard Docker installation may create a firewall rule that prevents forwarding.\nVerify if the iptables rule to accept forwarding traffic is set:\n$ /sbin/iptables -L -n | awk '/Chain FORWARD / {print $4}' | tr -d \u0026quot;)\u0026quot; If the output is \u0026ldquo;DROP\u0026rdquo;, then run the following command:\n$ /sbin/iptables -P FORWARD ACCEPT Verify if the iptables rule is set properly to \u0026ldquo;ACCEPT\u0026rdquo;:\n$ /sbin/iptables -L -n | awk '/Chain FORWARD / {print $4}' | tr -d \u0026quot;)\u0026quot;   Disable and stop firewalld:\n$ systemctl disable firewalld $ systemctl stop firewalld   1.2 Install and configure Docker  Note : If you have already installed Docker with version 18.03+ and configured Docker daemon root to sufficient disk space along with proxy settings, continue to Install and configure Kubernetes\n   Make sure that you have the right operating system version:\n$ uname -a $ more /etc/oracle-release For example:\nLinux xxxxxxx 4.1.12-124.27.1.el7uek.x86_64 #2 SMP Mon May 13 08:56:17 PDT 2019 x86_64 x86_64 x86_64 GNU/Linux Oracle Linux Server release 7.6   Install the latest docker-engine and start the Docker service:\n$ yum-config-manager --enable ol7_addons $ yum install docker-engine $ systemctl enable docker $ systemctl start docker   Add your userid to the Docker group. This will allow you to run the Docker commands without root access:\n$ /sbin/usermod -a -G docker \u0026lt;YOUR_USERID\u0026gt;   Check your Docker version. It must be at least 18.03.\n$ docker version For example:\nClient: Docker Engine - Community Version: 19.03.1-ol API version: 1.40 Go version: go1.12.5 Git commit: ead9442 Built: Wed Sep 11 06:40:28 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.1-ol API version: 1.40 (minimum version 1.12) Go version: go1.12.5 Git commit: ead9442 Built: Wed Sep 11 06:38:43 2019 OS/Arch: linux/amd64 Experimental: false Default Registry: docker.io containerd: Version: v1.2.0-rc.0-108-gc444666 GitCommit: c4446665cb9c30056f4998ed953e6d4ff22c7c39 runc: Version: 1.0.0-rc5+dev GitCommit: 4bb1fe4ace1a32d3676bb98f5d3b6a4e32bf6c58 docker-init: Version: 0.18.0 GitCommit: fec3683   Update the Docker engine configuration:\n$ mkdir -p /etc/docker $ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/docker/daemon.json { \u0026quot;group\u0026quot;: \u0026quot;docker\u0026quot;, \u0026quot;data-root\u0026quot;: \u0026quot;/u01/docker\u0026quot; } EOF   Configure proxy settings if you are behind an HTTP proxy. On some hosts /etc/systemd/system/docker.service.d may not be available. Create this directory if it is not available.\n ### Create the drop-in file /etc/systemd/system/docker.service.d/http-proxy.conf that contains proxy details: $ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/docker.service.d/http-proxy.conf [Service] Environment=\u0026quot;HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT\u0026quot; Environment=\u0026quot;HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT\u0026quot; Environment=\u0026quot;NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock\u0026quot; EOF   Restart the Docker daemon to load the latest changes:\n$ systemctl daemon-reload $ systemctl restart docker   Verify that the proxy is configured with Docker:\n$ docker info|grep -i proxy For example:\nHTTP Proxy: http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT HTTPS Proxy: http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT No Proxy: localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock   Verify Docker installation:\n$ docker run hello-world For example:\nHello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/   1.3 Install and configure Kubernetes   Add the external Kubernetes repository:\n$ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF   Set SELinux in permissive mode (effectively disabling it):\n$ export PATH=/sbin:$PATH $ setenforce 0 $ sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config   Export proxy and install kubeadm, kubelet, and kubectl:\n### Get the nslookup IP address of the master node to use with apiserver-advertise-address during setting up Kubernetes master ### as the host may have different internal ip (hostname -i) and nslookup $HOSTNAME $ ip_addr=`nslookup $(hostname -f) | grep -m2 Address | tail -n1| awk -F: '{print $2}'| tr -d \u0026quot; \u0026quot;` $ echo $ip_addr ### Set the proxies $ export NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr $ export no_proxy=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr $ export http_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export https_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT ### install kubernetes 1.18.4-1 $ VERSION=1.18.4-1 $ yum install -y kubelet-$VERSION kubeadm-$VERSION kubectl-$VERSION --disableexcludes=kubernetes ### enable kubelet service so that it auto-restart on reboot $ systemctl enable --now kubelet   Ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl to avoid traffic routing issues:\n$ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sysctl --system   Disable swap check:\n$ sed -i 's/KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\u0026quot;--fail-swap-on=false\u0026quot;/' /etc/sysconfig/kubelet $ cat /etc/sysconfig/kubelet ### Reload and restart kubelet $ systemctl daemon-reload $ systemctl restart kubelet   1.4 Set up Helm   Install Helm v3.x.\na. Download Helm from https://github.com/helm/helm/releases. Example to download Helm v3.2.4:\n$ wget https://get.helm.sh/helm-v3.2.4-linux-amd64.tar.gz b. Unpack tar.gz:\n$ tar -zxvf helm-v3.2.4-linux-amd64.tar.gz c. Find the Helm binary in the unpacked directory, and move it to its desired destination:\n$ mv linux-amd64/helm /usr/bin/helm   Run helm version to verify its installation:\n$ helm version version.BuildInfo{Version:\u0026quot;v3.2.4\u0026quot;, GitCommit:\u0026quot;0ad800ef43d3b826f31a5ad8dfbb4fe05d143688\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, GoVersion:\u0026quot;go1.13.12\u0026quot;}   2. Set up a single instance Kubernetes cluster  Notes:\n These steps must be run with the root user, unless specified otherwise! If you choose to use a different cidr block (that is, other than 10.244.0.0/16 for the --pod-network-cidr= in the kubeadm init command), then also update NO_PROXY and no_proxy with the appropriate value.  Also make sure to update kube-flannel.yaml with the new value before deploying.   Replace the following with appropriate values:  ADD-YOUR-INTERNAL-NO-PROXY-LIST REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT     2.1 Set up the master node   Create a shell script that sets up the necessary environment variables. You can append this to the user’s .bashrc so that it will run at login. You must also configure your proxy settings here if you are behind an HTTP proxy:\n## grab my IP address to pass into kubeadm init, and to add to no_proxy vars ip_addr=`nslookup $(hostname -f) | grep -m2 Address | tail -n1| awk -F: '{print $2}'| tr -d \u0026quot; \u0026quot;` export pod_network_cidr=\u0026quot;10.244.0.0/16\u0026quot; export service_cidr=\u0026quot;10.96.0.0/12\u0026quot; export PATH=$PATH:/sbin:/usr/sbin ### Set the proxies export NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr,$pod_network_cidr,$service_cidr export no_proxy=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr,$pod_network_cidr,$service_cidr export http_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export https_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT   Source the script to set up your environment variables:\n$ . ~/.bashrc   To implement command completion, add the following to the script:\n$ [ -f /usr/share/bash-completion/bash_completion ] \u0026amp;\u0026amp; . /usr/share/bash-completion/bash_completion $ source \u0026lt;(kubectl completion bash)   Run kubeadm init to create the master node:\n$ kubeadm init \\ --pod-network-cidr=$pod_network_cidr \\ --apiserver-advertise-address=$ip_addr \\ --ignore-preflight-errors=Swap \u0026gt; /tmp/kubeadm-init.out 2\u0026gt;\u0026amp;1   Log in to the terminal with YOUR_USERID:YOUR_GROUP. Then set up the ~/.bashrc similar to steps 1 to 3 with YOUR_USERID:YOUR_GROUP.\n Note that from now on we will be using YOUR_USERID:YOUR_GROUP to execute any kubectl commands and not root.\n   Set up YOUR_USERID:YOUR_GROUP to access the Kubernetes cluster:\n$ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config   Verify that YOUR_USERID:YOUR_GROUP is set up to access the Kubernetes cluster using the kubectl command:\n$ kubectl get nodes  Note: At this step, the node is not in ready state as we have not yet installed the pod network add-on. After the next step, the node will show status as Ready.\n   Install a pod network add-on (flannel) so that your pods can communicate with each other.\n Note: If you are using a different cidr block than 10.244.0.0/16, then download and update kube-flannel.yml with the correct cidr address before deploying into the cluster:\n $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.12.0/Documentation/kube-flannel.yml   Verify that the master node is in Ready status:\n$ kubectl get nodes For example:\nNAME STATUS ROLES AGE VERSION mymasternode Ready master 8m26s v1.18.4 or:\n$ kubectl get pods -n kube-system For example:\nNAME READY STATUS RESTARTS AGE pod/coredns-86c58d9df4-58p9f 1/1 Running 0 3m59s pod/coredns-86c58d9df4-mzrr5 1/1 Running 0 3m59s pod/etcd-mymasternode 1/1 Running 0 3m4s pod/kube-apiserver-node 1/1 Running 0 3m21s pod/kube-controller-manager-mymasternode 1/1 Running 0 3m25s pod/kube-flannel-ds-amd64-6npx4 1/1 Running 0 49s pod/kube-proxy-4vsgm 1/1 Running 0 3m59s pod/kube-scheduler-mymasternode 1/1 Running 0 2m58s   To schedule pods on the master node, taint the node:\n$ kubectl taint nodes --all node-role.kubernetes.io/master-   Congratulations! Your Kubernetes cluster environment is ready to deploy your Oracle WebCenter Content domain.\nFor additional references on Kubernetes cluster setup, check the cheat sheet.\n3. Get scripts and images 3.1 Set up the code repository to deploy Oracle WebCenter Content domains Follow these steps to set up the source code repository required to deploy Oracle WebCenter Content domains.\n3.2 Get required Docker images and add them to your local registry Follow these steps to set up the source code repository required to deploy Oracle WebCenter Content domains.\n3.3 Build Oracle WebCenter Content Docker image and add it to your local registry Follow these steps to set up the source code repository required to deploy Oracle WebCenter Content domains.\n Note: For test and development purposes this Oracle WebCenter Content image need not contain any product patches.\n 4. Install WebLogic Kubernetes Operator 4.1 Prepare for WebLogic Kubernetes Operator.   Create a namespace opns for the WebLogic Kubernetes Operator:\n$ kubectl create namespace opns   Create a service account op-sa for WebLogic Kubernetes Operator in the operator’s namespace:\n$ kubectl create serviceaccount -n opns op-sa   4.2 Install the WebLogic Kubernetes Operator Use Helm to install and start WebLogic Kubernetes Operator from the directory you just cloned:\n $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator \\ --namespace opns \\ --set image=oracle/weblogic-kubernetes-operator:3.3.0 \\ --set serviceAccount=op-sa \\ --set \u0026quot;domainNamespaces={}\u0026quot; \\ --wait 4.3 Verify the WebLogic Kubernetes Operator   Verify that the WebLogic Kubernetes Operator\u0026rsquo;s pod is running by listing the pods in the respective namespace. You should see one for the WebLogic Kubernetes Operator:\n$ kubectl get pods -n opns   Verify that the WebLogic Kubernetes Operator is up and running by viewing the operator-pod\u0026rsquo;s logs:\n$ kubectl logs -n opns -c weblogic-operator deployments/weblogic-operator   The WebLogic Kubernetes Operator v3.3.0 has been installed. Continue with the load balancer and Oracle WebCenter Content domain setup.\n5. Install the Traefik (ingress-based) load balancer WebLogic Kubernetes Operator supports these load balancers: Traefik, NGINX and Apache. Samples are provided in the documentation.\nThis Quick Start demonstrates how to install the Traefik ingress controller to provide load balancing for an Oracle WebCenter Content domain.\n  Create a namespace for Traefik:\n$ kubectl create namespace traefik   Set up Helm for 3rd party services:\n$ helm repo add traefik https://containous.github.io/traefik-helm-chart   Install the Traefik operator in the traefik namespace with the provided sample values:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\ --namespace traefik \\ --values kubernetes/samples/scripts/charts/traefik/values.yaml \\ --set \u0026quot;kubernetes.namespaces={traefik}\u0026quot; \\ --set \u0026quot;service.type=NodePort\u0026quot; \\ --wait   6. Create and configure an Oracle WebCenter Content domain 6.1 Prepare for an Oracle WebCenter Content domain   Create a namespace that can host Oracle WebCenter Content domain:\n$ kubectl create namespace wccns   Use Helm to configure the WebLogic Kubernetes Operator to manage Oracle WebCenter Content domains in this namespace:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade weblogic-kubernetes-operator kubernetes/charts/weblogic-operator \\ --reuse-values \\ --namespace opns \\ --set \u0026quot;domainNamespaces={wccns}\u0026quot; \\ --wait   Create Kubernetes secrets.\na. Create a Kubernetes secret for the domain in the same Kubernetes namespace as the domain. In this example, the username is weblogic, the password in welcome1, and the namespace is wccns:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-credentials $ ./create-weblogic-credentials.sh \\ -u weblogic \\ -p welcome1 \\ -n wccns \\ -d wccinfra \\ -s wccinfra-domain-credentials b. Create a Kubernetes secret for the RCU in the same Kubernetes namespace as the domain:\n Schema user : WCC1 Schema password : Oradoc_db1 DB sys user password : Oradoc_db1 Domain name : wccinfra Domain Namespace : wccns Secret name : wccinfra-rcu-credentials  $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-rcu-credentials $ ./create-rcu-credentials.sh \\ -u WCC1 \\ -p Oradoc_db1 \\ -a sys \\ -q Oradoc_db1 \\ -d wccinfra \\ -n wccns \\ -s wccinfra-rcu-credentials   Create the Kubernetes persistence volume and persistence volume claim.\na. Create the Oracle WebCenter Content domain home directory. Determine if a user already exists on your host system with uid:gid of 1000:0:\n$ sudo getent passwd 1000 If this command returns a username (which is the first field), you can skip the following useradd command. If not, create the oracle user with useradd:\n$ sudo useradd -u 1000 -g 0 oracle Create the directory that will be used for the Oracle WebCenter Content domain home:\n$ sudo mkdir /scratch/k8s_dir $ sudo chown -R 1000:0 /scratch/k8s_dir b. Update create-pv-pvc-inputs.yaml with the following values:\n baseName: domain domainUID: wccinfra namespace: wccns weblogicDomainStoragePath: /scratch/k8s_dir  $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ cp create-pv-pvc-inputs.yaml create-pv-pvc-inputs.yaml.orig $ sed -i -e \u0026quot;s:baseName\\: weblogic-sample:baseName\\: domain:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:domainUID\\::domainUID\\: wccinfra:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:namespace\\: default:namespace\\: wccns:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:#weblogicDomainStoragePath\\: /scratch/k8s_dir:weblogicDomainStoragePath\\: /scratch/k8s_dir:g\u0026quot; create-pv-pvc-inputs.yaml c. Run the create-pv-pvc.sh script to create the PV and PVC configuration files:\n$ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output d. Create the PV and PVC using the configuration files created in the previous step:\n$ kubectl create -f output/pv-pvcs/wccinfra-domain-pv.yaml $ kubectl create -f output/pv-pvcs/wccinfra-domain-pvc.yaml   Configure the database and create schemas for the Oracle WebCenter Content domain.\nFollow configure-database-access step and run-RCU step to set up the database connection and configure product schemas required to deploy Oracle WebCenter Content domain.\n  Now the environment is ready to start the Oracle WebCenter Content domain creation.\n6.2 Create an Oracle WebCenter Content domain   The sample scripts for Oracle WebCenter Content domain deployment are available at \u0026lt;weblogic-kubernetes-operator-project\u0026gt;/kubernetes/samples/scripts/create-wcc-domain. You must edit create-domain-inputs.yaml (or a copy of it) to provide the details for your domain.\n  Run the create-domain.sh script to create a domain:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./create-domain.sh -i create-domain-inputs.yaml -o output   Create a Kubernetes domain object:\nOnce the create-domain.sh is successful, it generates the output/weblogic-domains/wccinfra/domain.yaml that you can use to create the Kubernetes resource domain, which starts the domain and servers:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv $ kubectl create -f output/weblogic-domains/wccinfra/domain.yaml   Verify that the Kubernetes domain object named wccinfra is created:\n$ kubectl get domain -n wccns NAME AGE wccinfra 3m18s   Once you create the domain, introspect pod is created. This inspects the domain home and then starts the wccinfra-adminserver pod. Once the wccinfra-adminserver pod starts successfully, then the Managed Server pods are started in parallel. Watch the wccns namespace for the status of domain creation:\n$ kubectl get pods -n wccns   Verify that the Oracle WebCenter Content domain server pods and services are created and in Ready state:\n$ kubectl get all -n wccns   6.3 Configure Traefik to access in Oracle WebCenter Content domain services   Configure Traefik to manage ingresses created in the Oracle WebCenter Content domain namespace (wccns):\n$ helm upgrade traefik traefik/traefik \\ --reuse-values \\ --namespace traefik \\ --set \u0026quot;kubernetes.namespaces={traefik,wccns}\u0026quot; \\ --wait   Create an ingress for the domain in the domain namespace by using the sample Helm chart:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress kubernetes/samples/charts/ingress-per-domain \\ --namespace wccns \\ --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\ --set \u0026quot;traefik.hostname=$(hostname -f)\u0026quot;   Verify the created ingress per domain details:\n$ kubectl describe ingress wccinfra-traefik -n wccns   6.4 Verify that you can access the Oracle WebCenter Content domain URL   Get the LOADBALANCER_HOSTNAME for your environment:\nexport LOADBALANCER_HOSTNAME=$(hostname -f)   The following URLs are available for Oracle WebCenter Content domain:\nCredentials: username: weblogic password: welcome1\nhttp://${LOADBALANCER_HOSTNAME}:30305/console http://${LOADBALANCER_HOSTNAME}:30305/em http://${LOADBALANCER_HOSTNAME}:30305/cs http://${LOADBALANCER_HOSTNAME}:30305/ibr http://${LOADBALANCER_HOSTNAME}:30305/imaging http://${LOADBALANCER_HOSTNAME}:30305/dc-console http://${LOADBALANCER_HOSTNAME}:30305/wcc   "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/configure-load-balancer/nginx/",
	"title": "NGINX",
	"tags": [],
	"description": "Configure the ingress-based NGINX load balancer for Oracle WebCenter Content domain.",
	"content": "This section provides information about how to install and configure the ingress-based NGINX load balancer to load balance Oracle WebCenter Content domain clusters. You can configure NGINX for non-SSL, SSL termination, and end-to-end SSL access of the application URL.\nFollow these steps to set up NGINX as a load balancer for an Oracle WebCenter Content domain in a Kubernetes cluster:\nSee the official installation document for prerequisites.\n  Non-SSL and SSL termination\n Install the NGINX load balancer Configure NGINX to manage ingresses Verify non-SSL and SSL termination access    End-to-end SSL configuration\n Install the NGINX load balancer for End-to-end SSL Deploy tls to access individual Managed Servers Deploy tls to access Administration Server    To get repository information, enter the following Helm commands:\n$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx $ helm repo update Non-SSL and SSL termination Install the NGINX load balancer   Deploy the ingress-nginx controller by using Helm on the domain namespace:\nFor Kubernetes versions up to v1.18.x:\n$ helm install nginx-ingress -n wccns \\  --version=3.34.0 \\  --set controller.service.type=NodePort \\  --set controller.admissionWebhooks.enabled=false \\  ingress-nginx/ingress-nginx     Click here to see the sample output.   NAME: nginx-ingress LAST DEPLOYED: Sun Feb 7 23:19:30 2021 NAMESPACE: wccns STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export HTTP_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export HTTPS_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[1].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export NODE_IP=$(kubectl --namespace wccns get nodes -o jsonpath=\u0026#34;{.items[0].status.addresses[1].address}\u0026#34;) echo \u0026#34;Visit http://$NODE_IP:$HTTP_NODE_PORTto access your application via HTTP.\u0026#34; echo \u0026#34;Visit https://$NODE_IP:$HTTPS_NODE_PORTto access your application via HTTPS.\u0026#34; An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls      Check the status of the deployed ingress controller:\n$ kubectl --namespace wccns get services | grep ingress-nginx-controller Sample output:\nnginx-ingress-ingress-nginx-controller NodePort 10.97.189.122 \u0026lt;none\u0026gt; 80:30993/TCP,443:30232/TCP 7d2h   Configure NGINX to manage ingresses  Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK, tls is Non-SSL, and domainType is wccinfra. These values can be overridden by passing values through the command line or can be edited in the sample file values.yaml. If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. Update the template YAML file for the NGINX load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/nginx-ingress.yaml  $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wccinfra-nginx-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;nginx.hostname=$(hostname -f)\u0026#34; \\  --set type=NGINX \\  --set tls=NONSSL Sample output:\nNAME: wccinfra-nginx-ingress LAST DEPLOYED: Sun Feb 7 23:52:38 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate a Kubernetes secret:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Install ingress-per-domain using Helm for SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wccinfra-nginx-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;nginx.hostname=$(hostname -f)\u0026#34; \\  --set type=NGINX --set tls=SSL Sample output:\nNAME: wccinfra-nginx-ingress LAST DEPLOYED: Mon Feb 8 00:01:13 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For non-SSL access or SSL to the Oracle WebCenter Content application, get the details of the services by the ingress:\n$ kubectl describe ingress wccinfra-nginx -n wccns     Click here to see the sample output of the services supported by the above deployed ingress.   Name: wccinfra-nginx Namespace: wccns Address: 10.97.189.122 Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026#34;default-http-backend\u0026#34; not found\u0026gt;) TLS: domain1-tls-cert terminates domain1.org Rules: Host Path Backends ---- ---- -------- domain1.org /console wccinfra-adminserver:7001 (10.244.0.58:7001) /em wccinfra-adminserver:7001 (10.244.0.58:7001) /servicebus wccinfra-adminserver:7001 (10.244.0.58:7001) /cs wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /adfAuthentication wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /ibr wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /ibr/adfAuthentication wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /weblogic/ready wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /imaging wccinfra-cluster-ipm-cluster:16000 (10.244.0.206:16000,10.244.0.209:16000,10.244.0.213:16000) /dc-console wccinfra-cluster-capture-cluster:16400 (10.244.0.204:16400,10.244.0.208:16400,10.244.0.212:16400) /dc-client wccinfra-cluster-capture-cluster:16400 (10.244.0.204:16400,10.244.0.208:16400,10.244.0.212:16400) /wcc wccinfra-cluster-wccadf-cluster:16225 (10.244.0.205:16225,10.244.0.210:16225,10.244.0.214:16225) Annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: wccinfra-nginx-ingress meta.helm.sh/release-namespace: wccns nginx.ingress.kubernetes.io/configuration-snippet: more_set_input_headers \u0026#34;X-Forwarded-Proto: https\u0026#34;; more_set_input_headers \u0026#34;WL-Proxy-SSL: true\u0026#34;; nginx.ingress.kubernetes.io/ingress.allow-http: false Events: \u0026lt;none\u0026gt;    Verify non-SSL and SSL termination access Non-SSL configuration Verify that the Oracle WebCenter Content domain application URLs are accessible through the LOADBALANCER-Non-SSLPORT:\nhttp://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/imaging http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/dc-console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/wcc SSL configuration Verify that the Oracle WebCenter Content domain application URLs are accessible through the LOADBALANCER-SSLPORT:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/imaging https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/dc-console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/wcc Uninstall the ingress Uninstall and delete the ingress-nginx deployment:\n$ helm delete wccinfra-nginx -n wccns End-to-end SSL configuration Install the NGINX load balancer for End-to-end SSL   For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate secrets:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Deploy the ingress-nginx controller by using Helm on the domain namespace:\nFor Kubernetes versions up to v1.18.x:\n$ helm install nginx-ingress -n wccns \\  --version=3.34.0 \\  --set controller.extraArgs.default-ssl-certificate=wccns/domain1-tls-cert \\  --set controller.service.type=NodePort \\  --set controller.admissionWebhooks.enabled=false \\  --set controller.extraArgs.enable-ssl-passthrough=true \\  ingress-nginx/ingress-nginx\t   Click here to see the sample output.   Release \u0026#34;nginx-ingress\u0026#34; has been upgraded. Happy Helming! NAME: nginx-ingress LAST DEPLOYED: Mon Feb 8 02:07:26 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export HTTP_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export HTTPS_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[1].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export NODE_IP=$(kubectl --namespace wccns get nodes -o jsonpath=\u0026#34;{.items[0].status.addresses[1].address}\u0026#34;) echo \u0026#34;Visit http://$NODE_IP:$HTTP_NODE_PORTto access your application via HTTP.\u0026#34; echo \u0026#34;Visit https://$NODE_IP:$HTTPS_NODE_PORTto access your application via HTTPS.\u0026#34; An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls      Check the status of the deployed ingress controller:\n$ kubectl --namespace wccns get services | grep ingress-nginx-controller Sample output:\nnginx-ingress-ingress-nginx-controller NodePort 10.97.189.122 \u0026lt;none\u0026gt; 80:30993/TCP,443:30232/TCP 168m   Deploy tls to access individual Managed Servers   Deploy tls to securely access the services. Only one application can be configured with ssl-passthrough. A sample tls file for NGINX is shown below for the service wccinfra-cluster-ucm-cluster and port 16201. All the applications running on port 16201 can be securely accessed through this ingress. For each backend service, create different ingresses as NGINX does not support multiple path/rules with annotation ssl-passthrough. That is, for wccinfra-cluster-ucm-cluster, wccinfra-cluster-ibr-cluster, wccinfra-cluster-ipm-cluster, wccinfra-cluster-capture-cluster, wccinfra-cluster-wccadf-cluster and wccinfra-adminserver, different ingresses must be created.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls Sample nginx-ucm-tls.yaml:\n  Click here to see the content of the file nginx-ucm-tls.yaml   apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wcc-ucm-ingress namespace: wccns annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: \u0026#34;true\u0026#34; spec: tls: - hosts: - \u0026#39;domain1.org\u0026#39; secretName: domain1-tls-cert rules: - host: \u0026#39;domain1.org\u0026#39; http: paths: - path: backend: serviceName: wccinfra-cluster-ucm-cluster servicePort: 16201     Note: host is the server on which this ingress is deployed.\n   Deploy the secured ingress:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl create -f nginx-ucm-tls.yaml   Check the services supported by the ingress:\n$ kubectl describe ingress wcc-ucm-ingress -n wccns    Click here check the services supported by the ingress.   Name: wcc-ucm-ingress Namespace: wccns Address: 10.102.97.237 Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026#34;default-http-backend\u0026#34; not found\u0026gt;) TLS: domain1-tls-cert terminates domain1.org Rules: Host Path Backends ---- ---- -------- domain1.org wccinfra-cluster-ucm-cluster:16201 (10.244.238.136:16201,10.244.253.132:16201) Annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: true Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Sync 62s (x2 over 106s) nginx-ingress-controller Scheduled for sync      Verify end-to-end SSL access Verify that the Oracle WebCenter Content domain application URLs are accessible through the LOADBALANCER-SSLPORT:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs Deploy tls to access Administration Server   As ssl-passthrough in NGINX works on the clusterIP of the backing service instead of individual endpoints, you must expose adminserver service created by the WebLogic Kubernetes Operator with clusterIP.\nFor example:\na. Get the name of Administration Server service:\n$ kubectl get svc -n wccns | grep wccinfra-adminserver Sample output:\nwccinfra-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP,7002/TCP 7 b. Expose the Administration Server service wccinfra-adminserver and use the new service name wccinfra-adminserver-nginx-ssl:\n$ kubectl expose svc wccinfra-adminserver -n wccns --name=wccinfra-adminserver-nginx-ssl --port=7002 c. Deploy the secured ingress:\nSample nginx-admin-tls.yaml:\n  Click here to see the content of the file nginx-admin-tls.yaml   apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wcc-admin-ingress namespace: wccns annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: \u0026#34;true\u0026#34; spec: tls: - hosts: - \u0026#39;domain1.org\u0026#39; secretName: domain1-tls-cert rules: - host: \u0026#39;domain1.org\u0026#39; http: paths: - path: backend: serviceName: wccinfra-adminserver-nginx-ssl servicePort: 7002     Note: host is the server on which this ingress is deployed.\n $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl create -f nginx-admin-tls.yaml   Verify end-to-end SSL access Verify that the Oracle WebCenter Content Administration Server URL is accessible through the LOADBALANCER-SSLPORT:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console Uninstall ingress-nginx tls $ cd weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl delete -f nginx-ucm-tls.yaml "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/weblogic-monitoring-exporter-setup/",
	"title": "Monitor an Oracle WebCenter Content domain",
	"tags": [],
	"description": "Use the WebLogic Monitoring Exporter to monitor an Oracle WebCenter Content instance using Prometheus and Grafana.",
	"content": "You can monitor a WebCenter Content domain using Prometheus and Grafana by exporting the metrics from the domain instance using the WebLogic Monitoring Exporter. This sample shows you how to set up the WebLogic Monitoring Exporter to push the data to Prometheus.\nPrerequisites This document assumes that the Prometheus Operator is deployed on the Kubernetes cluster. If it is not already deployed, follow the steps below for deploying the Prometheus Operator.\nDeploy Prometheus and Grafana Refer to the compatibility matrix of Kube Prometheus and clone the release version of the kube-prometheus repository according to the Kubernetes version of your cluster.\nClone the kube-prometheus project $ git clone https://github.com/coreos/kube-prometheus.git Label the nodes Kube-Prometheus requires all the exporter nodes to be labelled with kubernetes.io/os=linux. If a node is not labelled, then you must label it using the following command:\n$ kubectl label nodes --all kubernetes.io/os=linux Create Prometheus and Grafana resources Change to the kube-prometheus directory and execute the following commands to create the namespace and CRDs:\nNOTE: Wait for a minute for each command to process.\n$ cd kube-prometheus $ kubectl create -f manifests/setup $ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo \u0026#34;\u0026#34;; done $ kubectl create -f manifests/ Provide external access To provide external access for Grafana, Prometheus, and Alertmanager, execute the commands below:\n$ kubectl patch svc grafana -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32100 }]\u0026#39; $ kubectl patch svc prometheus-k8s -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32101 }]\u0026#39; $ kubectl patch svc alertmanager-main -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32102 }]\u0026#39; NOTE:\n 32100 is the external port for Grafana 32101 is the external port for Prometheus 32102 is the external port for Alertmanager   Set Up the WebLogic Monitoring Exporter Set up the WebLogic Monitoring Exporter that will collect WebLogic Server metrics and monitor your Oracle WebCenter Content domain.\nGenerate the WebLogic Monitoring Exporter Deployment Package Two packages are required as the listening ports are different for the Administration Server and Managed Servers. One binary required for the Admin Server (wls-exporter-as.war) and one for Managed Cluster (wls-exporter-ms.war). Set the required proxies and then run the script getX.X.X.sh to generate two binaries:\nDownload WebLogic Monitoring Exporter Download WebLogic Monitoring Exporter package from https://github.com/oracle/weblogic-monitoring-exporter/releases Download wls-exporter.war and getX.X.X.sh\nCreate configuration file for WebLogic Monitoring Exporter In this step we will create the configuration file for WebLogic Monitoring Exporter.The configuration will have the server port for serving the webapp, metrics to be scraped from the WebLogic server etc.\n  Click here to see sample content for config-admin `config-admin.yaml`.   metricsNameSnakeCase: true restPort: 7001 queries: - key: name keyName: location prefix: wls_server_ applicationRuntimes: key: name keyName: app componentRuntimes: prefix: wls_webapp_config_ type: WebAppComponentRuntime key: name values: [deploymentState, contextRoot, sourceInfo, openSessionsHighCount, openSessionsCurrentCount, sessionsOpenedTotalCount, sessionCookieMaxAgeSecs, sessionInvalidationIntervalSecs, sessionTimeoutSecs, singleThreadedServletPoolSize, sessionIDLength, servletReloadCheckSecs, jSPPageCheckSecs] servlets: prefix: wls_servlet_ key: servletName - JVMRuntime: prefix: wls_jvm_ key: name - executeQueueRuntimes: prefix: wls_socketmuxer_ key: name values: [pendingRequestCurrentCount] - workManagerRuntimes: prefix: wls_workmanager_ key: name values: [stuckThreadCount, pendingRequests, completedRequests] - threadPoolRuntime: prefix: wls_threadpool_ key: name values: [executeThreadTotalCount, queueLength, stuckThreadCount, hoggingThreadCount] - JMSRuntime: key: name keyName: jmsruntime prefix: wls_jmsruntime_ JMSServers: prefix: wls_jms_ key: name keyName: jmsserver destinations: prefix: wls_jms_dest_ key: name keyName: destination - persistentStoreRuntimes: prefix: wls_persistentstore_ key: name - JDBCServiceRuntime: JDBCDataSourceRuntimeMBeans: prefix: wls_datasource_ key: name - JTARuntime: prefix: wls_jta_ key: name    In this step we will generate the deployemt package. We have to generate three separate packages with restPort as 7001 16200 and 16250 in config.yaml. The three packages are required as the listening ports for AdminServer, Oracle WebCenter Content server \u0026amp; Oracle WebCenter Inbound Refinery server.\nUse getX.X.X.sh script to update the configuration file into wls-exporter package. Below a sample usage\nSet the required proxies and then run the script getX.X.X.sh\n$ cd kubernetes/samples/scripts/create-wcc-domain/utils/weblogic-monitoring-exporter $ sh get1.2.0.sh config-admin.yaml Output:\n./get1.2.0.sh config-admin.yaml % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 642 100 642 0 0 1186 0 --:--:-- --:--:-- --:--:-- 1184 100 2033k 100 2033k 0 0 846k 0 0:00:02 0:00:02 --:--:-- 1527k created /tmp/ci-6gGPjopn3l /tmp/ci-6gGPjopn3l /\u0026lt;your_path\u0026gt;/prometheus/weblogic_monitor_exporter in temp dir adding: config.yml (deflated 63%) Generate the packages for Managed Servers/clusters with the different configuration file.\nDeploy the WebLogic Monitoring Exporter Follow these steps to deploy the package in the WebLogic Server instances:\n  In the Administration Server and Managed Servers, deploy the WebLogic Monitoring Exporter (wls-exporter.war) separately using the Oracle Enterprise Manager.\n  Select the servers to which the Exporter WAR should be deployed:\n  Set the application name. The application name must be different if it is deployed separately in the Administration Server and Managed Servers. Make sure the context-root for both the deployments is wls-exporter:\n  Click Install and start application.\n  Then deploy the WebLogic Monitoring Exporter application.\n  Activate the changes to start the application. If the application is started and the port is exposed, then you can access the WebLogic Monitoring Exporter console using this URL: http://\u0026lt;server:port\u0026gt;/wls-exporter.\n  Repeat same steps for ucm, ibr, ipm, capture and wccadf servers.\n  Configure Prometheus Operator Prometheus enables you to collect metrics from the WebLogic Monitoring Exporter. The Prometheus Operator identifies the targets using service discovery. To get the WebLogic Monitoring Exporter end point discovered as a target, you must create a service monitor pointing to the service.\nSee the following sample service monitor deployment YAML configuration file located at\nkubernetes/samples/scripts/create-wccontent-domains/utils/weblogic-monitoring-exporter/wls-exporter.yaml.\nServiceMonitor for wls-exporter:\n  Click here to see sample content for wls-exporter.yaml   apiVersion: v1 kind: Secret metadata: name: basic-auth namespace: monitoring data: password: d2VsY29tZTE= # welcome1 i.e.'WebLogic password' user: d2VibG9naWM= # weblogic i.e. 'WebLogic username' type: Opaque --- apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: wls-exporter-wccinfra namespace: monitoring labels: k8s-app: wls-exporter spec: namespaceSelector: matchNames: - wccns selector: matchLabels: weblogic.domainName: wccinfra endpoints: - basicAuth: password: name: basic-auth key: password username: name: basic-auth key: user port: default relabelings: - action: labelmap regex: __meta_kubernetes_service_label_(.+) interval: 10s honorLabels: true path: /wls-exporter/metrics    The exporting of metrics from wls-exporter requires basicAuth so a Kubernetes Secret is created with the user name and password that are base64 encoded. This Secret will be used in the ServiceMonitor deployment.\nWhen generating the base64 encoded strings for the user name and password, observe if a new line character is appended in the encoded string. This line character causes an authentication failure. To avoid a new line string, use the following example:\n$ echo -n \u0026quot;welcome1\u0026quot; | base64 d2VsY29tZTE= In the deployment YAML configuration for wls-exporter shown above, weblogic.domainName: wccinfra is used as a label under spec.selector.matchLabels, so all the services will be selected for the service monitor. If you don\u0026rsquo;t use this label, you should create separate service monitors for each server - if the server name is used as matching labels in spec.selector.matchLabels. Doing so will require you to relabel the configuration because Prometheus, by default, ignores the labels provided in the wls-exporter.\nBy default, Prometheus does not store all the labels provided by the target. In the service monitor deployment YAML configuration, you must mention the relabeling configuration (spec.endpoints.relabelings) so that certain labels provided by weblogic-monitoring-exporter (required for the Grafana dashboard) are stored in Prometheus. Do not delete the following section from the configuration YAML file:\nrelabelings: - action: labelmap regex: __meta_kubernetes_service_label_(.+) Add RoleBinding and Role for the WebLogic Domain Namespace The RoleBinding is required for Prometheus to access the endpoints provided by the WebLogic Monitoring Exporter. You need to add RoleBinding for the namespace under which the WebLogic Servers pods are running in the Kubernetes cluster. Edit the kube-prometheus/manifests/prometheus-roleBindingSpecificNamespaces.yaml file in the Prometheus Operator deployment manifests and add the RoleBinding for the namespace (wccns) similar to the following example:\n- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: prometheus-k8s namespace: wccns roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: prometheus-k8s subjects: - kind: ServiceAccount name: prometheus-k8s namespace: monitoring Similarly, add the Role for the namespace under which the WebLogic Servers pods are running in the Kubernetes cluster. Edit kube-prometheus/manifests/prometheus-roleSpecificNamespaces.yaml in the Prometheus Operator deployment manifests and add the Role for the namespace (wccns) similar to the following example:\n- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: prometheus-k8s namespace: wccns rules: - apiGroups: - \u0026quot;\u0026quot; resources: - services - endpoints - pods verbs: - get - list - watch Then apply prometheus-roleBindingSpecificNamespaces.yaml and prometheus-roleSpecificNamespaces.yaml for the RoleBinding and Role to take effect in the cluster.\n$ kubectl apply -f kube-prometheus/manifests/prometheus-roleBindingSpecificNamespaces.yaml $ kubectl apply -f kube-prometheus/manifests/prometheus-roleSpecificNamespaces.yaml Deploy the Service Monitor To deploy the service monitor, use the above wls-exporter.yaml deployment YAML and run the following command:\n$ cd kubernetes/samples/scripts/create-wccontent-domains/utils/weblogic-monitoring-exporter/ $ kubectl create -f wls-exporter.yaml Enable Prometheus to Discover the Service After the deployment of the service monitor, Prometheus should be able to discover wls-exporter and export metrics.\nYou can access the Prometheus dashboard at http://mycompany.com:32101/.\nDeploy Grafana Dashboard To view the domain metrics, deploy the Grafana dashboard provided in the WebLogic Monitoring Exporter.\nYou can access the Grafana dashboard at http://mycompany.com:32100/.\n  Log in to Grafana dashboard with admin/admin.\n  Go to Settings, then select DataSources, and then Add Data Source.\nHTTP URL: Prometheus URL http://mycompany.com:32101/\nAuth: Enable Basic Auth\nBasic Auth Details: WebLogic credentials provided in step Configure Prometheus Operator\n  Download the weblogic_dashboard.json file from here.\n  Click Add and then Import. Paste the modified JSON in the Paste JSON block, and then load it.\nThis displays the WebLogic Server Dashboard.\n  "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/patch_and_upgrade/upgrade-operator-release/",
	"title": "Upgrade an WebLogic Kubernetes Operator release",
	"tags": [],
	"description": "Upgrade the WebLogic Kubernetes Operator release to a newer version.",
	"content": "These instructions apply to upgrading WebLogic Kubernetes Operators within the 3.x release family as additional versions are released.\nTo upgrade WebLogic Kubernetes Operator, use the helm upgrade command. Make sure that the weblogic-kubernetes-operator repository on your local machine is at the WebLogic Kubernetes Operator release to which you are upgrading. When upgrading the WebLogic Kubernetes Operator, the helm upgrade command requires that you supply a new Helm chart and image. For example:\n$ helm upgrade \\ --reuse-values \\ --set image=oracle/weblogic-kubernetes-operator:3.3.0 \\ --namespace weblogic-operator-namespace \\ --wait \\ weblogic-kubernetes-operator \\ kubernetes/charts/weblogic-operator "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/",
	"title": "Administration Guide",
	"tags": [],
	"description": "Describes how to use some of the common utility tools and configurations to administer Oracle WebCenter Content domains.",
	"content": "Administer Oracle WebCenter Content domains in Kubernetes.\n Set up a load balancer  Configure different load balancers for Oracle WebCenter Content domains.\n Monitor an Oracle WebCenter Content domain  Use the WebLogic Monitoring Exporter to monitor an Oracle WebCenter Content instance using Prometheus and Grafana.\n Elasticsearch integration for logs  Monitor an Oracle WebCenter Sites domain and publish the WebLogic Server logs to Elasticsearch.\n Publish logs to Elasticsearch  Use the WebLogic Logging Exporter to publish the WebLogic Server logs to Elasticsearch.\n Publish logs to Elasticsearch Using Fluentd  Configure a WebLogic domain to use Fluentd to send log information to Elasticsearch.\n Configure an additional mount or shared space to a domain for Imaging and Capture  Configure an additional mount or shared space to a domain, for WebCenter Imaging and WebCenter Capture\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/installguide/create-wccontent-domains/",
	"title": "Create Oracle WebCenter Content domain",
	"tags": [],
	"description": "Create Oracle WebCenter Content domain home on an existing PV or PVC and create the domain resource YAML file for deploying the generated Oracle WebCenter Content domain.",
	"content": "The WebCenter Content deployment scripts demonstrate the creation of Oracle WebCenter Content domain home on an existing Kubernetes persistent volume (PV) and persistent volume claim (PVC). The scripts also generate the domain YAML file, which can then be used to start the Kubernetes artifacts of the corresponding domain.\nPrerequisites Before you begin, complete the following steps:\n Review the Domain resource documentation. Review the requirements and limitations. Ensure that you have executed all the preliminary steps in Prepare your environment. Ensure that the database schemas were created and the WebLogic Kubernetes Operator are running.  Prepare to use the create domain script The sample scripts for Oracle WebCenter Content domain deployment are available at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain.\nYou must edit create-domain-inputs.yaml (or a copy of it) located under ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domian-home-on-pv to provide the details for your domain. Refer to the configuration parameters below to understand the information that you must provide in this file.\nConfiguration parameters The following parameters can be provided in the inputs file.\n   Parameter Definition Default     sslEnabled Boolean indicating whether to enable SSL for each WebLogic Server instance. false   adminPort Port number for the Administration Server inside the Kubernetes cluster. 7001   adminServerSSLPort SSL port number of the Administration Server inside the Kubernetes cluster. 7002   adminNodePort Port number of the Administration Server outside the Kubernetes cluster. 30701   adminServerName Name of the Administration Server. AdminServer   clusterName Name of the WebLogic cluster instance to generate for the domain. By default the cluster name is ucm_cluster \u0026amp; ibr_cluster for the WebCenter Content domain. ucm_cluster   configuredManagedServerCount Number of Managed Server instances to generate for the domain. 5   createDomainFilesDir Directory on the host machine to locate all the files to create a WebLogic domain, including the script that is specified in the createDomainScriptName property. By default, this directory is set to the relative path wlst, and the create script will use the built-in WLST offline scripts in the wlst directory to create the WebLogic domain. An absolute path is also supported to point to an arbitrary directory in the file system. The built-in scripts can be replaced by the user-provided scripts as long as those files are in the specified directory. Files in this directory are put into a Kubernetes config map, which in turn is mounted to the createDomainScriptsMountPath, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. wlst   createDomainScriptsMountPath Mount path where the create domain scripts are located inside a pod. The create-domain.sh script creates a Kubernetes job to run the script (specified in the createDomainScriptName property) in a Kubernetes pod to create a domain home. Files in the createDomainFilesDir directory are mounted to this location in the pod, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. /u01/weblogic   createDomainScriptName Script that the create domain script uses to create a WebLogic domain. The create-domain.sh script creates a Kubernetes job to run this script to create a domain home. The script is located in the in-pod directory that is specified in the createDomainScriptsMountPath property. If you need to provide your own scripts to create the domain home, instead of using the built-it scripts, you must use this property to set the name of the script that you want the create domain job to run. create-domain-job.sh   domainHome Home directory of the WebCenter Content domain. If not specified, the value is derived from the domainUID as /shared/domains/\u0026lt;domainUID\u0026gt;. /u01/oracle/user_projects/domains/wccinfra   domainPVMountPath Mount path of the domain persistent volume. /u01/oracle/user_projects   domainUID Unique ID that will be used to identify this particular domain. Used as the name of the generated WebLogic domain as well as the name of the Kubernetes domain resource. This ID must be unique across all domains in a Kubernetes cluster. This ID cannot contain any character that is not valid in a Kubernetes service name. wccinfra   exposeAdminNodePort Boolean indicating if the Administration Server is exposed outside of the Kubernetes cluster. false   exposeAdminT3Channel Boolean indicating if the T3 administrative channel is exposed outside the Kubernetes cluster. false   image WebCenter Content Docker image. WebLogic Kubernetes Operator requires Oracle WebCenter Content 12.2.1.4.0 Refer to Obtain the Oracle WebCenter Content Docker image for details on how to obtain or create the image. oracle/wccontent:12.2.1.4.0   imagePullPolicy WebLogic Docker image pull policy. Legal values are IfNotPresent, Always, or Never. IfNotPresent   imagePullSecretName Name of the Kubernetes secret to access the Docker Store to pull the WebLogic Server Docker image. The presence of the secret will be validated when this parameter is specified.    includeServerOutInPodLog Boolean indicating whether to include the server .out to the pod\u0026rsquo;s stdout. true   initialManagedServerReplicas Number of Managed Servers to initially start for the domain. 3   javaOptions Java options for starting the Administration Server and Managed Servers. A Java option can have references to one or more of the following pre-defined variables to obtain WebLogic domain information: $(DOMAIN_NAME), $(DOMAIN_HOME), $(ADMIN_NAME), $(ADMIN_PORT), and $(SERVER_NAME). If sslEnabled is set to true and the WebLogic demo certificate is used, add -Dweblogic.security.SSL.ignoreHostnameVerification=true to allow the Managed Servers to connect to the Administration Server while booting up. The WebLogic generated demo certificate in this environment typically contains a host name that is different from the runtime container\u0026rsquo;s host name. -Dweblogic.StdoutDebugEnabled=false   logHome The in-pod location for the domain log, server logs, server out, and Node Manager log files. If not specified, the value is derived from the domainUID as /shared/logs/\u0026lt;domainUID\u0026gt;. /u01/oracle/user_projects/domains/logs/wccinfra   managedServerNameBase Base string used to generate Managed Server names. ucm_server   managedServerPort Port number for each Managed Server. By default the managedServerPort is 16200 for the ucm_server \u0026amp; managedServerPort is 16250 for the ibr_server. 16200   managedServerSSLPort SSL port number for each Managed Server. By default the managedServerSSLPort is 16201 for the ucm_server \u0026amp; managedServerSSLPort is 16251 for the ibr_server. 16201   namespace Kubernetes namespace in which to create the domain. wccns   persistentVolumeClaimName Name of the persistent volume claim created to host the domain home. If not specified, the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-sample-pvc. wccinfra-domain-pvc   productionModeEnabled Boolean indicating if production mode is enabled for the domain. true   serverStartPolicy Determines which WebLogic Server instances will be started. Legal values are NEVER, IF_NEEDED, ADMIN_ONLY. IF_NEEDED   t3ChannelPort Port for the t3 channel of the NetworkAccessPoint. 30012   t3PublicAddress Public address for the T3 channel. This should be set to the public address of the Kubernetes cluster. This would typically be a load balancer address. For development environments only: In a single server (all-in-one) Kubernetes deployment, this may be set to the address of the master, or at the very least, it must be set to the address of one of the worker nodes. If not provided, the script will attempt to set it to the IP address of the Kubernetes cluster   weblogicCredentialsSecretName Name of the Kubernetes secret for the Administration Server\u0026rsquo;s user name and password. If not specified, then the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-credentials. wccinfra-domain-credentials   weblogicImagePullSecretName Name of the Kubernetes secret for the Docker Store, used to pull the WebLogic Server image.    serverPodCpuRequest, serverPodMemoryRequest, serverPodCpuCLimit, serverPodMemoryLimit The maximum amount of compute resources allowed, and minimum amount of compute resources required, for each server pod. Please refer to the Kubernetes documentation on Managing Compute Resources for Containers for details. Resource requests and resource limits are not specified.   rcuSchemaPrefix The schema prefix to use in the database, for example WCC1. You may wish to make this the same as the domainUID in order to simplify matching domains to their RCU schemas. WCC1   rcuDatabaseURL The database URL. \u0026lt;YOUR DATABASE CONNECTION DETAILS\u0026gt;   rcuCredentialsSecret The Kubernetes secret containing the database credentials. wccinfra-rcu-credentials   ipmEnabled Boolean indicating whether to enable WebCenter Imaging application false   captureEnabled Boolean indicating whether to enable WebCenter Capture application false   adfuiEnabled Boolean indicating whether to enable WebCenter ADF UI application false    Note that the names of the Kubernetes resources in the generated YAML files may be formed with the value of some of the properties specified in the create-inputs.yaml file. Those properties include the adminServerName, clusterName and managedServerNameBase. If those values contain any characters that are invalid in a Kubernetes service name, those characters are converted to valid values in the generated YAML files. For example, an uppercase letter is converted to a lowercase letter and an underscore (\u0026quot;_\u0026quot;) is converted to a hyphen (\u0026quot;-\u0026quot;).\n Note: The properties ipmEnabled, captureEnabled, adfuiEnabled are set to false by default and should be updated to true if you need to enable the respective applications.\n The sample demonstrates how to create the Oracle WebCenter Content domain home and associated Kubernetes resources for that domain. In addition, the sample provides the capability for users to supply their own scripts to create the domain home for other use cases. The generated domain YAML file could also be modified to cover more use cases.\nRun the create domain script Run the create domain script, specifying your inputs file and an output directory to store the generated artifacts:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./create-domain.sh \\ -i create-domain-inputs.yaml \\ -o \u0026lt;path to output-directory\u0026gt; The script will perform the following steps:\n  Create a directory for the generated Kubernetes YAML files for this domain if it does not already exist. The path name is \u0026lt;path to output-directory\u0026gt;/weblogic-domains/\u0026lt;domainUID\u0026gt;. If the directory already exists, its contents must be removed before using this script.\n  Create a Kubernetes job that will start up a utility Oracle WebCenter Content container and run offline WLST scripts to create the domain on the shared storage.\n  Run and wait for the job to finish.\n  Create a Kubernetes domain YAML file, domain.yaml, in the \u0026ldquo;output\u0026rdquo; directory that was created above. This YAML file can be used to create the Kubernetes resource using the kubectl create -f or kubectl apply -f command.\n  Run managed-server-wrapper script, which intrenally applies the domain YAML. This script also applies initial configurations for Managed Server containers and readies Managed Servers for future inter-container communications.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./start-managed-servers-wrapper.sh -o \u0026lt;path_to_output_directory\u0026gt; -p \u0026lt;load_balancer_port\u0026gt;   Create a convenient utility script, delete-domain-job.yaml, to clean up the domain home created by the create script.\n  The default domain created by the script has the following characteristics:\n An Administration Server named AdminServer listening on port 7001. A configured cluster named ucm_cluster of size 3. A configured cluster named ibr_cluster of size 1. A configured cluster named ipm_cluster of size 3. A configured cluster named capture_cluster of size 3. A configured cluster named wccadf_cluster of size 3. Managed Servers, named ucm_cluster listening on port 16200. Managed Servers, named ibr_cluster listening on port 16250. Managed Servers, named ipm_cluster listening on port 16000. Managed Servers, named capture_cluster listening on port 16400. Managed Servers, named wccadf_cluster listening on port 16225. Log files that are located in /shared/logs/\u0026lt;domainUID\u0026gt;.  Verify the results The create domain script will verify that the domain was created, and will report failure if there was any error. However, it may be desirable to manually verify the domain, even if just to gain familiarity with the various Kubernetes objects that were created by the script.\nGenerated YAML files with the default inputs   Click here to see sample content of the generated `domain.yaml`.   $ cat output/weblogic-domains/wccinfra/domain.yaml # Copyright (c) 2021, Oracle and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # apiVersion: \u0026quot;weblogic.oracle/v8\u0026quot; kind: Domain metadata: name: wccinfra namespace: wccns labels: weblogic.domainUID: wccinfra spec: # The WebLogic Domain Home domainHome: /u01/oracle/user_projects/domains/wccinfra maxClusterConcurrentStartup: 1 # The domain home source type # Set to PersistentVolume for domain-in-pv, Image for domain-in-image, or FromModel for model-in-image domainHomeSourceType: PersistentVolume # The WebLogic Server Docker image that WebLogic Kubernetes Operator uses to start the domain image: \u0026quot;oracle/wccontent:12.2.1.4.0\u0026quot; # imagePullPolicy defaults to \u0026quot;Always\u0026quot; if image version is :latest imagePullPolicy: \u0026quot;IfNotPresent\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: # Identify which Secret contains the WebLogic Admin credentials (note that there is an example of # how to create that Secret at the end of this file) webLogicCredentialsSecret: name: wccinfra-domain-credentials # Whether to include the server out file into the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable log home logHomeEnabled: true # Whether to write HTTP access log file to log home httpAccessLogInLogHome: true # The in-pod location for domain log, server logs, server out, and Node Manager log files logHome: /u01/oracle/user_projects/domains/logs/wccinfra # An (optional) in-pod location for data storage of default and custom file stores. # If not specified or the value is either not set or empty (e.g. dataHome: \u0026quot;\u0026quot;) then the # data storage directories are determined from the WebLogic domain home configuration. dataHome: \u0026quot;\u0026quot; # serverStartPolicy legal values are \u0026quot;NEVER\u0026quot;, \u0026quot;IF_NEEDED\u0026quot;, or \u0026quot;ADMIN_ONLY\u0026quot; # This determines which WebLogic Servers the WebLogic Kubernetes Operator will start up when it discovers this Domain # - \u0026quot;NEVER\u0026quot; will not start any server in the domain # - \u0026quot;ADMIN_ONLY\u0026quot; will start up only the administration server (no managed servers will be started) # - \u0026quot;IF_NEEDED\u0026quot; will start all non-clustered servers, including the administration server and clustered servers up to the replica count serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; serverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026quot;-Dweblogic.StdoutDebugEnabled=false\u0026quot; - name: USER_MEM_ARGS value: \u0026quot;-Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx512m \u0026quot; volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume # adminServer is used to configure the desired behavior for starting the administration server. adminServer: # serverStartState legal values are \u0026quot;RUNNING\u0026quot; or \u0026quot;ADMIN\u0026quot; # \u0026quot;RUNNING\u0026quot; means the listed server will be started up to \u0026quot;RUNNING\u0026quot; mode # \u0026quot;ADMIN\u0026quot; means the listed server will be start up to \u0026quot;ADMIN\u0026quot; mode serverStartState: \u0026quot;RUNNING\u0026quot; adminService: channels: # The Admin Server's NodePort - channelName: default nodePort: 30701 # Uncomment to export the T3Channel as a service # - channelName: T3Channel # clusters is used to configure the desired behavior for starting member servers of a cluster. # If you use this entry, then the rules will be applied to ALL servers that are members of the named clusters. clusters: - clusterName: ibr_cluster serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 1 serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; # The number of managed servers to start for unlisted clusters # replicas: 1 # Istio # configuration: # istio: # enabled: # readinessPort: - clusterName: ucm_cluster clusterService: annotations: traefik.ingress.kubernetes.io/affinity: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/service.sticky.cookie: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 3 serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; # The number of managed servers to start for unlisted clusters # replicas: 1 - clusterName: ipm_cluster clusterService: annotations: traefik.ingress.kubernetes.io/affinity: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/service.sticky.cookie: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 3 # The number of managed servers to start for unlisted clusters # replicas: 1 - clusterName: capture_cluster clusterService: annotations: traefik.ingress.kubernetes.io/affinity: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/service.sticky.cookie: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 3 # The number of managed servers to start for unlisted clusters # replicas: 1 - clusterName: wccadf_cluster clusterService: annotations: traefik.ingress.kubernetes.io/affinity: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/service.sticky.cookie: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/session-cookie-name: WCCSID serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 3 # The number of managed servers to start for unlisted clusters # replicas: 1    Verify the domain To confirm that the domain was created, enter the following command:\n$ kubectl describe domain DOMAINUID -n NAMESPACE Replace DOMAINUID with the domainUID and NAMESPACE with the actual namespace.\n  Click here to see a sample domain description.   $ kubectl describe domain wccinfra -n wccns Name: wccinfra Namespace: wccns Labels: weblogic.domainUID=wccinfra Annotations: API Version: weblogic.oracle/v8 Kind: Domain Metadata: Creation Timestamp: 2020-11-23T12:48:13Z Generation: 7 Managed Fields: API Version: weblogic.oracle/v8 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:kubectl.kubernetes.io/last-applied-configuration: f:labels: .: f:weblogic.domainUID: Manager: kubectl Operation: Update Time: 2020-11-23T13:50:28Z API Version: weblogic.oracle/v8 Fields Type: FieldsV1 fieldsV1: f:status: .: f:clusters: f:conditions: f:servers: f:startTime: Manager: OpenAPI-Generator Operation: Update Time: 2020-12-03T10:20:52Z Resource Version: 18267402 Self Link: /apis/weblogic.oracle/v8/namespaces/wccns/domains/wccinfra UID: 1a866c30-9b29-4281-bd2b-df80914efdff Spec: Admin Server: Admin Service: Channels: Channel Name: default Node Port: 30701 Server Start State: RUNNING Clusters: Cluster Name: ibr_cluster Replicas: 1 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start Policy: IF_NEEDED Server Start State: RUNNING Cluster Name: ucm_cluster Cluster Service: Annotations: traefik.ingress.kubernetes.io/affinity: true traefik.ingress.kubernetes.io/service.sticky.cookie: true traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID Replicas: 3 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start Policy: IF_NEEDED Server Start State: RUNNING Cluster Name: ipm_cluster Cluster Service: Annotations: traefik.ingress.kubernetes.io/affinity: true traefik.ingress.kubernetes.io/service.sticky.cookie: true traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID Replicas: 3 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start State: RUNNING Cluster Name: capture_cluster Cluster Service: Annotations: traefik.ingress.kubernetes.io/affinity: true traefik.ingress.kubernetes.io/service.sticky.cookie: true traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID Replicas: 3 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start State: RUNNING Cluster Name: wccadf_cluster Cluster Service: Annotations: traefik.ingress.kubernetes.io/affinity: true traefik.ingress.kubernetes.io/service.sticky.cookie: true traefik.ingress.kubernetes.io/session-cookie-name: WCCSID Replicas: 3 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start State: RUNNING Data Home: Domain Home: /u01/oracle/user_projects/domains/wccinfra Domain Home Source Type: PersistentVolume Http Access Log In Log Home: true Image: oracle/wccontent_ora_final_it:12.2.1.4.0 Image Pull Policy: IfNotPresent Include Server Out In Pod Log: true Log Home: /u01/oracle/user_projects/domains/logs/wccinfra Log Home Enabled: true Max Cluster Concurrent Startup: 1 Server Pod: Env: Name: JAVA_OPTIONS Value: -Dweblogic.StdoutDebugEnabled=false Name: USER_MEM_ARGS Value: -Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx512m Volume Mounts: Mount Path: /u01/oracle/user_projects/domains Name: weblogic-domain-storage-volume Volumes: Name: weblogic-domain-storage-volume Persistent Volume Claim: Claim Name: wccinfra-domain-pvc Server Start Policy: IF_NEEDED Web Logic Credentials Secret: Name: wccinfra-domain-credentials Status: Clusters: Cluster Name: ibr_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 1 Replicas: 1 Replicas Goal: 1 Cluster Name: ucm_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 3 Replicas: 3 Replicas Goal: 3 Cluster Name: ipm_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 3 Replicas: 3 Replicas Goal: 3 Cluster Name: capture_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 3 Replicas: 3 Replicas Goal: 3 Cluster Name: wccadf_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 3 Replicas: 3 Replicas Goal: 3 Conditions: Last Transition Time: 2020-11-23T13:58:41.070Z Reason: ServersReady Status: True Type: Available Servers: Desired State: RUNNING Health: Activation Time: 2020-11-25T16:55:24.930Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: AdminServer State: RUNNING Cluster Name: ibr_cluster Desired State: RUNNING Health: Activation Time: 2020-11-30T12:23:27.603Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: ibr_server1 State: RUNNING Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server2 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server3 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server4 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server5 Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2020-12-02T14:10:37.992Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: ucm_server1 State: RUNNING Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2020-12-01T04:51:19.886Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: ucm_server2 State: RUNNING Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm_server3 Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm_server4 Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm_server5 Cluster Name: ipm_cluster Desired State: RUNNING Health: Activation Time: 2020-12-01T04:51:19.886Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: ipm_server1 State: RUNNING Cluster Name: ipm_cluster Desired State: SHUTDOWN Server Name: ipm_server2 Cluster Name: ipm_cluster Desired State: SHUTDOWN Server Name: ipm_server3 Cluster Name: ipm_cluster Desired State: SHUTDOWN Server Name: ipm_server4 Cluster Name: ipm_cluster Desired State: SHUTDOWN Server Name: ipm_server5 Cluster Name: capture_cluster Desired State: RUNNING Health: Activation Time: 2020-12-01T04:51:19.886Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: capture_server1 State: RUNNING Cluster Name: capture_cluster Desired State: SHUTDOWN Server Name: capture_server2 Cluster Name: capture_cluster Desired State: SHUTDOWN Server Name: capture_server3 Cluster Name: capture_cluster Desired State: SHUTDOWN Server Name: capture_server4 Cluster Name: capture_cluster Desired State: SHUTDOWN Server Name: capture_server5 Cluster Name: wccadf_cluster Desired State: RUNNING Health: Activation Time: 2020-12-01T04:51:19.886Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: MyNodeName Server Name: wccadf_server1 State: RUNNING Cluster Name: wccadf_cluster Desired State: SHUTDOWN Server Name: wccadf_server2 Cluster Name: wccadf_cluster Desired State: SHUTDOWN Server Name: wccadf_server3 Cluster Name: wccadf_cluster Desired State: SHUTDOWN Server Name: wccadf_server4 Cluster Name: wccadf_cluster Desired State: SHUTDOWN Server Name: wccadf_server5 Start Time: 2020-11-23T12:48:13.756Z Events: \u0026lt;none\u0026gt;    In the Status section of the output, the available servers and clusters are listed. Note that if this command is issued soon after the script finishes, there may be no servers available yet, or perhaps only the Administration Server but no Managed Servers. WebLogic Kubernetes Operator will start up the Administration Server first and wait for it to become ready before starting the Managed Servers.\nVerify the pods Enter the following command to see the pods running the servers:\n$ kubectl get pods -n NAMESPACE Here is an example of the output of this command. You can verify that an Administration Server and Managed Servers for ucm, ibr, ipm, capture and wccadf cluster are running.\n$ kubectl get pod -n wccns NAME READY STATUS RESTARTS AGE rcu 1/1 Running 0 78d wccinfra-adminserver 1/1 Running 0 9d wccinfra-create-fmw-infra-sample-domain-job-l8r9d 0/1 Completed 0 9d wccinfra-ibr-server1 1/1 Running 0 9d wccinfra-ucm-server1 1/1 Running 0 9d wccinfra-ucm-server2 1/1 Running 0 9d wccinfra-ucm-server3 1/1 Running 0 9d wccinfra-ipm-server1 1/1 Running 0 9d wccinfra-ipm-server2 1/1 Running 0 9d wccinfra-ipm-server3 1/1 Running 0 9d wccinfra-capture-server1 1/1 Running 0 9d wccinfra-capture-server2 1/1 Running 0 9d wccinfra-capture-server3 1/1 Running 0 9d wccinfra-wccadf-server1 1/1 Running 0 9d wccinfra-wccadf-server2 1/1 Running 0 9d wccinfra-wccadf-server3 1/1 Running 0 9d Verify the services Enter the following command to see the services for the domain:\n$ kubectl get services -n NAMESPACE Here is an example of the output of this command.\n  Click here to see a sample list of services.   $ kubectl get services -n wccns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE wccinfra-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 9d wccinfra-adminserver-external NodePort 10.104.100.193 \u0026lt;none\u0026gt; 7001:30701/TCP 9d wccinfra-cluster-ibr-cluster ClusterIP 10.98.100.212 \u0026lt;none\u0026gt; 16250/TCP 114s wccinfra-cluster-ucm-cluster ClusterIP 10.108.47.178 \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-cluster-ipm-cluster ClusterIP 10.108.217.111 \u0026lt;none\u0026gt; 16000/TCP 9d wccinfra-cluster-capture-cluster ClusterIP 10.110.193.252 \u0026lt;none\u0026gt; 16400/TCP 9d wccinfra-cluster-wccadf-cluster ClusterIP 10.109.191.247 \u0026lt;none\u0026gt; 16225/TCP 9d wccinfra-ibr-server1 ClusterIP None \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server2 ClusterIP 10.97.253.44 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server3 ClusterIP 10.110.183.48 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server4 ClusterIP 10.108.228.158 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server5 ClusterIP 10.101.29.140 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ucm-server1 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server2 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server3 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server4 ClusterIP 10.109.25.242 \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server5 ClusterIP 10.109.193.26 \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ipm-server1 ClusterIP None \u0026lt;none\u0026gt; 16000/TCP 9d wccinfra-ipm-server2 ClusterIP None \u0026lt;none\u0026gt; 16000/TCP 9d wccinfra-ipm-server3 ClusterIP None \u0026lt;none\u0026gt; 16000/TCP 9d wccinfra-ipm-server4 ClusterIP 10.111.215.108 \u0026lt;none\u0026gt; 16000/TCP 9d wccinfra-ipm-server5 ClusterIP 10.109.220.10 \u0026lt;none\u0026gt; 16000/TCP 9d wccinfra-capture-server1 ClusterIP None \u0026lt;none\u0026gt; 16400/TCP 9d wccinfra-capture-server2 ClusterIP None \u0026lt;none\u0026gt; 16400/TCP 9d wccinfra-capture-server3 ClusterIP None \u0026lt;none\u0026gt; 16400/TCP 9d wccinfra-capture-server4 ClusterIP 10.109.72.216 \u0026lt;none\u0026gt; 16400/TCP 9d wccinfra-capture-server5 ClusterIP 10.102.90.234 \u0026lt;none\u0026gt; 16400/TCP 9d wccinfra-wccadf-server1 ClusterIP None \u0026lt;none\u0026gt; 16225/TCP 9d wccinfra-wccadf-server2 ClusterIP None \u0026lt;none\u0026gt; 16225/TCP 9d wccinfra-wccadf-server3 ClusterIP None \u0026lt;none\u0026gt; 16225/TCP 9d wccinfra-wccadf-server4 ClusterIP 10.99.91.229 \u0026lt;none\u0026gt; 16225/TCP 9d wccinfra-wccadf-server5 ClusterIP 10.105.114.38 \u0026lt;none\u0026gt; 16225/TCP 9d    Configure an additional mount or shared space to a domain for Imaging and Capture Optionally, if you want to configure an additional mount or shared space to a domain, for WebCenter Imaging and WebCenter Capture applications for file imports, refer to the Configure an Additional Mount or Shared-Space to a Domain for Imaging and Capture.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/appendix/docker-k8s-hardening/",
	"title": "Security hardening",
	"tags": [],
	"description": "Review resources for the Docker and Kubernetes cluster hardening.",
	"content": "Securing a Kubernetes cluster involves hardening on multiple fronts - securing the API servers, etcd, nodes, container images, container run-time, and the cluster network. Apply principles of defense in depth, principle of least privilege, and minimize the attack surface. Use security tools such as Kube-Bench to verify the cluster\u0026rsquo;s security posture. Since Kubernetes is evolving rapidly refer to Kubernetes Security Overview for the latest information on securing a Kubernetes cluster. Also ensure the deployed Docker containers follow the Docker Security guidance.\nThis section provides references on how to securely configure Docker and Kubernetes.\nReferences   Docker hardening\n https://docs.docker.com/engine/security/security/ https://blog.aquasec.com/docker-security-best-practices    Kubernetes hardening\n https://kubernetes.io/docs/concepts/security/overview/ https://kubernetes.io/docs/concepts/security/pod-security-standards/ https://blogs.oracle.com/developers/5-best-practices-for-kubernetes-security    Security best practices for Oracle WebLogic Server Running in Docker and Kubernetes\n https://blogs.oracle.com/weblogicserver/security-best-practices-for-weblogic-server-running-in-docker-and-kubernetes    "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/elasticsearch-integration/",
	"title": "Elasticsearch integration for logs",
	"tags": [],
	"description": "Monitor an Oracle WebCenter Sites domain and publish the WebLogic Server logs to Elasticsearch.",
	"content": "1. Integrate Elasticsearch to WebLogic Kubernetes Operator For reference information, see Elasticsearch integration for the WebLogic Kubernetes Operator.\nTo enable elasticsearch integration, you must edit file kubernetes/charts/weblogic-operator/values.yaml before deploying the WebLogic Kubernetes Operator.\n# elkIntegrationEnabled specifies whether or not ELK integration is enabled. elkIntegrationEnabled: true # logStashImage specifies the docker image containing logstash. # This parameter is ignored if 'elkIntegrationEnabled' is false. logStashImage: \u0026quot;logstash:6.6.0\u0026quot; # elasticSearchHost specifies the hostname of where Elasticsearch is running. # This parameter is ignored if 'elkIntegrationEnabled' is false. elasticSearchHost: \u0026quot;elasticsearch.default.svc.cluster.local\u0026quot; # elasticSearchPort specifies the port number of where Elasticsearch is running. # This parameter is ignored if 'elkIntegrationEnabled' is false. elasticSearchPort: 9200 After you\u0026rsquo;ve deployed WebLogic Kubernetes Operator and made the above changes, the weblogic-operator pod will have additional Logstash container. The Logstash container will push the weblogic-operator logs to the configured Elasticsearch server.\n2. Publish WebLogic Server and WebCenter Content Logs using Logstash Pod You can publish the WebLogic Server logs to Elasticsearch Server using Logstash pod. This Logstash pod must have access to the shared domain home. For the WebCenter Content wccinfra, you can use the persistent volume of the domain home in the Logstash pod. The steps to create the Logstash pod are as follows:\nGet the persistent volume details of the domain home of the WebLogic Server(s). The following command will list the persistent volume details in the namespace - \u0026ldquo;wccns\u0026rdquo;:\n$ kubectl get pv -n wccns NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE wccinfra-domain-pv 10Gi RWX Retain Bound wccns/wccinfra-domain-pvc wccinfra-domain-storage-class 33d Create the deployment yaml for Logstash pod. The mounted persistent volume of the domain home will provide access to the WebLogic server logs to Logstash pod. Given below is a sample Logstash deployment yaml.\napiVersion: apps/v1 kind: Deployment metadata: name: logstash-wls namespace: wccns spec: selector: matchLabels: app: \u0026quot;logstash-wls\u0026quot; template: # create pods using pod definition in this template metadata: labels: app: logstash-wls spec: volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc - name: shared-logs emptyDir: {} containers: - name: logstash image: logstash:6.6.0 command: [\u0026quot;/bin/sh\u0026quot;] args: [\u0026quot;/usr/share/logstash/bin/logstash\u0026quot;, \u0026quot;-f\u0026quot;, \u0026quot;/u01/oracle/user_projects/domains/logstash.conf\u0026quot;] imagePullPolicy: IfNotPresent volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume - name: shared-logs mountPath: /shared-logs ports: - containerPort: 5044 name: logstash Sample Logstash configuration file is located at kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.conf\n$ vi kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.conf input { file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/AdminServer.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ucm_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ibr_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ipm_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/capture_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/wccadf_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/AdminServer.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ucm_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ibr_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ipm_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/capture_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/wccadf_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/AdminServer/logs/AdminServer-diagnostic.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/ucm_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/ibr_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/ipm_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/capture_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/wccadf_server*.log\u0026quot; start_position =\u0026gt; beginning } } filter { grok { match =\u0026gt; [ \u0026quot;message\u0026quot;, \u0026quot;\u0026lt;%{DATA:log_timestamp}\u0026gt; \u0026lt;%{WORD:log_level}\u0026gt; \u0026lt;%{WORD:thread}\u0026gt; \u0026lt;%{HOSTNAME:hostname}\u0026gt; \u0026lt;%{HOSTNAME:servername}\u0026gt; \u0026lt;%{DATA:timer}\u0026gt; \u0026lt;\u0026lt;%{DATA:kernel}\u0026gt;\u0026gt; \u0026lt;\u0026gt; \u0026lt;%{DATA:uuid}\u0026gt; \u0026lt;%{NUMBER:timestamp}\u0026gt; \u0026lt;%{DATA:misc}\u0026gt; \u0026lt;%{DATA:log_number}\u0026gt; \u0026lt;%{DATA:log_message}\u0026gt;\u0026quot; ] } } output { elasticsearch { hosts =\u0026gt; [\u0026quot;elasticsearch.default.svc.cluster.local:9200\u0026quot;] } } Here ** means that all ucm_server.log and ibr_server.log from any servers under wccinfra will be pushed to Logstash.\n$ kubectl cp kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.conf wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/logstash.conf Deploy Logstash pod After you have created the Logstash deployment yaml and Logstash configuration file, deploy Logstash using following command:\n$ kubectl create -f kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.yaml 3. Test the deployment of Elasticsearch and Kibana The WebLogic Kubernetes Operator also provides a sample deployment of Elasticsearch and Kibana for testing purpose. You can deploy Elasticsearch and Kibana on the Kubernetes cluster as shown below:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/ $ kubectl create -f kubernetes/samples/scripts/elasticsearch-and-kibana/elasticsearch_and_kibana.yaml Get the Kibana dashboard port information as shown below: Wait for pods to start:\n-bash-4.2$ kubectl get pods -w NAME READY STATUS RESTARTS AGE elasticsearch-8bdb7cf54-mjs6s 1/1 Running 0 4m3s kibana-dbf8964b6-n8rcj 1/1 Running 0 4m3s -bash-4.2$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE elasticsearch ClusterIP 10.105.205.157 \u0026lt;none\u0026gt; 9200/TCP,9300/TCP 10d kibana NodePort 10.98.104.41 \u0026lt;none\u0026gt; 5601:30412/TCP 10d kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 42d You can access the Kibana dashboard at http://\u0026lt;your_hostname\u0026gt;:30412/. In our example, the node port would be 30412.\nCreate an Index Pattern in Kibana Create an index pattern logstash-* in Kibana \u0026gt; Management. After the servers are started, you will see the log data in the Kibana dashboard.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/configure-load-balancer/",
	"title": "Set up a load balancer",
	"tags": [],
	"description": "Configure different load balancers for Oracle WebCenter Content domains.",
	"content": "WebLogic Kubernetes Operator supports ingress-based load balancers such as Traefik.\n Traefik  Configure the ingress-based Traefik load balancer for Oracle WebCenter Content domains.\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/patch_and_upgrade/upgrade-k8s-cluster/",
	"title": "Upgrade a Kubernetes cluster",
	"tags": [],
	"description": "Upgrade the underlying Kubernetes cluster version in a running WebCenter Content Kubernetes environment.",
	"content": "These instructions describe how to upgrade a Kubernetes cluster created using kubeadm on which an Oracle WebCenter Content domain is deployed. A rolling upgrade approach is used to upgrade nodes (master and worker) of the Kubernetes cluster.\nIt is expected that there will be a down time during the upgrade of the Kubernetes cluster as the nodes need to be drained as part of the upgrade process.\n Prerequisites  Review Prerequisites and ensure that your Kubernetes cluster is ready for upgrade. Make sure your environment meets all prerequisites. Make sure the database used for the WebCenter Content domain deployment is up and running during the upgrade process.  Upgrade the Kubernetes version An upgrade of Kubernetes is supported from one MINOR version to the next MINOR version, or between PATCH versions of the same MINOR. For example, you can upgrade from 1.x to 1.x+1, but not from 1.x to 1.x+2. To upgrade a Kubernetes version, first all the master nodes of the Kubernetes cluster must be upgraded sequentially, followed by the sequential upgrade of each worker node.\n See here for Kubernetes official documentation to upgrade from v1.14.x to v1.15.x. See here for Kubernetes official documentation to upgrade from v1.15.x to v1.16.x. See here for Kubernetes official documentation to upgrade from v1.16.x to v1.17.x. See here for Kubernetes official documentation to upgrade from v1.17.x to v1.18.x.  "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/create-wccontent-domains/",
	"title": "Create Oracle WebCenter Content domain",
	"tags": [],
	"description": "Create Oracle WebCenter Content domain on Oracle Kubernetes Engine (OKE).",
	"content": "Contents  Run the create domain script Create Container Clusters (OKE) Verify the results Verify the pods Verify the services Expose service for IBR intradoc port  Run the create domain script Run the create domain script, specifying your inputs file and an output directory to store the generated artifacts:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./create-domain.sh \\ -i create-domain-inputs.yaml \\ -o \u0026lt;path to output-directory\u0026gt; The script will perform the following steps:\n  Create a directory for the generated Kubernetes YAML files for this domain if it does not already exist. The path name is \u0026lt;path to output-directory\u0026gt;/weblogic-domains/\u0026lt;domainUID\u0026gt;. If the directory already exists, its contents must be removed before using this script.\n  Create a Kubernetes job that will start up a utility Oracle WebCenter Content container and run offline WLST scripts to create the domain on the shared storage.\n  Run and wait for the job to finish.\n  Create a Kubernetes domain YAML file, domain.yaml, in the \u0026ldquo;output\u0026rdquo; directory that was created above. This YAML file can be used to create the Kubernetes resource using the kubectl create -f or kubectl apply -f command.\n  Run oke-start-managed-server-wrapper.sh script, which intrenally applies the domain YAML. This script also applies initial configurations for Managed Server containers and readies Managed Servers for future inter-container communications.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./oke-start-managed-servers-wrapper.sh -o \u0026lt;path_to_output_directory\u0026gt; -l \u0026lt;load_balancer_external_ip\u0026gt; -p \u0026lt;load_balancer_port\u0026gt;   Verify the results The create domain script will verify that the domain was created, and will report failure if there was any error. However, it may be desirable to manually verify the domain, even if just to gain familiarity with the various Kubernetes objects that were created by the script.\nGenerated YAML files with the default inputs   Click here to see sample content of the generated `domain.yaml`.   $ cat output/weblogic-domains/wccinfra/domain.yaml # Copyright (c) 2017, 2021, Oracle and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # apiVersion: \u0026quot;weblogic.oracle/v8\u0026quot; kind: Domain metadata: name: wccinfra namespace: wccns labels: weblogic.domainUID: wccinfra spec: # The WebLogic Domain Home domainHome: /u01/oracle/user_projects/domains/wccinfra maxClusterConcurrentStartup: 1 # The domain home source type # Set to PersistentVolume for domain-in-pv, Image for domain-in-image, or FromModel for model-in-image domainHomeSourceType: PersistentVolume # The WebLogic Server image that the WebLogic Kubernetes Operator uses to start the domain image: \u0026quot;phx.ocir.io/xxxxxxxxxx/oracle/wccontent/oracle/wccontent:x.x.x.x\u0026quot; # imagePullPolicy defaults to \u0026quot;Always\u0026quot; if image version is :latest imagePullPolicy: \u0026quot;IfNotPresent\u0026quot; # Identify which Secret contains the credentials for pulling an image imagePullSecrets: - name: image-secret # Identify which Secret contains the WebLogic Admin credentials (note that there is an example of # how to create that Secret at the end of this file) webLogicCredentialsSecret: name: wccinfra-domain-credentials # Whether to include the server out file into the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable log home logHomeEnabled: true # Whether to write HTTP access log file to log home httpAccessLogInLogHome: true # The in-pod location for domain log, server logs, server out, introspector out, and Node Manager log files logHome: /u01/oracle/user_projects/domains/logs/wccinfra # An (optional) in-pod location for data storage of default and custom file stores. # If not specified or the value is either not set or empty (e.g. dataHome: \u0026quot;\u0026quot;) then the # data storage directories are determined from the WebLogic domain home configuration. dataHome: \u0026quot;\u0026quot; # serverStartPolicy legal values are \u0026quot;NEVER\u0026quot;, \u0026quot;IF_NEEDED\u0026quot;, or \u0026quot;ADMIN_ONLY\u0026quot; # This determines which WebLogic Servers the WebLogic Kubernetes Operator will start up when it discovers this Domain # - \u0026quot;NEVER\u0026quot; will not start any server in the domain # - \u0026quot;ADMIN_ONLY\u0026quot; will start up only the administration server (no managed servers will be started) # - \u0026quot;IF_NEEDED\u0026quot; will start all non-clustered servers, including the administration server and clustered servers up to the replica count serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; serverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026quot;-Dweblogic.StdoutDebugEnabled=false\u0026quot; - name: USER_MEM_ARGS value: \u0026quot;-Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx1024m \u0026quot; volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume # adminServer is used to configure the desired behavior for starting the administration server. adminServer: # serverStartState legal values are \u0026quot;RUNNING\u0026quot; or \u0026quot;ADMIN\u0026quot; # \u0026quot;RUNNING\u0026quot; means the listed server will be started up to \u0026quot;RUNNING\u0026quot; mode # \u0026quot;ADMIN\u0026quot; means the listed server will be start up to \u0026quot;ADMIN\u0026quot; mode serverStartState: \u0026quot;RUNNING\u0026quot; # adminService: # channels: # The Admin Server's NodePort # - channelName: default # nodePort: 30701 # Uncomment to export the T3Channel as a service # - channelName: T3Channel # clusters is used to configure the desired behavior for starting member servers of a cluster. # If you use this entry, then the rules will be applied to ALL servers that are members of the named clusters. clusters: - clusterName: ibr_cluster serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 1 # The number of managed servers to start for unlisted clusters # replicas: 1 # Istio # configuration: # istio: # enabled: # readinessPort: - clusterName: ucm_cluster clusterService: annotations: traefik.ingress.kubernetes.io/affinity: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/service.sticky.cookie: \u0026quot;true\u0026quot; traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 3 # The number of managed servers to start for unlisted clusters # replicas: 1    Verify the domain To confirm that the domain was created, enter the following command:\n$ kubectl describe domain DOMAINUID -n NAMESPACE Replace DOMAINUID with the domainUID and NAMESPACE with the actual namespace.\n  Click here to see a sample domain description.   [opc@bastionhost domain-home-on-pv]$ kubectl describe domain wccinfra -n wccns Name: wccinfra Namespace: wccns Labels: weblogic.domainUID=wccinfra Annotations: kubectl.kubernetes.io/last-applied-configuration: {\u0026quot;apiVersion\u0026quot;:\u0026quot;weblogic.oracle/v8\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Domain\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;labels\u0026quot;:{\u0026quot;weblogic.domainUID\u0026quot;:\u0026quot;wccinfra\u0026quot;},\u0026quot;name\u0026quot;:\u0026quot;wccinfr... API Version: weblogic.oracle/v8 Kind: Domain Metadata: Creation Timestamp: 2021-08-24T12:26:19Z Generation: 33 Managed Fields: API Version: weblogic.oracle/v8 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:kubectl.kubernetes.io/last-applied-configuration: f:labels: .: f:weblogic.domainUID: Manager: kubectl Operation: Update Time: 2021-09-30T10:56:07Z API Version: weblogic.oracle/v8 Fields Type: FieldsV1 fieldsV1: f:status: .: f:clusters: f:conditions: f:introspectJobFailureCount: f:servers: f:startTime: Manager: Kubernetes Java Client Operation: Update Time: 2021-10-04T20:06:17Z Resource Version: 115422662 Self Link: /apis/weblogic.oracle/v8/namespaces/wccns/domains/wccinfra UID: e283c968-b80b-404b-aa1e-711080d7cc38 Spec: Admin Server: Server Start State: RUNNING Clusters: Cluster Name: ibr_cluster Replicas: 1 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start State: RUNNING Cluster Name: ucm_cluster Cluster Service: Annotations: traefik.ingress.kubernetes.io/affinity: true traefik.ingress.kubernetes.io/service.sticky.cookie: true traefik.ingress.kubernetes.io/session-cookie-name: JSESSIONID Replicas: 3 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start State: RUNNING Data Home: Domain Home: /u01/oracle/user_projects/domains/wccinfra Domain Home Source Type: PersistentVolume Http Access Log In Log Home: true Image: phx.ocir.io/xxxxxxxxxx/oracle/wccontent:x.x.x.x Image Pull Policy: IfNotPresent Image Pull Secrets: Name: image-secret Include Server Out In Pod Log: true Log Home: /u01/oracle/user_projects/domains/logs/wccinfra Log Home Enabled: true Max Cluster Concurrent Startup: 1 Server Pod: Env: Name: JAVA_OPTIONS Value: -Dweblogic.StdoutDebugEnabled=false Name: USER_MEM_ARGS Value: -Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx1024m Volume Mounts: Mount Path: /u01/oracle/user_projects/domains Name: weblogic-domain-storage-volume Volumes: Name: weblogic-domain-storage-volume Persistent Volume Claim: Claim Name: wccinfra-domain-pvc Server Start Policy: IF_NEEDED Web Logic Credentials Secret: Name: wccinfra-domain-credentials Status: Clusters: Cluster Name: ibr_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 1 Replicas: 1 Replicas Goal: 1 Cluster Name: ucm_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 3 Replicas: 3 Replicas Goal: 3 Conditions: Last Transition Time: 2021-09-30T11:04:35.889547Z Reason: ServersReady Status: True Type: Available Introspect Job Failure Count: 0 Servers: Desired State: RUNNING Health: Activation Time: 2021-09-30T10:58:38.381000Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: 10.0.10.135 Server Name: adminserver State: RUNNING Cluster Name: ibr_cluster Desired State: RUNNING Health: Activation Time: 2021-09-30T11:01:09.987000Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: 10.0.10.135 Server Name: ibr_server1 State: RUNNING Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server2 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server3 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server4 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server5 Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2021-09-30T11:00:36.369000Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: 10.0.10.142 Server Name: ucm-server1 State: RUNNING Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2021-09-30T11:02:35.448000Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: 10.0.10.135 Server Name: ucm-server2 State: RUNNING Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2021-09-30T11:04:32.314000Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: 10.0.10.142 Server Name: ucm-server3 State: RUNNING Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm-server4 Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm-server5 Start Time: 2021-08-24T12:26:20.033714Z Events: \u0026lt;none\u0026gt;    In the Status section of the output, the available servers and clusters are listed. Note that if this command is issued soon after the script finishes, there may be no servers available yet, or perhaps only the Administration Server but no Managed Servers. The WebLogic Kubernetes Operator will start up the Administration Server first and wait for it to become ready before starting the Managed Servers.\nVerify the pods Enter the following command to see the pods running the servers:\n$ kubectl get pods -n NAMESPACE Here is an example of the output of this command. You can verify that an Administration Server and Managed Servers for ucm and ibr cluster are running.\n$ kubectl get pod -n wccns NAME READY STATUS RESTARTS AGE rcu 1/1 Running 0 54d wccinfra-adminserver 1/1 Running 0 18d wccinfra-create-fmw-infra-sample-domain-job-xqnn4 0/1 Completed 0 54d wccinfra-ibr-server1 1/1 Running 0 18d wccinfra-ucm-server1 1/1 Running 0 18d wccinfra-ucm-server2 1/1 Running 0 18d wccinfra-ucm-server3 1/1 Running 0 18d Verify the services Enter the following command to see the services for the domain:\n$ kubectl get services -n NAMESPACE Here is an example of the output of this command.\n  Click here to see a sample list of services.   $ kubectl get services -n wccns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE oracle-db LoadBalancer 10.96.74.187 123.45.xxx.xxx 1521:30011/TCP 80d wccinfra-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 18d wccinfra-cluster-ibr-cluster ClusterIP 10.96.206.89 \u0026lt;none\u0026gt; 16250/TCP 119s wccinfra-cluster-ucm-cluster ClusterIP 10.96.180.150 \u0026lt;none\u0026gt; 16200/TCP 54d wccinfra-ibr-server1 ClusterIP None \u0026lt;none\u0026gt; 16250/TCP 18d wccinfra-ibr-server2 ClusterIP 10.96.185.209 \u0026lt;none\u0026gt; 16250/TCP 18d wccinfra-ibr-server3 ClusterIP 10.96.43.99 \u0026lt;none\u0026gt; 16250/TCP 18d wccinfra-ibr-server4 ClusterIP 10.96.77.52 \u0026lt;none\u0026gt; 16250/TCP 18d wccinfra-ibr-server5 ClusterIP 10.96.63.174 \u0026lt;none\u0026gt; 16250/TCP 18d wccinfra-ucm-server1 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 18d wccinfra-ucm-server2 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 18d wccinfra-ucm-server3 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 18d wccinfra-ucm-server4 ClusterIP 10.96.141.251 \u0026lt;none\u0026gt; 16200/TCP 18d wccinfra-ucm-server5 ClusterIP 10.96.85.52 \u0026lt;none\u0026gt; 16200/TCP 18d    Expose service for IBR intradoc port  Get the IP address for the node, hosting ibr managed server pod. In this sample, node running wccinfra-ibr-server1 pod has ip \u0026lsquo;10.0.10.xx\u0026rsquo; $ kubectl get pods -n wccns -o wide #output NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES wccinfra-adminserver 1/1 Running 0 4h50m 10.244.0.150 10.0.10.xxx \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; wccinfra-create-fmw-infra-sample-domain-job-zbsxr 0/1 Completed 0 7d22h 10.244.1.25 10.0.10.xx \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; wccinfra-ibr-server1 1/1 Running 0 4h48m 10.244.1.38 10.0.10.xx \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; wccinfra-ucm-server1 1/1 Running 0 4h48m 10.244.1.39 10.0.10.xx \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; wccinfra-ucm-server2 1/1 Running 0 4h46m 10.244.0.151 10.0.10.xxx \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; wccinfra-ucm-server3 1/1 Running 0 4h44m 10.244.1.40 10.0.10.xx \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  Expose service for IBR intradoc port $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ kubectl expose service/wccinfra-cluster-ibr-cluster --name wccinfra-cluster-ibr-cluster-ext --port=5555 --target-port=5555 --external-ip=\u0026lt;your-ibr-managed-server-node-ip\u0026gt; -n wccns #sample $ kubectl expose service/wccinfra-cluster-ibr-cluster --name wccinfra-cluster-ibr-cluster-ext --port=5555 --target-port=5555 --external-ip=10.0.10.xx -n wccns $ kubectl get service/wccinfra-cluster-ibr-cluster-ext -n wccns -o yaml \u0026gt; wccinfra-cluster-ibr-cluster-ext.yaml $ sed -i \u0026#34;0,/5555/s//16250/\u0026#34; wccinfra-cluster-ibr-cluster-ext.yaml $ kubectl -n wccns apply -f wccinfra-cluster-ibr-cluster-ext.yaml  Verify ibr service name \u0026lsquo;wccinfra-cluster-ibr-cluster-ext\u0026rsquo; $ kubectl get svc -n wccns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE oracle-db LoadBalancer 10.96.74.187 123.45.xxx.xxx 1521:30011/TCP 13d wccinfra-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 5h10m wccinfra-cluster-ibr-cluster ClusterIP 10.96.155.21 \u0026lt;none\u0026gt; 16250/TCP 20s wccinfra-cluster-ibr-cluster-ext ClusterIP 10.96.152.184 10.0.10.xx 5555/TCP 7d3h wccinfra-cluster-ucm-cluster ClusterIP 10.96.136.224 \u0026lt;none\u0026gt; 16200/TCP 7d4h   "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/patch_and_upgrade/",
	"title": "Patch and upgrade",
	"tags": [],
	"description": "",
	"content": "Patch an existing Oracle WebCenter Content image or upgrade the infrastructure, such as upgrading the underlying Kubernetes cluster to a new release and upgrading the WebLogic Kubernetes Operator release.\n Patch an image  Create a patched Oracle WebCenter Content image using the WebLogic Image Tool.\n Upgrade an WebLogic Kubernetes Operator release  Upgrade the WebLogic Kubernetes Operator release to a newer version.\n Upgrade a Kubernetes cluster  Upgrade the underlying Kubernetes cluster version in a running WebCenter Content Kubernetes environment.\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/weblogic-logging-exporter-setup/",
	"title": "Publish logs to Elasticsearch",
	"tags": [],
	"description": "Use the WebLogic Logging Exporter to publish the WebLogic Server logs to Elasticsearch.",
	"content": "The WebLogic Logging Exporter adds a log event handler to WebLogic Server. WebLogic Server logs can be pushed to Elasticsearch in Kubernetes directly by using the Elasticsearch REST API. For more details, see to the WebLogic Logging Exporter project.\nThis sample shows you how to publish WebLogic Server logs to Elasticsearch and view them in Kibana. For publishing WebLogic Kubernetes Operator logs, see this sample.\nPrerequisites This document assumes that you have already set up Elasticsearch and Kibana for logs collection. If you have not, please see this document.\n Download the WebLogic Logging Exporter binaries The pre-built binaries are available on the WebLogic Logging Exporter Releases page.\nDownload:\n weblogic-logging-exporter-1.0.0.jar from the Releases page. snakeyaml-1.25.jar from Maven Central.  These identifiers are used in the sample commands in this document.\n wccns: WebCenter Content domain namespace wccinfra: domainUID wccinfra-adminserver: Administration Server pod name   Copy the JAR Files to the WebLogic Domain Home Copy the weblogic-logging-exporter-1.0.0.jar and snakeyaml-1.25.jar files to the domain home directory in the Administration Server pod.\n$ kubectl cp \u0026lt;file-to-copy\u0026gt; \u0026lt;namespace\u0026gt;/\u0026lt;Administration-Server-pod\u0026gt;:\u0026lt;domainhome\u0026gt; $ kubectl cp weblogic-logging-exporter-1.0.0.jar wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/ $ kubectl cp snakeyaml-1.25.jar wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/ Add a Startup Class to the Domain Configuration In this step, we configure weblogic-logging-exporter JAR as a startup class in the WebLogic servers where we intend to collect the logs.\n  In the WebLogic Server Administration Console, in the left navigation pane, expand Environment, and then select Startup and Shutdown Classes.\n  Add a new startup class. You may choose any descriptive name, however, the class name must be weblogic.logging.exporter.Startup.\n  Target the startup class to each server from which you want to export logs.\n  You can verify this by checking for the update in your config.xml file(/u01/oracle/user_projects/domains/wccinfra/config/config.xml) which should be similar to this example:\n$ kubectl exec -n wccns -it wccinfra-adminserver cat /u01/oracle/user_projects/domains/wccinfra/config/config.xml \u0026lt;startup-class\u0026gt; \u0026lt;name\u0026gt;weblogic-logging-exporter\u0026lt;/name\u0026gt; \u0026lt;target\u0026gt;AdminServer,ucm_cluster,ibr_cluster,ipm_cluster,capture_cluster,wccadf_cluster\u0026lt;/target\u0026gt; \u0026lt;class-name\u0026gt;weblogic.logging.exporter.Startup\u0026lt;/class-name\u0026gt; \u0026lt;/startup-class\u0026gt;   Update the WebLogic Server CLASSPATH   Copy the setDomainEnv.sh file from the pod to a local folder:\n$ kubectl cp wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/bin/setDomainEnv.sh $PWD/setDomainEnv.sh tar: Removing leading `/' from member names Ignore exception: tar: Removing leading '/' from member names\n  Modify setDomainEnv.sh to update the Server Class path, add below code at the end of file:\nCLASSPATH=/u01/oracle/user_projects/domains/wccinfra/weblogic-logging-exporter-1.0.0.jar:/u01/oracle/user_projects/domains/wccinfra/snakeyaml-1.25.jar:${CLASSPATH} export CLASSPATH   Copy back the modified setDomainEnv.sh file to the pod:\n$ kubectl cp setDomainEnv.sh wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/bin/setDomainEnv.sh ``\n  Create a Configuration File for the WebLogic Logging Exporter In this step, we will be creating the configuration file for weblogic-logging-exporter.\n  Specify the Elasticsearch server host and port number in file kubernetes/samples/scripts/create-wcc-domain/utils/weblogic-logging-exporter/WebLogicLoggingExporter.yaml:\nExample:\nweblogicLoggingIndexName: wls publishHost: elasticsearch.default.svc.cluster.local publishPort: 9200 domainUID: wccinfra weblogicLoggingExporterEnabled: true weblogicLoggingExporterSeverity: Notice weblogicLoggingExporterBulkSize: 2 weblogicLoggingExporterFilters: - FilterExpression: NOT(MSGID = 'BEA-000449')   Copy the WebLogicLoggingExporter.yaml file to the domain home directory in the WebLogic Administration Server pod:\n$ kubectl cp kubernetes/samples/scripts/create-wcc-domain/utils/weblogic-logging-exporter/WebLogicLoggingExporter.yaml wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/config/   Restart All the Servers in the Domain To restart the servers, stop and then start them using the following commands:\nTo STOP the servers: $ kubectl patch domain wccinfra -n wccns --type='json' -p='[{\u0026quot;op\u0026quot;: \u0026quot;replace\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/spec/serverStartPolicy\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;NEVER\u0026quot; }]' To START the servers: $ kubectl patch domain wccinfra -n wccns --type='json' -p='[{\u0026quot;op\u0026quot;: \u0026quot;replace\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/spec/serverStartPolicy\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;IF_NEEDED\u0026quot; }]' After all the servers are restarted, see their server logs to check that the weblogic-logging-exporter class is called, as shown below:\n======================= Weblogic Logging Exporter Startup class called ================== Reading configuration from file name: /u01/oracle/user_projects/domains/wccinfra/config/WebLogicLoggingExporter.yaml Config{weblogicLoggingIndexName='wls', publishHost='elasticsearch.default.svc.cluster.local', publishPort=9200, weblogicLoggingExporterSeverity='Notice', weblogicLoggingExporterBulkSize='1', enabled=true, weblogicLoggingExporterFilters=[ FilterConfig{expression='NOT(MSGID = 'BEA-000449')', servers=[]}], domainUID='wccinfra'} ====================== WebLogic Logging Exporter is ebled ================= publishHost in initialize: elasticsearch.default.svc.cluster.local ================= publishPort in initialize: 9200 ================= url in executePutOrPostOnUrl: http://elasticsearch.default.svc.cluster.local:9200/wls Create an Index Pattern in Kibana Create an appropriate index pattern in Kibana \u0026gt; Management. After the servers are started, you will see the log data in the Kibana dashboard.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/configure-load-balancer/apache/",
	"title": "Apache webtier",
	"tags": [],
	"description": "Configure the Apache webtier load balancer for Oracle WebCenter Content domain.",
	"content": "This section provides information about how to install and configure Apache webtier to load balance Oracle WebCenter Content domain clusters. You can configure Apache webtier for non-SSL and SSL termination access of the application URL.\nFollow these steps to set up Apache webtier as a load balancer for an Oracle WebCenter Content domain in a Kubernetes cluster:\n Build the Apache webtier image Create the Apache plugin configuration file Prepare the certificate and private key Install the Apache webtier Helm chart Verify domain application URL access Uninstall Apache webtier  Build the Apache webtier image Refer to the sample, to build the Apache webtier Docker image.\nCreate the Apache plugin configuration file  The configuration file named custom_mod_wl_apache.conf should have all the URL routing rules for the Oracle WebCenter Content application deployed in the domain that needs to be accessible externally. Update this file with values based on your environment. The file content is similar to below mentioned sample.    Click here to see the sample content of the configuration file custom_mod_wl_apache.conf for Oracle WebCenter Content domain   # Copyright (c) 2018, 2020, Oracle Corporation and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. \u0026lt;IfModule mod_weblogic.c\u0026gt; WebLogicHost \u0026lt;WEBLOGIC_HOST\u0026gt; WebLogicPort 7001 \u0026lt;/IfModule\u0026gt; # Directive for weblogic admin Console deployed on Weblogic Admin Server \u0026lt;Location /console\u0026gt; SetHandler weblogic-handler WebLogicHost wccinfra-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; \u0026lt;Location /em\u0026gt; SetHandler weblogic-handler WebLogicHost wccinfra-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; \u0026lt;Location /weblogic/ready\u0026gt; SetHandler weblogic-handler WebLogicHost wccinfra-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; # Directive for all application deployed on weblogic cluster with a prepath defined by LOCATION variable # For example, if the LOCAITON is set to \u0026#39;/weblogic\u0026#39;, all applications deployed on the cluster can be accessed via # http://myhost:myport/weblogic/application_end_url # where \u0026#39;myhost\u0026#39; is the IP of the machine that runs the Apache web tier, and # \u0026#39;myport\u0026#39; is the port that the Apache web tier is publicly exposed to. # Note that LOCATION cannot be set to \u0026#39;/\u0026#39; unless this is the only Location module configured. \u0026lt;Location /cs\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ucm-cluster:16200 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /adfAuthentication\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ucm-cluster:16200 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /ibr\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ibr-cluster:16250 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /ibr/adfAuthentication\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ibr-cluster:16250 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /imaging\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ipm-cluster:16000 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /dc-console\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-capture-cluster:16400 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /dc-client\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-capture-cluster:16400 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /wcc\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-wccadf-cluster:16225 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; # Directive for all application deployed on weblogic cluster with a prepath defined by LOCATION2 variable # For example, if the LOCAITON2 is set to \u0026#39;/weblogic2\u0026#39;, all applications deployed on the cluster can be accessed via # http://myhost:myport/weblogic2/application_end_url # where \u0026#39;myhost\u0026#39; is the IP of the machine that runs the Apache web tier, and # \u0026#39;myport\u0026#39; is the port that the Apache webt ier is publicly exposed to. #\u0026lt;Location /weblogic2\u0026gt; #WLSRequest On #WebLogicCluster domain2-cluster-cluster-1:8021 #PathTrim /weblogic2 #\u0026lt;/Location\u0026gt;     Update persistentVolumeClaimName with your PV-claim-name which contains your custom_mod_wl_apache.conf in file kubernetes/samples/charts/apache-samples/custom-sample/input.yaml.  Prepare the certificate and private key   (For the SSL termination configuration only) Run the following commands to generate your own certificate and private key using openssl.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ cd kubernetes/samples/charts/apache-samples/custom-sample $ export VIRTUAL_HOST_NAME=WEBLOGIC_HOST $ export SSL_CERT_FILE=WEBLOGIC_HOST.crt $ export SSL_CERT_KEY_FILE=WEBLOGIC_HOST.key $ sh certgen.sh  NOTE: Replace WEBLOGIC_HOST with the host name on which Apache webtier is to be installed.\n   Click here to see the output of the certifcate generation   $ls certgen.sh custom_mod_wl_apache.conf custom_mod_wl_apache.conf_orig input.yaml README.md $ sh certgen.sh Generating certs for WEBLOGIC_HOST Generating a 2048 bit RSA private key ........................+++ .......................................................................+++ unable to write \u0026#39;random state\u0026#39; writing new private key to \u0026#39;apache-sample.key\u0026#39; ----- $ ls certgen.sh custom_mod_wl_apache.conf_orig WEBLOGIC_HOST.info config.txt input.yaml WEBLOGIC_HOST.key custom_mod_wl_apache.conf WEBLOGIC_HOST.crt README.md      Prepare input values for the Apache webtier Helm chart.\nRun the following commands to prepare the input value file for the Apache webtier Helm chart.\n$ base64 -i ${SSL_CERT_FILE} | tr -d \u0026#39;\\n\u0026#39; $ base64 -i ${SSL_CERT_KEY_FILE} | tr -d \u0026#39;\\n\u0026#39; $ touch input.yaml Update virtualHostName with the value of the WEBLOGIC_HOST in file kubernetes/samples/charts/apache-samples/custom-sample/input.yaml\n  Click here to see the snapshot of the sample input.yaml file   $ cat apache-samples/custom-sample/input.yaml # Use this to provide your own Apache webtier configuration as needed; simply define this # path and put your own custom_mod_wl_apache.conf file under this path. persistentVolumeClaimName: \u0026lt;pv-claim-name\u0026gt; # The VirtualHostName of the Apache HTTP server. It is used to enable custom SSL configuration. virtualHostName: \u0026lt;WEBLOGIC_HOST\u0026gt;      Install the Apache webtier Helm chart   Install the Apache webtier Helm chart to the domain wccns namespace with the specified input parameters:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts $ kubectl create namespace apache-webtier $ helm install apache-webtier --values apache-samples/custom-sample/input.yaml --namespace wccns apache-webtier --set image=oracle/apache:12.2.1.3   Check the status of the Apache webtier:\n$ kubectl get all -n wccns | grep apache Sample output of the status of the apache webtier:\n  pod/apache-webtier-new-apache-webtier-65d8d7c59f-k27wf 1/1 Running 0 9d service/apache-webtier-new-apache-webtier NodePort 10.108.12.143 \u0026lt;none\u0026gt; 80:30505/TCP,4433:30453/TCP 9d deployment.apps/apache-webtier-new-apache-webtier 1/1 1 1 9d replicaset.apps/apache-webtier-new-apache-webtier-65d8d7c59f 1 1 1 9d Verify domain application URL access Post the Apache webtier load balancer is up, verify that the domain applications are accessible through the load balancer port 30505/30453. The application URLs for domain of type wcc are:\n Note: Port 30505 is the LOADBALANCER-Non-SSLPORT and Port 30453 is LOADBALANCER-SSLPORT.\n Non-SSL configuration http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/imaging http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/dc-console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/wcc SSL configuration https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/imaging https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/dc-console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/wcc Uninstall Apache webtier $ helm delete apache-webtier -n wccns "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/installguide/additional-steps-to-launch-native-binaries/",
	"title": "Launch Oracle Webcenter Content Native Applications in Containers",
	"tags": [],
	"description": "How to launch Oracle WebCenter Content native binaries from inside containerized environment.",
	"content": "This section provides the steps required to use product native binaries with user interfaces.\nIssue with Launching Headful User Interfaces for Oracle WebCenter Content Native Binaries Oracle WebCenter Content (UCM) provide a set of native binaries with headful UIs, which are located inside the persistent volume, as part of the domain. WebCenter Content container images are, by default, created with Oracle slim linux image, which doesn\u0026rsquo;t come with all the packages pre-installed to support headful applications with UIs to be launched. With current Oracle WebCenter Content container images, running native applications fails, being unable to launch UIs.\nThe following sections document the solution, by providing a set of instructions, enabling users to run UCM native applications with UIs.\nThese instructions are divided in two parts -\n Steps to update the existing container image Steps to launch native apps using VNC sessions  Steps to Update out-of-the-box Oracle WebCenter Content Container Image Using WebLogic Image Tool This section describes the method to update image with a OS package using WebLogic Image Tool. Please refer this for setting up the WebLogic Image Tool.\nAdditional Build Commands The installation of required OS packages in the image, can be done using yum command in additional build command option available in WebLogic Image Tool. Here is the sample additionalBuildCmds.txt file, to be used, to install required Linux packages (libXext.x86_64, libXrender.x86_64 and libXtst.x86_64).\n[final-build-commands] USER root RUN yum -y --downloaddir=/tmp/imagetool install libXext libXrender libXtst \\ \u0026amp;\u0026amp; yum -y --downloaddir=/tmp/imagetool clean all \\ \u0026amp;\u0026amp; rm -rf /var/cache/yum/* \\ \u0026amp;\u0026amp; rm -rf /tmp/imagetool USER oracle  Note: It is important to change the user to oracle, otherwise the user during the container execution will be root.\n Build arguments The arguments required for updating the image can be passed as file to the WebLogic Image Tool.\n'update' is the sub command to Image Tool for updating an existing docker image. '--fromImage' option provides the existing docker image that has to be updated. '--tag' option should be provided with the new tag for the updated image. '--additionalBuildCommands' option should be provided with the above created additional build commands file.  Below is a sample build argument (buildArgs) file, to be used for updating the image,\n update --fromImage \u0026lt;existing_WCContent_image_without_dependent_packages\u0026gt; --tag \u0026lt;name_of_updated_WCContent_image_to_be_built\u0026gt; --additionalBuildCommands ./additionalBuildCmds.txt Update Oracle WebCenter Content Container Image Now we can execute the WebLogic Image Tool to update the out-of-the-box image, using the build-argument file described above -\n$ imagetool @buildArgs WebLogic Image Tool provides multiple options for updating the image. For detailed information on the update options, please refer to this document.\nUpdating the image does not modify the \u0026lsquo;CMD\u0026rsquo; from the source image unless it is modified in the additional build commands.\n$ docker inspect -f '{{.Config.Cmd}}' \u0026lt;name_of_updated_Wccontent_image\u0026gt; [/u01/oracle/container-scripts/createDomainandStartAdmin.sh] Steps to launch Oracle WebCenter Content native applications using VNC sessions. Once updated image is successfully built and available on all required nodes, do the following: a. Update the domain.yaml file with updated image name and apply the domain.yaml file.\n$ kubectl apply -f domain.yaml b. After applying the modified domain.yaml, pods will get restarted and start running with updated image with required packages.\n$ kubectl get pods -n \u0026lt;namespace_being_used_for_wccontent_domain\u0026gt; c. Create VNC sessions on the master node to launch native apps. These are the steps to be followed using the VNC session.\nd. Run this command on each VNC session:\n$ xhost + \u0026lt;HOST-IP or HOST-NAME of the node, on which POD is deployed\u0026gt;  Note: The above command works for multi-node clusters (in which master node and worker nodes are deployed on different hosts and pods are distributed among worker nodes, running on different hosts). In case of single node clusters (where there is only master node and no worker nodes and all pods are deployed on the host, on which master node is running), one needs to use container/pod’s IP instead of the master-node’s HOST-IP itself.\n To obtain the container IP, follow the command mentioned in step g, from within that container\u0026rsquo;s shell.\n$ xhost + \u0026lt;IP of the container, from which binaries are to be run \u0026gt; e. Get into the pod\u0026rsquo;s (for example, wccinfra-ucm-server1) shell:\n$ kubectl exec -n wccns -it wccinfra-ucm-server1 -- /bin/bash f. Traverse to the binaries location:\n$ cd /u01/oracle/user_projects/domains/wccinfra/ucm/cs/bin g. Get the container IP:\n$ hostname -i h. Set DISPLAY variable within the container:\n$ export DISPLAY=\u0026lt;HOST-IP/HOST-NAME of the master node, where VNC session was created\u0026gt;:vnc-session display-id i. Launch any native UCM application, from within the container, like this:\n$ ./SystemProperties If the application has an UI, it will get launched now.\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/configure-wcc-for-idcs/",
	"title": "Configuring Oracle WebCenter Content for  Oracle Identity Cloud Service (IDCS)",
	"tags": [],
	"description": "Configuring Oracle WebCenter Content for  Oracle Identity Cloud Service (IDCS)",
	"content": "Contents  Introduction Updating SSL.hostnameVerifier Property Configuring IDCS Security Provider Configuring Oracle Identity Cloud Integrator Provider Setting Up Trust between IDCS and WebLogic Creating Admin User in IDCS Admin Console for WebCenter Content Managing Group Memberships, Roles, and Accounts Configuring WebCenter Content for User Logout  Introduction Configuring WebCenter Content for Oracle Identity Cloud Service (IDCS) on OKE. Configuration information is provided in the following sections:\n Updating SSL.hostnameVerifier Property Configuring IDCS Security Provider Configuring WebCenter Content for User Logout  Updating SSL.hostnameVerifier Property To update SSL.hostnameVerifier property, do the following: This is necessary for the IDCS provider to access IDCS.\n  Stop all the servers in the domain including Administration server and all Managed WebLogic servers.\n  Update the SSL.hostnameVerifier property:\nedit the file \u0026lt;DOMAIN_HOME\u0026gt;//bin/setDomainEnv.sh: go to pv location file system and modify the file setDomainEnv.sh sample: /WCCFS/wccinfra/bin/setDomainEnv.sh\nOR\nAlternatively create or modify the file \u0026lt;DOMAIN_HOME\u0026gt;/\u0026lt;domain_name\u0026gt;/bin/setUserOverrides.sh. Add the SSL.hostnameVerifier property for the IDCS Authenticator: sample: /WCCFS/wccinfra/bin/setUserOverrides.sh\nEXTRA_JAVA_PROPERTIES=\u0026#34;${EXTRA_JAVA_PROPERTIES}-Dweblogic.security.SSL.hostnameVerifier=weblogic.security.utils.SSLWLSWildcardHostnameVerifier\u0026#34; export EXTRA_JAVA_PROPERTIES   Start the Administration server and all Managed WebLogic servers.\n  Configuring IDCS Security Provider   Log in to the IDCS administration console.\n  Create a trusted application. In the Add Confidential Application wizard:\n Enter the client name and the description (optional). Select the Configure this application as a client now option. To configure this application, expand the Client Configuration in the Configuration tab. In the Allowed Grant Types , select Client Credentials field the check box. In the Grant the client access to Identity Cloud Service Admin APIs section, click Add to add the APP Roles (application roles). You can add the Identity Domain Administrator role. Keep the default settings for the pages and click Finish. Record/Copy the Client ID and Client Secret.This is needed when you will create the IDCS provider. Activate the application.    Configuring Oracle Identity Cloud Integrator Provider To configure Identity Cloud Integrator Provider:\n  Log in to the WebLogic Server Administration console.\n  Select Security Realm in the Domain Structure pane.\n  On the Summary of Security Realms page, select the name of the realm (for example, myrealm). Click myrealm. The Settings for myrealm page appears.\n  On the Settings for Realm Name page, select Providers and then Authentication. To create a new Authentication Provider, in the Authentication Providers table, click New.\n  In the Create a New Authentication Provider page, enter the name of the authentication provider, for example, IDCSIntegrator and select the OracleIdentityCloudIntegrator type of authentication provider from the drop-down list and click OK.\n  In the Authentication Providers table, click the newly created Oracle Identity Cloud Integrator, IDCSIntegrator link.\n  In the Settings for IDCSIntegrator page, for the Control Flag field, select the Sufficient option from the drop-down list Click Save.\n  Go to the Provider Specific page to configure the additional attributes for the security provider. Enter the values for the following fields \u0026amp; Click Save:\n Host Port 443(default) select SSLEnabled Tenant Client Id Client Secret.   NOTE: If IDCS URL is idcs-abcde.identity.example.com, then IDCS host would be identity.example.com and tenant name would be idcs-abcde. Keep the default settings for other sections of the page.\n   Select Security Realm, then myrealm, and then Providers. In the Authentication Providers table, click Reorder.\n  In the Reorder Authentication Providers page, move IDCSIntegrator on the top and click OK.\n  In the Authentication Providers table, click the DefaultAuthenticator link. In the Settings for DefaultAuthenticator page, for the Control Flag field, select the Sufficient option from the drop-down list. Click Save.\n  All changes will be activated. Restart the Administration server.\n  Setting Up Trust between IDCS and WebLogic To set up trust between IDCS and WebLogic\n Import certificate in KSS store.  Run this from the Administration Server node. Get IDCS certificate: echo -n | openssl s_client -showcerts -servername \u0026lt;IDCS_URL\u0026gt; -connect \u0026lt;IDCS_URL\u0026gt;:443|sed -ne \u0026#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p\u0026#39; \u0026gt; /tmp/idcs_cert_chain.crt #sample echo -n | openssl s_client -showcerts -servername xyz.identity.oraclecloud.com -connect idcs-xyz.identity.oraclecloud.com:443|sed -ne \u0026#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p\u0026#39; \u0026gt; /tmp/idcs_cert_chain.crt #copy the certificate inside the admin_pod kubectl cp /tmp/idcs_cert_chain.crt wccns/xyz-adminserver:/u01/idcs_cert_chain.crt  Import certificate. Run \u0026lt;ORACLE_HOME\u0026gt;/oracle_common/common/bin/wlst.sh file. connect(\u0026#39;weblogic\u0026#39;,\u0026#39;Welcome_1\u0026#39;,\u0026#39;t3://\u0026lt;WEBLOGIC_HOST\u0026gt;:7001\u0026#39;) svc=getOpssService(name=\u0026#39;KeyStoreService\u0026#39;) svc.importKeyStoreCertificate(appStripe=\u0026#39;system\u0026#39;,name=\u0026#39;trust\u0026#39;,password=\u0026#39;\u0026#39;,alias=\u0026#39;idcs_cert_chain\u0026#39;,type=\u0026#39;TrustedCertificate\u0026#39;,filepath=\u0026#39;/tmp/idcs_cert_chain.crt\u0026#39;,keypassword=\u0026#39;\u0026#39;) syncKeyStores(appStripe=\u0026#39;system\u0026#39;,keystoreFormat=\u0026#39;KSS\u0026#39;) #sample $./wlst.sh wls:/offline\u0026gt; connect(\u0026#39;weblogic\u0026#39;,\u0026#39;welcome\u0026#39;,\u0026#39;t3://xyz-adminserver:7001\u0026#39;) wls:/wccinfra/serverConfig/\u0026gt; svc=getOpssService(name=\u0026#39;KeyStoreService\u0026#39;) wls:/wccinfra/serverConfig/\u0026gt;svc.importKeyStoreCertificate(appStripe=\u0026#39;system\u0026#39;,name=\u0026#39;trust\u0026#39;,password=\u0026#39;\u0026#39;,alias=\u0026#39;idcs_cert_chain\u0026#39;,type=\u0026#39;TrustedCertificate\u0026#39;,filepath=\u0026#39;/u01/idcs_cert_chain.crt\u0026#39;,keypassword=\u0026#39;\u0026#39;) wls:/wccinfra/domainRuntime/\u0026gt;syncKeyStores(appStripe=\u0026#39;system\u0026#39;,keystoreFormat=\u0026#39;KSS\u0026#39;)  exit()   Restart the Administration server and Managed servers  Creating Admin User in IDCS Administration Console for WebCenter Content It is important to create the Admin user in IDCS because once the Managed servers are configured for SAML, the domain admin user (typically weblogic user) will not be able to log into the Managed servers.\nTo create WebLogic Admin user in IDCS for WebCenter Content JaxWS connection:\n Go to the Groups tab and create Administrators and sysmanager roles in IDCS. Go to the Users tab and create a wls admin user, for example, weblogic and assign it to Administrators and sysmanager groups. Restart all the Managed servers.  Managing Group Memberships, Roles, and Accounts This will require modifying OPSS and libOVD to access IDCS. The following steps are required if using IDCS for user authorization. Do not run these steps if you are using IDCS only for user authentication. Ensure that all the servers are stopped (including Administration) before proceeding with the following steps:\n NOTE: Shutdown all the servers using WebLogic Server Administration Console. Please keep in mind - kubectl patch domain command is the recommended way for starting/stopping pods. Please refrain from using WebLogic Server Administration Console for the same, anywhere else.\n   Run the following script:\n#exec the Administration server kubectl exec -n wccns -it wccinfra-adminserver -- /bin/bash #Run the wlst.sh cd /u01/oracle/oracle_common/common/bin/ ./wlst.sh  NOTE: It\u0026rsquo;s not required to connect to WebLogic Administration Server.\n   Read the domain:\nreadDomain(\u0026lt;DOMAIN_HOME\u0026gt;) #sample wls:/offline\u0026gt; readDomain(\u0026#39;/u01/oracle/user_projects/domains/wccinfra\u0026#39;)   Add the template:\naddTemplate(\u0026lt;MIDDLEWARE_HOME\u0026gt;/oracle_common/common/templates/wls/oracle.opss_scim_template.jar\u0026#34;) #sample wls:/offline/wccinfra\u0026gt;addTemplate(\u0026#39;/u01/oracle/oracle_common/common/templates/wls/oracle.opss_scim_template.jar\u0026#39;)  NOTE: This step may throw a warning, which can be ignored. The addTemplate is deprecated. Use selectTemplate followed by loadTemplates in place of addTemplate.\n   Update the domain:\nupdateDomain() #sample wls:/offline/wccinfra\u0026gt; updateDomain()   Close the domain:\ncloseDomain() #sample wls:/offline/wccinfra\u0026gt; closeDomain()   Exit from the Administration server container:\nexit   Start the servers (Administration and Managed).\n  Configuring WebCenter Content for User Logout If the Logout link is selected, you will be re-authenticated by SAML. To be able to select the Logout link:\n Log in to WebCenter Content Server as an administrator. Select Administration, then Admin Server, and then General Configuration. In the Additional Configuration Variables pane, add the following parameter: EXTRA_JAVA_PROPERTIES=\u0026#34;${EXTRA_JAVA_PROPERTIES}-Dweblogic.security.SSL.hostnameVerifier=weblogic.security.utils.SSLWLSWildcardHostnameVerifier\u0026#34;  Click Save. Restart the Administration and Managed servers.  "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/create-or-update-image/",
	"title": "Create or update an image",
	"tags": [],
	"description": "Create or update an Oracle WebCenter Content Docker image used for deploying Oracle WebCenter Content domains. An Oracle WebCenter Content Docker image can be created using the WebLogic Image Tool or using the Dockerfile approach.",
	"content": "If you have access to the My Oracle Support (MOS), and there is a need to build a new image with a patch (bundle or interim), it is recommended to use the WebLogic Image Tool to build an Oracle WebCenter Content image for production deployments.\n Create or update an Oracle WebCenter Content Docker image using the WebLogic Image Tool  Set up the WebLogic Image Tool Create an image Update an image   Create an Oracle WebCenter Content Docker image using Dockerfile  Create or update an Oracle WebCenter Content Docker image using the WebLogic Image Tool Using the WebLogic Image Tool, you can create a new Oracle WebCenter Content Docker image (can include patches as well) or update an existing image with one or more patches (bundle patch and interim patches).\n Recommendations:\n Use create for creating a new Oracle WebCenter Content Docker image either:  without any patches or, containing the Oracle WebCenter Content binaries, bundle patch and interim patches. This is the recommended approach if you have access to the Oracle WebCenter Content patches because it optimizes the size of the image.   Use update for patching an existing Oracle WebCenter Content Docker image with a single interim patch. Note that the patched image size may increase considerably due to additional image layers introduced by the patch application tool.   Set up the WebLogic Image Tool  Prerequisites Set up the WebLogic Image Tool Validate setup WebLogic Image Tool build directory WebLogic Image Tool cache Set up additional build scripts  Prerequisites Verify that your environment meets the following prerequisites:\n Docker client and daemon on the build machine, with minimum Docker version 18.03.1.ce. Bash version 4.0 or later, to enable the command complete feature. JAVA_HOME environment variable set to the appropriate JDK location.  Set up the WebLogic Image Tool To set up the WebLogic Image Tool:\n  Create a working directory and change to it. In these steps, this directory is imagetool-setup.\n$ mkdir imagetool-setup $ cd imagetool-setup   Download the latest version of the WebLogic Image Tool from the releases page.\n  Unzip the release ZIP file to the imagetool-setup directory.\n  Execute the following commands to set up the WebLogic Image Tool on a Linux environment:\n$ cd imagetool-setup/imagetool/bin $ source setup.sh   Validate setup To validate the setup of the WebLogic Image Tool:\n  Enter the following command to retrieve the version of the WebLogic Image Tool:\n$ imagetool --version   Enter imagetool then press the Tab key to display the available imagetool commands:\n$ imagetool \u0026lt;TAB\u0026gt; cache create help rebase update   WebLogic Image Tool build directory The WebLogic Image Tool creates a temporary Docker context directory, prefixed by wlsimgbuilder_temp, every time the tool runs. Under normal circumstances, this context directory will be deleted. However, if the process is aborted or the tool is unable to remove the directory, it is safe for you to delete it manually. By default, the WebLogic Image Tool creates the Docker context directory under the user\u0026rsquo;s home directory. If you prefer to use a different directory for the temporary context, set the environment variable WLSIMG_BLDDIR:\n$ export WLSIMG_BLDDIR=\u0026#34;/path/to/buid/dir\u0026#34; WebLogic Image Tool cache The WebLogic Image Tool maintains a local file cache store. This store is used to look up where the Java, WebLogic Server installers, and WebLogic Server patches reside in the local file system. By default, the cache store is located in the user\u0026rsquo;s $HOME/cache directory. Under this directory, the lookup information is stored in the .metadata file. All automatically downloaded patches also reside in this directory. You can change the default cache store location by setting the environment variable WLSIMG_CACHEDIR:\n$ export WLSIMG_CACHEDIR=\u0026#34;/path/to/cachedir\u0026#34; Set up additional build scripts Creating an Oracle WebCenter Content Docker image using the WebLogic Image Tool requires additional container scripts for Oracle WebCenter Content domains.\n  Clone the docker-images repository to set up those scripts. In these steps, this directory is DOCKER_REPO:\n$ cd imagetool-setup $ git clone https://github.com/oracle/docker-images.git   Copy the additional WebLogic Image Tool build files from the WebLogic Kubernetes Operator source repository to the imagetool-setup location:\n$ mkdir -p imagetool-setup/docker-images/WebCenterContent/imagetool/12.2.1.4.0 $ cd imagetool-setup/docker-images/WebCenterContent/imagetool/12.2.1.4.0 $ cp -rf ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/imagetool-scripts/* .   Create an image After setting up the WebLogic Image Tool and required build scripts, follow these steps to use the WebLogic Image Tool to create a new Oracle WebCenter Content Docker image.\nDownload the Oracle WebCenter Content installation binaries and patches You must download the required Oracle WebCenter Content installation binaries and patches as listed below from the Oracle Software Delivery Cloud and save them in a directory of your choice. In these steps, this directory is download location.\n  Click here to see the sample list of installation binaries and patches:     JDK:\n jdk-8u251-linux-x64.tar.gz    Fusion MiddleWare Infrastructure installer:\n fmw_12.2.1.4.0_infrastructure_generic.jar    WebCenter Content installers:\n fmw_12.2.1.4.0_wccontent.jar    Fusion MiddleWare Infrastructure patches:\n p28186730_139424_Generic-23574493.zip (Opatch)    WebCenter Content patches:\n p31390302_122140_Generic.zip (wcc)       Note: This is a sample list of patches. You must get the appropriate list of patches for your Oracle WebCenter Content image.\n Update required build files The following files available in the code repository location \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/imagetool/12.2.1.4.0 are used for creating the image.\n additionalBuildCmds.txt buildArgs    In the buildArgs file, update all the occurrences of %DOCKER_REPO% with the docker-images repository location, which is the complete path of imagetool-setup/docker-images.\nFor example, update:\n%DOCKER_REPO%/OracleWebCenterContent/imagetool/12.2.1.4.0/\nto:\n\u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/imagetool/12.2.1.4.0/\n  Similarly, update the placeholders %JDK_VERSION% and %BUILDTAG% with appropriate values.\n  Create the image   Add a JDK package to the WebLogic Image Tool cache:\n$ imagetool cache addInstaller --type jdk --version 8u251 --path \u0026lt;download location\u0026gt;/jdk-8u251-linux-x64.tar.gz   Add the downloaded installation binaries to the WebLogic Image Tool cache:\n$ imagetool cache addInstaller --type fmw --version 12.2.1.4.0 --path \u0026lt;download location\u0026gt;/fmw_12.2.1.4.0_infrastructure.jar $ imagetool cache addInstaller --type wcc --version 12.2.1.4.0 --path \u0026lt;download location\u0026gt;/fmw_12.2.1.4.0_wccontent.jar   Add the downloaded patches to the WebLogic Image Tool cache:\n  Click here to see the commands to add patches in to the cache:   ``` bash $ imagetool cache addEntry --key p33578966_122140_Generic --path \u0026lt;download location\u0026gt;/p33578966_122140_Generic.zip $ imagetool cache addEntry --key 28186730_13.9.4.2.8 --path \u0026lt;download location\u0026gt;/p28186730_139428_Generic-24497645.zip ```      Update the patches list to buildArgs.\nTo the create command in the buildArgs file, append the Oracle WebCenter Content patches list using the --patches flag and Opatch patch using the --opatchBugNumber flag. Sample options for the list of patches above are:\n--patches 33578966_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.8 Example buildArgs file after appending product\u0026rsquo;s list of patches and Opatch patch:\ncreate --jdkVersion=8u251 --type WCC --version=12.2.1.4.0 --tag=oracle/wccontent_create_1015:12.2.1.4.0 --pull --chown oracle:root --additionalBuildCommands \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/imagetool/12.2.1.4.0/additionalBuildCmds.txt --additionalBuildFiles \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/dockerfiles/12.2.1.4.0/container-scripts --patches 33578966_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.8 Refer to this page for the complete list of options available with the WebLogic Image Tool create command.\n  Enter the following command to create the Oracle WebCenter Content image:\n$ imagetool @\u0026lt;absolute path to `buildargs` file\u0026gt;\u0026#34;     Click here to see the sample Dockerfile generated with the imagetool command.   ########## BEGIN DOCKERFILE ########## # # Copyright (c) 2019, 2021, Oracle and/or its affiliates. # # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # FROM ghcr.io/oracle/oraclelinux:7-slim as os_update LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; USER root RUN yum -y --downloaddir=/tmp/imagetool install gzip tar unzip libaio jq hostname \\  \u0026amp;\u0026amp; yum -y --downloaddir=/tmp/imagetool clean all \\  \u0026amp;\u0026amp; rm -rf /var/cache/yum/* \\  \u0026amp;\u0026amp; rm -rf /tmp/imagetool ## Create user and group RUN if [ -z \u0026#34;$(getent group root)\u0026#34; ]; then hash groupadd \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; groupadd root || exit -1 ; fi \\  \u0026amp;\u0026amp; if [ -z \u0026#34;$(getent passwd oracle)\u0026#34; ]; then hash useradd \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; useradd -g root oracle || exit -1; fi \\  \u0026amp;\u0026amp; mkdir -p /u01 \\  \u0026amp;\u0026amp; chown oracle:root /u01 \\  \u0026amp;\u0026amp; chmod 775 /u01 # Install Java FROM os_update as jdk_build LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; ENV JAVA_HOME=/u01/jdk COPY --chown=oracle:root jdk-8u251-linux-x64.tar.gz /tmp/imagetool/ USER oracle RUN tar xzf /tmp/imagetool/jdk-8u251-linux-x64.tar.gz -C /u01 \\  \u0026amp;\u0026amp; $(test -d /u01/jdk* \u0026amp;\u0026amp; mv /u01/jdk* /u01/jdk || mv /u01/graal* /u01/jdk) \\  \u0026amp;\u0026amp; rm -rf /tmp/imagetool \\  \u0026amp;\u0026amp; rm -f /u01/jdk/javafx-src.zip /u01/jdk/src.zip # Install Middleware FROM os_update as wls_build LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; ENV JAVA_HOME=/u01/jdk \\  ORACLE_HOME=/u01/oracle \\  OPATCH_NO_FUSER=true RUN mkdir -p /u01/oracle \\  \u0026amp;\u0026amp; mkdir -p /u01/oracle/oraInventory \\  \u0026amp;\u0026amp; chown oracle:root /u01/oracle/oraInventory \\  \u0026amp;\u0026amp; chown oracle:root /u01/oracle COPY --from=jdk_build --chown=oracle:root /u01/jdk /u01/jdk/ COPY --chown=oracle:root fmw_12.2.1.4.0_infrastructure_generic.jar fmw.rsp /tmp/imagetool/ COPY --chown=oracle:root fmw_12.2.1.4.0_wccontent.jar wcc.rsp /tmp/imagetool/ COPY --chown=oracle:root oraInst.loc /u01/oracle/ USER oracle RUN echo \u0026#34;INSTALLING MIDDLEWARE\u0026#34; \\  \u0026amp;\u0026amp; echo \u0026#34;INSTALLING fmw\u0026#34; \\  \u0026amp;\u0026amp; \\  /u01/jdk/bin/java -Xmx1024m -jar /tmp/imagetool/fmw_12.2.1.4.0_infrastructure_generic.jar -silent ORACLE_HOME=/u01/oracle \\  -responseFile /tmp/imagetool/fmw.rsp -invPtrLoc /u01/oracle/oraInst.loc -ignoreSysPrereqs -force -novalidation \\  \u0026amp;\u0026amp; echo \u0026#34;INSTALLING wcc\u0026#34; \\  \u0026amp;\u0026amp; \\  /u01/jdk/bin/java -Xmx1024m -jar /tmp/imagetool/fmw_12.2.1.4.0_wccontent.jar -silent ORACLE_HOME=/u01/oracle \\  -responseFile /tmp/imagetool/wcc.rsp -invPtrLoc /u01/oracle/oraInst.loc -ignoreSysPrereqs -force -novalidation \\  \u0026amp;\u0026amp; chmod -R g+r /u01/oracle FROM os_update as final_build ARG ADMIN_NAME ARG ADMIN_HOST ARG ADMIN_PORT ARG MANAGED_SERVER_PORT ENV ORACLE_HOME=/u01/oracle \\  JAVA_HOME=/u01/jdk \\  PATH=${PATH}:/u01/jdk/bin:/u01/oracle/oracle_common/common/bin:/u01/oracle/wlserver/common/bin:/u01/oracle LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; COPY --from=jdk_build --chown=oracle:root /u01/jdk /u01/jdk/ COPY --from=wls_build --chown=oracle:root /u01/oracle /u01/oracle/ USER oracle WORKDIR /u01/oracle #ENTRYPOINT /bin/bash ENV ORACLE_HOME=/u01/oracle \\  VOLUME_DIR=/u01/oracle/user_projects \\  SCRIPT_FILE=/u01/oracle/container-scripts/* \\  USER_MEM_ARGS=\u0026#34;-Djava.security.egd=file:/dev/./urandom\u0026#34; \\  PATH=$PATH:$JAVA_HOME/bin:$ORACLE_HOME/oracle_common/common/bin:/u01/oracle/wlserver/common/bin:/u01/oracle/container-scripts USER root RUN mkdir -p $VOLUME_DIR \u0026amp;\u0026amp; \\  mkdir -p /u01/oracle/container-scripts \u0026amp;\u0026amp; \\  mkdir -p /u01/oracle/silent-install-files-tmp/config \u0026amp;\u0026amp; \\  mkdir -p /u01/oracle/logs \u0026amp;\u0026amp; \\  chown oracle:root -R /u01 $VOLUME_DIR \u0026amp;\u0026amp; \\  chmod a+xr /u01 COPY --chown=oracle:root files/container-scripts/ /u01/oracle/container-scripts/ RUN chmod +xr $SCRIPT_FILE USER oracle EXPOSE $UCM_PORT $UCM_INTRADOC_PORT $IBR_INTRADOC_PORT $IBR_PORT $ADMIN_PORT WORKDIR ${ORACLE_HOME} CMD [\u0026#34;/u01/oracle/container-scripts/createDomainandStartAdmin.sh\u0026#34;] ########## END DOCKERFILE ##########      Check the created image using the docker images command:\n$ docker images | grep wcc   Update an image After setting up the WebLogic Image Tool and required build scripts, use the WebLogic Image Tool to update an existing Oracle WebCenter Content Docker image:\n  Enter the following command for each patch to add the required patch(es) to the WebLogic Image Tool cache:\n$ cd \u0026lt;imagetool-setup\u0026gt; $ imagetool cache addEntry --key=33578966_12.2.1.4.0 --value \u0026lt;downloaded-patches-location\u0026gt;/p33578966_122140_Generic.zip [INFO ] Added entry 33578966_12.2.1.4.0=\u0026lt;downloaded-patches-location\u0026gt;/p33578966_122140_Generic.zip   Provide the following arguments to the WebLogic Image Tool update command:\n –-fromImage - Identify the image that needs to be updated. In the example below, the image to be updated is wccontent:12.2.1.4.0. –-patches - Multiple patches can be specified as a comma-separated list. --tag - Specify the new tag to be applied for the image being built.  Refer here for the complete list of options available with the WebLogic Image Tool update command.\n Note: The WebLogic Image Tool cache should have the latest OPatch zip. The WebLogic Image Tool will update the OPatch if it is not already updated in the image.\n Examples     Click here to see the example `update` command:    # If you are using a pre-built Oracle WebCenter Content image, obtained from My Oracle Support, then please use this command: $ imagetool update --fromImage oracle/wccontent:12.2.1.4.0 --tag=oracle/wccontent_update_1015:12.2.1.4.0 --patches=33578966_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.8 # In case, you chose to build an Oracle WebCenter Content image, please use the command given below: $ imagetool update --chown oracle:root --fromImage oracle/wccontent:12.2.1.4.0 --tag=oracle/wccontent_update_1015:12.2.1.4.0 --patches=33578966_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.8     Check the built image using the docker images command: $ docker images | grep wcc   Create an Oracle WebCenter Content Docker image using Dockerfile For test and development purposes, you can create an Oracle WebCenter Content image using the Dockerfile. Consult the README file for important prerequisite steps, such as building or pulling the Server JRE Docker image, Oracle FMW Infrastructure Docker image, and downloading the Oracle WebCenter Content installer and bundle patch binaries.\nA prebuilt Oracle Fusion Middleware Infrastructure image, container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4-210407, is available at container-registry.oracle.com. We recommend that you pull and rename this image to build the Oracle WebCenter Content image.\n$ docker pull container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4-210407 $ docker tag container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4-210407 oracle/fmw-infrastructure:12.2.1.4.0 Follow these steps to build an Oracle WebCenter Content image :\n  Make a local clone of the sample repository:\n$ git clone https://github.com/oracle/docker-images   Download the Oracle WebCenter Content installer from the Oracle Technology Network or e-delivery.\n Note: Copy the installer binaries to the same location as the Dockerfile.\n   Create the Oracle WebCenter Content image by running the provided script:\n$ cd docker-images/OracleWebCenterContent/dockerfiles $ ./buildDockerImage.sh -v 12.2.1.4 -s The image produced will be named oracle/wccontent:12.2.1.4. The samples and instructions assume the Oracle WebCenter Content image is named wccontent:12.2.1.4.0. You must rename your image to match this name, or update the samples to refer to the image you created.\n$ docker tag oracle/wccontent:12.2.1.4 wccontent:12.2.1.4.0   "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/logging-fluentd-setup/",
	"title": "Publish logs to Elasticsearch Using Fluentd",
	"tags": [],
	"description": "Configure a WebLogic domain to use Fluentd to send log information to Elasticsearch.",
	"content": "Introduction This page describes to how to configure a WebLogic domain to use Fluentd to send log information to Elasticsearch. Here’s the general mechanism for how this works:\n fluentd runs as a separate container in the Administration Server and Managed Server pods The log files reside on a volume that is shared between the weblogic-server and fluentd containers fluentd tails the domain logs files and exports them to Elasticsearch A ConfigMap contains the filter and format rules for exporting log records.  Create fluentd configuration Create a ConfigMap named fluentd-config in the namespace of the domain. The ConfigMap contains the parsing rules and Elasticsearch configuration. Here’s an explanation of some elements defined in the ConfigMap:\n The @type tail indicates that tail will be used to obtain updates to the log file The path of the log file is obtained from the LOG_PATH environment variable that is defined in the fluentd container The tag value of log records is obtained from the DOMAIN_UID environment variable that is defined in the fluentd container The parse section defines how to interpret and tag each element of a log record The match section contains the configuration information for connecting to Elasticsearch and defines the index name of each record to be the domainUID  Here is a sample configmap for fluentd configuration,\n  Click here to see sample configmap for fluentd configuration `fluentd_configmap.yaml`.   apiVersion: v1 kind: ConfigMap metadata: labels: weblogic.domainUID: wccinfra weblogic.resourceVersion: domain-v2 name: fluentd-config namespace: wccns data: fluentd.conf: | \u0026lt;match fluent.**\u0026gt; @type null \u0026lt;/match\u0026gt; \u0026lt;source\u0026gt; @type tail path \u0026quot;#{ENV['LOG_PATH']}\u0026quot; pos_file /tmp/server.log.pos read_from_head true tag \u0026quot;#{ENV['DOMAIN_UID']}\u0026quot; # multiline_flush_interval 20s \u0026lt;parse\u0026gt; @type multiline format_firstline /^####/ format1 /^####\u0026lt;(?\u0026lt;timestamp\u0026gt;(.*?))\u0026gt;/ format2 / \u0026lt;(?\u0026lt;level\u0026gt;(.*?))\u0026gt;/ format3 / \u0026lt;(?\u0026lt;subSystem\u0026gt;(.*?))\u0026gt;/ format4 / \u0026lt;(?\u0026lt;serverName\u0026gt;(.*?))\u0026gt;/ format5 / \u0026lt;(?\u0026lt;serverName2\u0026gt;(.*?))\u0026gt;/ format6 / \u0026lt;(?\u0026lt;threadName\u0026gt;(.*?))\u0026gt;/ format7 / \u0026lt;(?\u0026lt;info1\u0026gt;(.*?))\u0026gt;/ format8 / \u0026lt;(?\u0026lt;info2\u0026gt;(.*?))\u0026gt;/ format9 / \u0026lt;(?\u0026lt;info3\u0026gt;(.*?))\u0026gt;/ format10 / \u0026lt;(?\u0026lt;sequenceNumber\u0026gt;(.*?))\u0026gt;/ format11 / \u0026lt;(?\u0026lt;severity\u0026gt;(.*?))\u0026gt;/ format12 / \u0026lt;(?\u0026lt;messageID\u0026gt;(.*?))\u0026gt;/ format13 / \u0026lt;(?\u0026lt;message\u0026gt;(.*?))\u0026gt;/ \u0026lt;/parse\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;match **\u0026gt; @type elasticsearch host \u0026quot;#{ENV['ELASTICSEARCH_HOST']}\u0026quot; port \u0026quot;#{ENV['ELASTICSEARCH_PORT']}\u0026quot; user \u0026quot;#{ENV['ELASTICSEARCH_USER']}\u0026quot; password \u0026quot;#{ENV['ELASTICSEARCH_PASSWORD']}\u0026quot; index_name \u0026quot;#{ENV['DOMAIN_UID']}\u0026quot; \u0026lt;/match\u0026gt;    Create the ConfigMap using the following command\n$kubectl create -f fluentd_configmap.yaml Mount fluentd configuration - Configmap as volume in the WebLogic container. Edit the domain definition and configure a volume for the ConfigMap containing the fluentd configuration.\n$kubectl edit domain -n wccns Below sample yaml code add Configmap as volume,\n volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc - configMap: defaultMode: 420 name: fluentd-config name: fluentd-config-volume Add fluentd container to WebLogic Server pods Add a \u0026ldquo;fluentd container yaml\u0026rdquo; to the domain under serverPod: section that will run fluentd in the Administration Server and Managed Server pods.\nNotice the container definition:\n Defines a LOG_PATH environment variable that points to the log location of WebLogic servers. Defines ELASTICSEARCH_HOST, ELASTICSEARCH_PORT, ELASTICSEARCH_USER, and ELASTICSEARCH_PASSWORD environment variables. Has volume mounts for the fluentd-config ConfigMap and the volume containing the domain logs.  $kubectl edit domain -n wccns    Click here to see sample fluentd container yaml `fluentd container`.   containers: - args: - -c - /etc/fluent.conf env: - name: DOMAIN_UID valueFrom: fieldRef: fieldPath: metadata.labels['weblogic.domainUID'] - name: SERVER_NAME valueFrom: fieldRef: fieldPath: metadata.labels['weblogic.serverName'] - name: LOG_PATH value: /u01/oracle/user_projects/domains/logs/wccinfra/$(SERVER_NAME).log - name: FLUENTD_CONF value: fluentd.conf - name: FLUENT_ELASTICSEARCH_SED_DISABLE value: \u0026quot;true\u0026quot; - name: ELASTICSEARCH_HOST value: elasticsearch.default.svc.cluster.local - name: ELASTICSEARCH_PORT value: \u0026quot;9200\u0026quot; - name: ELASTICSEARCH_USER value: elastic - name: ELASTICSEARCH_PASSWORD value: changeme image: fluent/fluentd-kubernetes-daemonset:v1.3.3-debian-elasticsearch-1.3 imagePullPolicy: IfNotPresent name: fluentd resources: {} volumeMounts: - mountPath: /fluentd/etc/fluentd.conf name: fluentd-config-volume subPath: fluentd.conf - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume    Restart WebLogic Servers To restart the servers, edit the domain and change serverStartPolicy to NEVER for the WebLogic servers to shutdown\n$kubectl edit domain -n wccns After all the servers are shutdown edit domain again and set serverStartPolicy to IF_NEEDED for the servers to start again.\nCreate index pattern in Kibana Create an index pattern \u0026ldquo;wccinfra*\u0026rdquo; in Kibana \u0026gt; Management. After the server starts, you will be able to see the log data in the Kibana dashboard,\n"
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/cleanup-domain-setup/",
	"title": "Uninstall",
	"tags": [],
	"description": "Clean up the Oracle WebCenter Content domain setup.",
	"content": "Learn how to clean up the Oracle WebCenter Content domain setup.\nStop all Administration and Managed server pods First stop the all pods related to a domain. This can be done by patching domain \u0026ldquo;serverStartPolicy\u0026rdquo; to \u0026ldquo;NEVER\u0026rdquo;. Here is the sample command for the same.\n$ kubectl patch domain wcc-domain-name -n wcc-namespace --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/serverStartPolicy\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NEVER\u0026#34; }]\u0026#39; For example:\nkubectl patch domain wccinfra -n wccns --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/serverStartPolicy\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NEVER\u0026#34; }]\u0026#39; Remove the domain   Remove the domain\u0026rsquo;s ingress (for example, Traefik ingress) using Helm:\n$ helm uninstall wcc-domain-ingress -n sample-domain1-ns For example:\n$ helm uninstall wccinfra-traefik -n wccns   Remove the domain resources by using the sample delete-weblogic-domain-resources.sh script present at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/delete-domain:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/delete-domain $ ./delete-weblogic-domain-resources.sh -d sample-domain1 For example:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/delete-domain $ ./delete-weblogic-domain-resources.sh -d wccinfra   Use kubectl to confirm that the server pods and domain resource are deleted:\n$ kubectl get pods -n sample-domain1-ns $ kubectl get domains -n sample-domain1-ns For example:\n$ kubectl get pods -n wccns $ kubectl get domains -n wccns   Drop the RCU schemas Follow these steps to drop the RCU schemas created for Oracle WebCenter Content domain.\nRemove the domain namespace   Configure the installed ingress load balancer (for example, Traefik) to stop managing the ingresses in the domain namespace:\n$ helm upgrade traefik-operator traefik/traefik \\  --namespace traefik \\  --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --wait   Configure the WebLogic Kubernetes Operator to stop managing the domain:\n$ helm upgrade sample-weblogic-operator \\  kubernetes/charts/weblogic-operator \\  --namespace sample-weblogic-operator-ns \\  --reuse-values \\  --set \u0026#34;domainNamespaces={}\u0026#34; \\  --wait For example:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade weblogic-kubernetes-operator \\  kubernetes/charts/weblogic-operator \\  --namespace opns \\  --reuse-values \\  --set \u0026#34;domainNamespaces={}\u0026#34; \\  --wait   Delete the domain namespace:\n$ kubectl delete namespace sample-domain1-ns For example:\n$ kubectl delete namespace wccns   Remove the WebLogic Kubernetes Operator   Remove the WebLogic Kubernetes Operator:\n$ helm uninstall sample-weblogic-operator -n sample-weblogic-operator-ns For example:\n$ helm uninstall weblogic-kubernetes-operator -n opns   Remove WebLogic Kubernetes Operator\u0026rsquo;s namespace:\n$ kubectl delete namespace sample-weblogic-operator-ns For example:\n$ kubectl delete namespace opns   Remove the load balancer   Remove the installed ingress based load balancer (for example, Traefik):\n$ helm uninstall traefik -n traefik   Remove the Traefik namespace:\n$ kubectl delete namespace traefik   Delete the domain home To remove the domain home that is generated using the create-domain.sh script, with appropriate privileges manually delete the contents of the storage attached to the domain home persistent volume (PV).\nFor example, for the domain\u0026rsquo;s persistent volume of type host_path:\n$ rm -rf /scratch/k8s_dir/WCC "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/adminguide/configure-mount-share/",
	"title": "Configure an additional mount or shared space to a domain for Imaging and Capture",
	"tags": [],
	"description": "Configure an additional mount or shared space to a domain, for WebCenter Imaging and WebCenter Capture",
	"content": "A volume can be mounted to a server pod which can be accessible directly from outside Kubernetes cluster so that an external application could write new files to it.\nThis can be used specifically in WebCenter Imaging and WebCenter Capture applications for File Imports.\nKubernetes supports several types of volumes as given in Volumes | Kubernetes.\nFurther in this section, we will take nfs volume as an example.\nMount \u0026ldquo;nfs\u0026rdquo; as volume To use a volume, specify the volumes to provide for the Pod in .spec.volumes and declare where to mount those volumes into containers in .spec.containers[*].volumeMounts in domain.yaml file.\nUpdate the domain.yaml and apply the changes as shown in sample below for mounting nfs server (for example, 100.XXX.XXX.X with shared export path at /sharedir) to all the server pods at /u01/sharedir.\nThe path /u01/sharedir can be configured as the file import path in WebCenter Imaging and WebCenter Capture applications and the files put to /sharedir will be processed by the applications.\nSample entry of domain.yaml with nfs-volume configuration\n... serverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026#34;-Dweblogic.StdoutDebugEnabled=false\u0026#34; - name: USER_MEM_ARGS value: \u0026#34;-Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx1024m \u0026#34; volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc - name: nfs-volume nfs: server: 100.XXX.XXX.XXX path: /sharedir volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume - mountPath: /u01/sharedir name: nfs-volume ... "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/oracle-cloud/",
	"title": "Oracle Cloud Infrastructure",
	"tags": [],
	"description": "",
	"content": "This is a guide to run WebLogic Kubernetes Operator managed WebCenter Content domain on Oracle Cloud Infrastructure. This section of the documentation is certified for WebLogic Kubernetes Operator version 3.3.0 and Oracle WebCenter Content 12.2.1.4 Jan'22 PSU (container image for this release can be downloaded from My Oracle Support MOS patch 33771196).\n Preparing an OKE environment  Running WebLogic Kubernetes Operator managed WebCenter Content domain on Oracle Kubernetes Engine (OKE).\n Preparing a file system  Running WebLogic Kubernetes Operator managed Oracle WebCenter Content domains on OKE\n Preparing OCIR  Running WebLogic Kubernetes Operator managed Oracle WebCenter Content domains on OKE\n Prepare environment for WCC domain  Prepare environment for WCC domain on Oracle Kubernetes Engine (OKE).\n Set up a load balancer  Configure different load balancers for Oracle WebCenter Content domains.\n Create Oracle WebCenter Content domain  Create Oracle WebCenter Content domain on Oracle Kubernetes Engine (OKE).\n Configuring Oracle WebCenter Content for Oracle Identity Cloud Service (IDCS)  Configuring Oracle WebCenter Content for Oracle Identity Cloud Service (IDCS)\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/",
	"title": "Oracle WebCenter Content",
	"tags": [],
	"description": "WebLogic Kubernetes Operator (the “operator”) supports deployment of Oracle WebCenter Content servers such as Oracle WebCenter Content(Content Server) and Oracle WebCenter Content(Inbound Refinery Server). Follow the instructions in this guide to set up Oracle WebCenter Content domain on Kubernetes.",
	"content": "In this release, Oracle WebCenter Content domain is supported using the “domain on a persistent volume” model only, where the domain home is located in a persistent volume (PV).\nThe WebLogic Kubernetes Operator has several key features to assist you with deploying and managing Oracle WebCenter Content domain in a Kubernetes environment. You can:\n Create Oracle WebCenter Content instances(Oracle WebCenter Content server \u0026amp; Oracle WebCenter Content Inbounnd Refinery server) in a Kubernetes persistent volume (PV). This PV can reside in an NFS file system or other Kubernetes volume types. Start servers based on declarative startup parameters and desired states. Expose the Oracle WebCenter Content services and composites for external access. Scale Oracle WebCenter Content domains by starting and stopping Managed Servers on demand, or by integrating with a REST API. Publish WebLogic Kubernetes Operator and WebLogic Server logs to Elasticsearch and interact with them in Kibana. Monitor the Oracle WebCenter Content instance using Prometheus and Grafana.  Current production release The current supported production release of WebLogic Kubernetes Operator, for Oracle WebCenter Content domain deployment is 3.3.0.\nRecent changes See the Release Notes for recent changes for Oracle WebCenter Content domain deployment on Kubernetes.\nLimitations See here for limitations in this release.\nAbout this documentation This documentation includes sections targeted to different audiences. To help you find what you are looking for easily, please consult this table of contents:\n  Quick Start explains how to quickly get an Oracle WebCenter Content instance running, using the defaults. Note that this is only for development and test purposes.\n  Install Guide and Administration Guide provide detailed information about all aspects of using WebLogic Kubernetes Operator including:\n Installing and configuring WebLogic Kubernetes Operator. Using WebLogic Kubernetes Operator to create and manage Oracle WebCenter Content domain. Configuring Kubernetes load balancers. Configuring Custom SSL certificates. Configuring Elasticsearch and Kibana to access the WebLogic Kubernetes Operator and WebLogic Server log files. Deploying composite applications for Oracle WebCenter Content. Patching an Oracle WebCenter Content Docker image. Removing/deleting domain. And much more!    Additional reading Oracle WebCenter Content domain deployment on Kubernetes leverages WebLogic Kubernetes Operator framework.\n To develop an understanding of WebLogic Kubernetes Operator, including design, architecture, domain life cycle management, and configuration overrides, review the WebLogic Kubernetes Operator documentation. To learn more about the Oracle WebCenter Content architecture and components, see Understanding Oracle WebCenter Content.  "
},
{
	"uri": "/fmw-kubernetes/22.1.3/wccontent-domains/appendix/",
	"title": "Appendix",
	"tags": [],
	"description": "",
	"content": "This section provides information on miscellaneous tasks related to Oracle WebCenter Content domain deployment on Kubernetes.\n Domain resource sizing  Describes the resourse sizing information for Oracle WebCenter Content domain setup on Kubernetes cluster.\n Quick start deployment guide  Describes how to quickly get an Oracle WebCenter Content domain instance running (using the defaults, nothing special) for development and test purposes.\n Security hardening  Review resources for the Docker and Kubernetes cluster hardening.\n "
},
{
	"uri": "/fmw-kubernetes/22.1.3/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/fmw-kubernetes/22.1.3/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]
