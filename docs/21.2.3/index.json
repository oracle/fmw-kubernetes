[
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/appendix/wcc-cluster-sizing-info/",
	"title": "Domain resource sizing",
	"tags": [],
	"description": "Describes the resourse sizing information for Oracle WebCenter Content domain setup on Kubernetes cluster.",
	"content": "Oracle WebCenter Content cluster sizing recommendations    Oracle WCC Normal Usage Moderate Usage High Usage     Administration Server No of CPU core(s) : 1, Memory : 4GB No of CPU core(s) : 1, Memory : 4GB No of CPU core(s) : 1, Memory : 4GB   Number of Managed Servers 2 3 5   Configurations per Managed Server No of CPU core(s) : 2, Memory : 16GB No of CPU core(s) : 4, Memory : 16GB No of CPU core(s) : 6, Memory : 16-32GB   PV Storage Minimum 250GB Minimum 250GB Minimum 500GB    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/configure-load-balancer/",
	"title": "Set up a load balancer",
	"tags": [],
	"description": "Configure different load balancers for Oracle WebCenter Content domains.",
	"content": "The Oracle WebLogic Server Kubernetes operator supports ingress-based load balancers such as Traefik, NGINX (kubernetes/ingress-nginx) and Voyager. It also supports Apache webtier load balancer.\n Traefik  Configure the ingress-based Traefik load balancer for Oracle WebCenter Content domains.\n NGINX  Configure the ingress-based NGINX load balancer for Oracle WebCenter Content domain.\n Voyager  Configure the ingress-based Voyager load balancer for Oracle WebCenter Content domain.\n Apache webtier  Configure the Apache webtier load balancer for Oracle WebCenter Content domain.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/",
	"title": "Oracle Fusion Middleware on Kubernetes",
	"tags": [],
	"description": "This document lists all the Oracle Fusion Middleware products deployment supported on Kubernetes.",
	"content": "Oracle Fusion Middleware on Kubernetes Oracle supports the deployment of the following Oracle Fusion Middleware products on Kubernetes. Click on the appropriate document link below to get started on setting up the product.\n Oracle WebCenter Content  The Oracle WebLogic Server Kubernetes Operator (the “operator”) supports deployment of Oracle WebCenter Content servers such as Oracle WebCenter Content(Content Server) and Oracle WebCenter Content(Inbound Refinery Server). Follow the instructions in this guide to set up Oracle WebCenter Content domain on Kubernetes.\n Oracle WebCenter Portal  The WebLogic Kubernetes operator (the “operator”) supports deployment of Oracle WebCenter Portal. Follow the instructions in this guide to set up Oracle WebCenter Portal domain on Kubernetes.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/appendix/wcp-cluster-sizing-info/",
	"title": "Domain resource sizing",
	"tags": [],
	"description": "Describes the resourse sizing information for the Oracle WebCenter Portal domain setup on Kubernetes cluster.",
	"content": "Oracle WebCenter Portal cluster sizing recommendations    WebCenter Portal Normal Usage Moderate Usage High Usage     Admin Server No of CPU(s) : 1, Memory : 4GB No of CPU(s) : 1, Memory : 4GB No of CPU(s) : 1, Memory : 4GB   Number of Managed Server No of Servers : 2 No of Servers : 2 No of Servers : 3   Configurations per Managed Server No of CPU(s) : 2, Memory : 16GB No of CPU(s) : 4, Memory : 16GB No of CPU(s) : 6, Memory : 16-32GB   PV Storage Minimum 250GB Minimum 250GB Minimum 500GB    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/configure-load-balancer/",
	"title": "Set up a load balancer",
	"tags": [],
	"description": "Configure different load balancers for the Oracle WebCenter Portal domain.",
	"content": "The WebLogic Kubernetes Operator supports ingress-based load balancers such as Traefik, NGINX (kubernetes/ingress-nginx) and Voyager. It also supports the Apache webtier load balancer.\n Traefik  Configure the ingress-based Traefik load balancer for an Oracle WebCenter Portal domain.\n NGINX  Configure the ingress-based NGINX load balancer for an Oracle WebCenter Portal domain.\n Voyager  Configure the ingress-based Voyager load balancer for an Oracle WebCenter Portal domain.\n Apache webtier  Configure the Apache webtier load balancer for an Oracle WebCenter Portal domain.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/configure-load-balancer/traefik/",
	"title": "Traefik",
	"tags": [],
	"description": "Configure the ingress-based Traefik load balancer for an Oracle WebCenter Portal domain.",
	"content": "To load balance Oracle WebCenter Portal domain clusters, you can install the ingress-based Traefik load balancer (version 2.2.1 or later for production deployments) and configure it for non-SSL, SSL termination, and end-to-end SSL access of the application URL. Follow these steps to set up Traefik as a load balancer for an Oracle WebCenter Portal domain in a Kubernetes cluster:\n  Non-SSL and SSL termination\n Install the Traefik (ingress-based) load balancer Configure Traefik to manage ingresses Create an Ingress for the domain Verify domain application URL access Uninstall the Traefik ingress    End-to-end SSL configuration\n Install the Traefik load balancer for End-to-end SSL Configure Traefik to manage domain Create IngressRouteTCP Verify end-to-end SSL access Uninstall Traefik    Non-SSL and SSL termination Install the Traefik (ingress-based) load balancer   Use Helm to install the Traefik (ingress-based) load balancer. You can use the following values.yaml sample file and set kubernetes.namespaces as required.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --set \u0026#34;service.type=NodePort\u0026#34; --wait    Click here to see the sample output.   LAST DEPLOYED: Sun Sep 13 21:32:00 2020 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None    A sample values.yaml for deployment of Traefik 2.2.x looks like this:\nimage: name: traefik tag: 2.2.8 pullPolicy: IfNotPresent ingressRoute: dashboard: enabled: true annotations: {} labels: {} providers: kubernetesCRD: enabled: true kubernetesIngress: enabled: true ports: traefik: port: 9000 expose: true exposedPort: 9000 protocol: TCP web: port: 8000 expose: true exposedPort: 30305 nodePort: 30305 protocol: TCP websecure: port: 8443 expose: true exposedPort: 30443 protocol: TCP nodePort: 30443   Verify the Traefik status and find the port number of the SSL and non-SSL services:\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-f9cf58697-29dlx 1/1 Running 0 35s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik NodePort 10.100.113.37 \u0026lt;none\u0026gt; 9000:30070/TCP,30305:30305/TCP,30443:30443/TCP 35s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 36s NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-f9cf58697 1 1 1 36s      Access the Traefik dashboard through the URL http://$(hostname -f):30070, with the HTTP host traefik.example.com:\n$ curl -H \u0026#34;host: $(hostname -f)\u0026#34; http://$(hostname -f):30070/dashboard/  Note: Make sure that you specify a fully qualified node name for $(hostname -f)\n   Configure Traefik to manage ingresses Configure Traefik to manage ingresses created in this namespace. In the following sample, traefik is the Traefik namespace and wcpns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik \\ --reuse-values \\ --namespace traefik \\ --set \u0026#34;kubernetes.namespaces={traefik,wcpns}\u0026#34; \\ --wait    Click here to see the sample output.   Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Tue Jan 12 04:33:15 2021 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create an ingress for the domain Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK , tls is Non-SSL. You can override these values by passing values through the command line or edit them in the sample values.yaml file based on the type of configuration (non-SSL or SSL). If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. The template YAML file for the Traefik (ingress-based) load balancer is located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/traefik-ingress.yaml\n  Install ingress-per-domain using Helm for non-SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcp-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --namespace wcpns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=$(hostname -f)\u0026#34; Sample output:\nNAME: wcp-traefik-ingress LAST DEPLOYED: Mon Jul 20 11:44:13 2020 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None   For secured access (SSL) to the Oracle WebCenter Portal application, create a certificate and generate a Kubernetes secret:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wcpns create secret tls wcpinfra-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt  Note: The value of CN is the host on which this ingress is to be deployed.\n   Create a Traefik Middleware custom resource\nIn case of SSL termination, Traefik must pass a custom header WL-Proxy-SSL:true to the WebLogic Server endpoints. Create the Middleware using the following command:\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: wls-proxy-ssl namespace: wcpns spec: headers: customRequestHeaders: WL-Proxy-SSL: \u0026#34;true\u0026#34; EOF   Create the Traefik TLSStore custom resource.\nIn case of SSL termination, Traefik should be configured to use the user-defined SSL certificate. If the user-defined SSL certificate is not configured, Traefik creates a default SSL certificate. To configure a user-defined SSL certificate for Traefik, use the TLSStore custom resource. The Kubernetes secret created with the SSL certificate should be referenced in the TLSStore object. Run the following command to create the TLSStore:\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: TLSStore metadata: name: default namespace: wcpns spec: defaultCertificate: secretName: wcpinfra-tls-cert EOF   Install ingress-per-domain using Helm for SSL configuration.\nThe Kubernetes secret name should be updated in the template file.\nThe template file also contains the following annotations:\ntraefik.ingress.kubernetes.io/router.entrypoints: websecure traefik.ingress.kubernetes.io/router.tls: \u0026#34;true\u0026#34; traefik.ingress.kubernetes.io/router.middlewares: wcpns-wls-proxy-ssl@kubernetescrd The entry point for SSL access and the Middleware name should be updated in the annotation. The Middleware name should be in the form \u0026lt;namespace\u0026gt;-\u0026lt;middleware name\u0026gt;@kubernetescrd.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcp-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --namespace wcpns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=$(hostname -f)\u0026#34; \\  --set tls=SSL Sample output:\nNAME: wcp-traefik-ingress LAST DEPLOYED: Mon Jul 20 11:44:13 2020 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None   For non-SSL access to the Oracle WebCenter Portal application, get the details of the services by the ingress:\n$ kubectl describe ingress wcp-domain-traefik -n wcpns    Click here to see all services supported by the above deployed ingress.   Name: wcp-domain-traefik Namespace: wcpns Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026#34;default-http-backend\u0026#34; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- www.example.com /webcenter wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /console wcp-domain-adminserver:7001 (10.244.0.51:7001) /rsscrawl wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /rest wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /webcenterhelp wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /em wcp-domain-adminserver:7001 (10.244.0.51:7001) Annotations: kubernetes.io/ingress.class: traefik meta.helm.sh/release-name: wcp-traefik-ingress meta.helm.sh/release-namespace: wcpns Events: \u0026lt;none\u0026gt;      For SSL access to the Oracle WebCenter Portal application, get the details of the services by the above deployed ingress:\n$ kubectl describe ingress wcp-domain-traefik -n wcpns    Click here to see all services supported by the above deployed ingress.   Name: wcp-domain-traefik Namespace: wcpns Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) TLS: wcpinfra-tls-cert terminates www.example.com Rules: Host Path Backends ---- ---- -------- www.example.com /webcenter wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /console wcp-domain-adminserver:7001 (10.244.0.51:7001) /rsscrawl wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /rest wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /webcenterhelp wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /em wcp-domain-adminserver:7001 (10.244.0.51:7001) Annotations: kubernetes.io/ingress.class: traefik meta.helm.sh/release-name: wcp-traefik-ingress meta.helm.sh/release-namespace: wcpns traefik.ingress.kubernetes.io/router.entrypoints: websecure traefik.ingress.kubernetes.io/router.middlewares: wcpns-wls-proxy-ssl@kubernetescrd traefik.ingress.kubernetes.io/router.tls: true Events: \u0026lt;none\u0026gt;      To confirm that the load balancer noticed the new ingress and is successfully routing to the domain server pods, you can send a request to the URL for the WebLogic ReadyApp framework, which should return an HTTP 200 status code, as follows:\n$ curl -v http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER_PORT}/weblogic/ready * Trying 149.87.129.203... \u0026gt; GET http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER_PORT}/weblogic/ready HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Accept: */* \u0026gt; Proxy-Connection: Keep-Alive \u0026gt; host: $(hostname -f) \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Sat, 14 Mar 2020 08:35:03 GMT \u0026lt; Vary: Accept-Encoding \u0026lt; Content-Length: 0 \u0026lt; Proxy-Connection: Keep-Alive \u0026lt; * Connection #0 to host localhost left intact   Verify domain application URL access For non-SSL configuration After setting up the Traefik (ingress-based) load balancer, verify that the domain application URLs are accessible through the non-SSL load balancer port 30305 for HTTP access. The sample URLs for Oracle WebCenter Portal domain are:\nhttp://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenter http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rsscrawl http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rest http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenterhelp For SSL configuration After setting up the Traefik (ingress-based) load balancer, verify that the domain applications are accessible through the SSL load balancer port 30443 for HTTPS access. The sample URLs for Oracle WebCenter Portal domain are:\nhttps://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenter https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/rsscrawl https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/rest https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenterhelp Uninstall the Traefik ingress Uninstall and delete the ingress deployment:\n$ helm delete wcp-traefik-ingress -n wcpns End-to-end SSL configuration Install the Traefik load balancer for end-to-end SSL   Use Helm to install the Traefik (ingress-based) load balancer. You can use the values.yaml sample file and set kubernetes.namespaces as required.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --set \u0026#34;service.type=NodePort\u0026#34; --wait    Click here to see the sample output.   LAST DEPLOYED: Sun Sep 13 21:32:00 2020 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None      Verify the Traefik operator status and find the port number of the SSL and non-SSL services:\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-845f5d6dbb-swb96 1/1 Running 0 32s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik NodePort 10.99.52.249 \u0026lt;none\u0026gt; 9000:31288/TCP,30305:30305/TCP,30443:30443/TCP 32s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 33s NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-845f5d6dbb 1 1 1 33s      Access the Traefik dashboard through the URL http://$(hostname -f):31288, with the HTTP host traefik.example.com:\n$ curl -H \u0026#34;host: $(hostname -f)\u0026#34; http://$(hostname -f):31288/dashboard/  Note: Make sure that you specify a fully qualified node name for $(hostname -f).\n   Configure Traefik to manage the domain Configure Traefik to manage the domain application service created in this namespace. In the following sample, traefik is the Traefik namespace and wcpns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik --namespace traefik --reuse-values \\ --set \u0026#34;kubernetes.namespaces={traefik,wcpns}\u0026#34;    Click here to see the sample output.   Release \u0026quot;traefik\u0026quot; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Sun Sep 13 21:32:12 2020 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create IngressRouteTCP   For each backend service, create different ingresses, as Traefik does not support multiple paths or rules with annotation ssl-passthrough. For example, for wcp-domain-adminserver and wcp-domain-cluster-wcp-cluster, different ingresses must be created.\n  To enable SSL passthrough in Traefik, you can configure a TCP router. A sample YAML for IngressRouteTCP is available at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls/traefik-tls.yaml. The following should be updated in traefik-tls.yaml:\n The service name and the SSL port should be updated in the services. The load balancer host name should be updated in the HostSNI rule.  Sample traefik-tls.yaml:\napiVersion: traefik.containo.us/v1alpha1 kind: IngressRouteTCP metadata: name: wcp-domain-cluster-routetcp namespace: wcpns spec: entryPoints: - websecure routes: - match: HostSNI(`${LOADBALANCER_HOSTNAME}`) services: - name: wcp-domain-cluster-wcp-cluster port: 8888 weight: 3 TerminationDelay: 400 tls: passthrough: true   Create the IngressRouteTCP:\n$ kubectl apply -f traefik-tls.yaml   Verify end-to-end SSL access Verify the access to application URLs exposed through the configured service. The configured WCP cluster service enables you to access the following WCP domain URLs:\nhttps://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenter https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/rsscrawl https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/rest https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenterhelp Uninstall Traefik $ helm delete traefik -n traefik $ cd weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl delete -f traefik-tls.yaml "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/monitoring-and-publishing-logs/publishing-logs/fluentd/",
	"title": " Fluentd",
	"tags": [],
	"description": "Describes how to configure a WebCenter Portal domain to use Fluentd to send log information to Elasticsearch.",
	"content": "Overview You can configure your WebLogic domain to use Fluentd so it can send the log information to Elasticsearch.\nHere\u0026rsquo;s how this works:\n fluentd runs as a separate container in the Administration Server and Managed Server pods. The log files reside on a volume that is shared between the weblogic-server and fluentd containers. fluentd tails the domain logs files and exports them to Elasticsearch. A ConfigMap contains the filter and format rules for exporting log records.  Prerequisites It is assumed that you are editing an existing WebCenter Portal domain. However, you can make all the changes to the domain YAML before creating the domain. A complete example of a domain definition with fluentd configuration is at the end of this document.\nThese identifiers are used in the sample commands.\n wcpns: WebCenter Portal domain namespace wcp-domain: domainUID wcpinfra-domain-credentials: Kubernetes secret   The sample Elasticsearch configuration is:\nelasticsearchhost: elasticsearch.wcp-domain.sample.com elasticsearchport: 443 elasticsearchuser: username elasticsearchpassword: password Install Elasticsearch and Kibana To install Elasticsearch and Kibana, run the following command:\n$ kubectl apply -f kubernetes/samples/scripts/elasticsearch-and-kibana/elasticsearch_and_kibana.yaml Configure log files to use a volume The domain log files must be written to a volume that can be shared between the weblogic-server and fluentd containers. The following elements are required to accomplish this:\n logHome must be a path that can be shared between containers. logHomeEnabled must be set to true so that the logs are written outside the pod and persist across pod restarts. A volume must be defined on which the log files will reside. In the example, emptyDir is a volume that gets created when a Pod is created. It will persist across pod restarts but deleting the pod would delete the emptyDir content. The volumeMounts mounts the named volume created with emptyDir and establishes the base path for accessing the volume.  NOTE: For brevity, only the paths to the relevant configuration are here.\nFor Example, run : kubectl edit domain wcp-domain -n wcpns and make the following edits:\nspec: logHome: /u01/oracle/user_projects/domains/logs/wcp-domain logHomeEnabled: true serverPod: volumes: - emptyDir: {} name: weblogic-domain-storage-volume volumeMounts: - mountPath: /scratch name: weblogic-domain-storage-volume Add Elasticsearch secrets to WebLogic domain credentials Configure the fluentd container to look for Elasticsearch parameters in the domain credentials. Edit the domain credentials and add the parameters shown in the example below.\nFor example, run: kubectl edit secret wcpinfra-domain-credentials -n wcpns and add the base64 encoded values of each Elasticsearch parameter:\nelasticsearchhost: ZWxhc3RpY3NlYXJjaC5ib2JzLWJvb2tzLnNhbXBsZS5jb20= elasticsearchport: NDQz elasticsearchuser: Ym9i elasticsearchpassword: d2VsY29tZTE= Create Fluentd configuration Create a ConfigMap named fluentd-config in the namespace of the domain. The ConfigMap contains the parsing rules and Elasticsearch configuration.\nHere\u0026rsquo;s an explanation of some elements defined in the ConfigMap:\n The @type tail indicates that tail is used to obtain updates to the log file. The path of the log file obtained from the LOG_PATH environment variable that is defined in the fluentd container. The tag value of log records obtained from the DOMAIN_UID environment variable that is defined in the fluentd container. The \u0026lt;parse\u0026gt; section defines how to interpret and tag each element of a log record. The \u0026lt;match **\u0026gt; section contains the configuration information for connecting to Elasticsearch and defines the index name of each record to be the domainUID. The scheme indicates type of connection between fluentd and Elasticsearch.  The following is an example of how to create the ConfigMap:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ConfigMap metadata: labels: weblogic.domainUID: wcp-domain weblogic.resourceVersion: domain-v2 name: fluentd-config namespace: wcpns data: fluentd.conf: | \u0026lt;match fluent.**\u0026gt; @type null \u0026lt;/match\u0026gt; \u0026lt;source\u0026gt; @type tail path \u0026#34;#{ENV[\u0026#39;LOG_PATH\u0026#39;]}\u0026#34; pos_file /tmp/server.log.pos read_from_head true tag \u0026#34;#{ENV[\u0026#39;DOMAIN_UID\u0026#39;]}\u0026#34; # multiline_flush_interval 20s \u0026lt;parse\u0026gt; @type multiline format_firstline /^####/ format1 /^####\u0026lt;(?\u0026lt;timestamp\u0026gt;(.*?))\u0026gt;/ format2 / \u0026lt;(?\u0026lt;level\u0026gt;(.*?))\u0026gt;/ format3 / \u0026lt;(?\u0026lt;subSystem\u0026gt;(.*?))\u0026gt;/ format4 / \u0026lt;(?\u0026lt;serverName\u0026gt;(.*?))\u0026gt;/ format5 / \u0026lt;(?\u0026lt;serverName2\u0026gt;(.*?))\u0026gt;/ format6 / \u0026lt;(?\u0026lt;threadName\u0026gt;(.*?))\u0026gt;/ format7 / \u0026lt;(?\u0026lt;info1\u0026gt;(.*?))\u0026gt;/ format8 / \u0026lt;(?\u0026lt;info2\u0026gt;(.*?))\u0026gt;/ format9 / \u0026lt;(?\u0026lt;info3\u0026gt;(.*?))\u0026gt;/ format10 / \u0026lt;(?\u0026lt;sequenceNumber\u0026gt;(.*?))\u0026gt;/ format11 / \u0026lt;(?\u0026lt;severity\u0026gt;(.*?))\u0026gt;/ format12 / \u0026lt;(?\u0026lt;messageID\u0026gt;(.*?))\u0026gt;/ format13 / \u0026lt;(?\u0026lt;message\u0026gt;(.*?))\u0026gt;/ \u0026lt;/parse\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;match **\u0026gt; @type elasticsearch host \u0026#34;#{ENV[\u0026#39;ELASTICSEARCH_HOST\u0026#39;]}\u0026#34; port \u0026#34;#{ENV[\u0026#39;ELASTICSEARCH_PORT\u0026#39;]}\u0026#34; user \u0026#34;#{ENV[\u0026#39;ELASTICSEARCH_USER\u0026#39;]}\u0026#34; password \u0026#34;#{ENV[\u0026#39;ELASTICSEARCH_PASSWORD\u0026#39;]}\u0026#34; index_name \u0026#34;#{ENV[\u0026#39;DOMAIN_UID\u0026#39;]}\u0026#34; scheme http \u0026lt;/match\u0026gt; EOF Mount the ConfigMap as a volume in the weblogic-server container Edit the domain definition and configure a volume for the ConfigMap containing the fluentd configuration.\nNOTE: For brevity, only the paths to the relevant configuration are shown.\nFor example, run: kubectl edit domain wcp-domain -n wcpns and add the following portions to the domain definition.\nspec: serverPod: volumes: - configMap: defaultMode: 420 name: fluentd-config name: fluentd-config-volume Add fluentd container Add a container to the domain to run fluentd in the Administration Server and Managed Server pods.\nThe container definition:\n Defines a LOG_PATH environment variable that points to the log location of bobbys-front-end. Defines ELASTICSEARCH_HOST, ELASTICSEARCH_PORT, ELASTICSEARCH_USER, and ELASTICSEARCH_PASSWORD environment variables that are all retrieving their values from the secret wcpinfra-domain-credentials. Includes volume mounts for the fluentd-config ConfigMap and the volume containing the domain logs.  NOTE: For brevity, only the paths to the relevant configuration are shown.\nFor example, run: kubectl edit domain wcp-domain -n wcpcns and add the following container definition.\nspec: serverPod: containers: - args: - -c - /etc/fluent.conf env: - name: DOMAIN_UID valueFrom: fieldRef: fieldPath: metadata.labels[\u0026#39;weblogic.domainUID\u0026#39;] - name: SERVER_NAME valueFrom: fieldRef: fieldPath: metadata.labels[\u0026#39;weblogic.serverName\u0026#39;] - name: LOG_PATH value: /u01/oracle/user_projects/domains/logs/wcp-domain/$(SERVER_NAME).log - name: FLUENTD_CONF value: fluentd.conf - name: FLUENT_ELASTICSEARCH_SED_DISABLE value: \u0026#34;true\u0026#34; - name: ELASTICSEARCH_HOST valueFrom: secretKeyRef: key: elasticsearchhost name: wcpinfra-domain-credentials - name: ELASTICSEARCH_PORT valueFrom: secretKeyRef: key: elasticsearchport name: wcpinfra-domain-credentials - name: ELASTICSEARCH_USER valueFrom: secretKeyRef: key: elasticsearchuser name: wcpinfra-domain-credentials optional: true - name: ELASTICSEARCH_PASSWORD valueFrom: secretKeyRef: key: elasticsearchpassword name: wcpinfra-domain-credentials optional: true image: fluent/fluentd-kubernetes-daemonset:v1.3.3-debian-elasticsearch-1.3 imagePullPolicy: IfNotPresent name: fluentd resources: {} volumeMounts: - mountPath: /fluentd/etc/fluentd.conf name: fluentd-config-volume subPath: fluentd.conf - mountPath: /scratch name: weblogic-domain-storage-volume Verify logs exported to Elasticsearch The logs are sent to Elasticsearch after you start the Administration Server and Managed Server pods after making the changes described previously.\nYou can check if the fluentd container is successfully tailing the log by executing a command like kubectl logs -f wcp-domain-adminserver -n wcpns fluentd. The log output should look similar to this:\n2019-10-01 16:23:44 +0000 [info]: #0 starting fluentd worker pid=13 ppid=9 worker=0 2019-10-01 16:23:44 +0000 [warn]: #0 /scratch/logs/bobs-bookstore/managed-server1.log not found. Continuing without tailing it. 2019-10-01 16:23:44 +0000 [info]: #0 fluentd worker is now running worker=0 2019-10-01 16:24:01 +0000 [info]: #0 following tail of /scratch/logs/bobs-bookstore/managed-server1.log When you connect to Kibana, you will see an index created for the domainUID.\nDomain example The following is a complete example of a domain custom resource with a fluentd container configured.\napiVersion: weblogic.oracle/v8 kind: Domain metadata: labels: weblogic.domainUID: wcp-domain name: wcp-domain namespace: wcpns spec: domainHome: /u01/oracle/user_projects/domains/wcp-domain domainHomeSourceType: PersistentVolume image: \u0026#34;oracle/wcportal:12.2.1.4\u0026#34; imagePullPolicy: \u0026#34;IfNotPresent\u0026#34; webLogicCredentialsSecret: name: wcpinfra-domain-credentials includeServerOutInPodLog: true logHomeEnabled: true httpAccessLogInLogHome: true logHome: /u01/oracle/user_projects/domains/logs/wcp-domain dataHome: \u0026#34;\u0026#34; serverStartPolicy: \u0026#34;IF_NEEDED\u0026#34; adminServer: serverStartState: \u0026#34;RUNNING\u0026#34; clusters: - clusterName: wcp_cluster serverStartState: \u0026#34;RUNNING\u0026#34; serverPod: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026#34;weblogic.clusterName\u0026#34; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; replicas: 2 serverPod: containers: - args: - -c - /etc/fluent.conf env: - name: DOMAIN_UID valueFrom: fieldRef: fieldPath: metadata.labels[\u0026#39;weblogic.domainUID\u0026#39;] - name: SERVER_NAME valueFrom: fieldRef: fieldPath: metadata.labels[\u0026#39;weblogic.serverName\u0026#39;] - name: LOG_PATH value: /u01/oracle/user_projects/domains/logs/wcp-domain/$(SERVER_NAME).log - name: FLUENTD_CONF value: fluentd.conf - name: FLUENT_ELASTICSEARCH_SED_DISABLE value: \u0026#34;true\u0026#34; - name: ELASTICSEARCH_HOST valueFrom: secretKeyRef: key: elasticsearchport name: wcpinfra-domain-credentials - name: ELASTICSEARCH_PORT valueFrom: secretKeyRef: key: elasticsearchhost name: wcpinfra-domain-credentials - name: ELASTICSEARCH_USER valueFrom: secretKeyRef: key: elasticsearchuser name: wcpinfra-domain-credentials - name: ELASTICSEARCH_PASSWORD valueFrom: secretKeyRef: key: elasticsearchpassword name: wcpinfra-domain-credentials image: fluent/fluentd-kubernetes-daemonset:v1.11.5-debian-elasticsearch6-1.0 imagePullPolicy: IfNotPresent name: fluentd resources: {} volumeMounts: - mountPath: /fluentd/etc/fluentd.conf name: fluentd-config-volume subPath: fluentd.conf - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume env: - name: JAVA_OPTIONS value: -Dweblogic.StdoutDebugEnabled=false - name: USER_MEM_ARGS value: \u0026#39;-Djava.security.egd=file:/dev/./urandom -Xms1g -Xmx2g\u0026#39; volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wcp-domain-domain-pvc - emptyDir: {} name: weblogic-domain-storage-volume - configMap: defaultMode: 420 name: fluentd-config name: fluentd-config-volume serverStartPolicy: IF_NEEDED webLogicCredentialsSecret: name: wcpinfra-domain-credentials Get the Kibana dashboard port information as shown below: -bash-4.2$ kubectl get pods -w NAME READY STATUS RESTARTS AGE elasticsearch-8bdb7cf54-mjs6s 1/1 Running 0 4m3s kibana-dbf8964b6-n8rcj 1/1 Running 0 4m3s -bash-4.2$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE elasticsearch ClusterIP 10.100.11.154 \u0026lt;none\u0026gt; 9200/TCP,9300/TCP 4m32s kibana NodePort 10.97.205.0 \u0026lt;none\u0026gt; 5601:31884/TCP 4m32s kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 71d You can access the Kibana dashboard at http://mycompany.com:kibana-nodeport/. In our example, the node port is 31884.\nCreate an Index Pattern in Kibana Create an index pattern wcp-domain* in Kibana by navigating to the dashboard through the Management option. When the servers are started, the log data is shown on the Kibana dashboard.\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/monitoring-and-publishing-logs/monitoring-domain/",
	"title": " Monitor a WebCenter Portal domain",
	"tags": [],
	"description": "Monitor an WebCenter Portal instance using Prometheus and Grafana.",
	"content": "You can monitor a WebCenter Portal domain using Prometheus and Grafana by exporting the metrics from the domain instance using the WebLogic Monitoring Exporter. This sample shows you how to set up the WebLogic Monitoring Exporter to push the data to Prometheus.\nPrerequisites This document assumes that the Prometheus Operator is deployed on the Kubernetes cluster. If it is not already deployed, follow the steps below for deploying the Prometheus Operator.\nClone the kube-prometheus project Refer to the compatibility matrix of Kube Prometheus and clone the release version of the kube-prometheus repository according to the Kubernetes version of your cluster. $ git clone https://github.com/coreos/kube-prometheus.git\n #### Label the nodes Kube-Prometheus requires all the exporter nodes to be labelled with `kubernetes.io/os=linux`. If a node is not labelled, then you must label it using the following command: $ kubectl label nodes \u0026ndash;all kubernetes.io/os=linux\n #### Create Prometheus and Grafana resources Change to the `kube-prometheus` directory and execute the following commands to create the namespace and CRDs: **NOTE**: Wait for a minute for each command to process. ```bash $ cd kube-prometheus $ kubectl create -f manifests/setup $ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo \u0026quot;\u0026quot;; done $ kubectl create -f manifests/ Provide external access To provide external access for Grafana, Prometheus, and Alertmanager, execute the commands below:\n$ kubectl patch svc grafana -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32100 }]\u0026#39; $ kubectl patch svc prometheus-k8s -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32101 }]\u0026#39; $ kubectl patch svc alertmanager-main -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32102 }]\u0026#39; NOTE:\n 32100 is the external port for Grafana 32101 is the external port for Prometheus 32102 is the external port for Alertmanager   Set Up the WebLogic Monitoring Exporter Set up the WebLogic Monitoring Exporter to collect WebLogic Server metrics and monitor your WebCenter Portal domain.\nGenerate the WebLogic Monitoring Exporter Deployment Package Two packages are required as the listening ports are different for the Administration Server and Managed Servers. One binary required for the Admin Server (wls-exporter-as.war) and one for Managed Cluster (wls-exporter-ms.war). Set the required proxies and then run the script getX.X.X.sh to generate two binaries:\n$ cd \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-monitoring-exporter $ sh get1.1.0.sh Output:\n % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 607 0 607 0 0 357 0 --:--:-- 0:00:01 --:--:-- 357 100 2016k 100 2016k 0 0 398k 0 0:00:05 0:00:05 --:--:-- 797k -------------------wls-exporter-ms start------------------- created /tmp/ci-GNysQzP1kv Copying completed /tmp/ci-GNysQzP1kv \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-monitoring-exporter in temp dir adding: WEB-INF/weblogic.xml (deflated 66%) adding: config.yml (deflated 63%) wls-exporter-ms.war is ready -------------------wls-exporter-ms end------------------- -------------------wls-exporter-as start------------------- Copying completed in temp dir adding: WEB-INF/weblogic.xml (deflated 66%) adding: config.yml (deflated 52%) wls-exporter-as.war is ready -------------------wls-exporter-as end------------------- zip completed \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-monitoring-exporter Copy the WAR Files to the WebLogic Domain Home Copy the wls-exporter-as.war and wls-exporter-ms.war files to the domain home directory in the Administration Server pod.\n$ kubectl cp wls-exporter-as.war wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/ $ kubectl cp wls-exporter-ms.war wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/ Deploy the WebLogic Monitoring Exporter Follow these steps to deploy the package in the WebLogic Server instances:\n  On the Administration Server and Managed Servers, deploy the WebLogic Monitoring Exporter (wls-exporter-ms.war) separately using the Oracle Enterprise Manager.\n  Select the servers to which the Exporter WAR should be deployed:\n  Set the application name. The application name must be different if it is deployed separately in the Administration Server and Managed Servers. Make sure the context-root for both the deployments is wls-exporter:\n  Click Install and start application.\n  Then deploy the WebLogic Monitoring Exporter application (wls-exporter-ms.war).\n  Activate the changes to start the application. If the application is started and the port is exposed, then you can access the WebLogic Monitoring Exporter console using this URL: http://\u0026lt;server:port\u0026gt;/wls-exporter.\n  Repeat same steps for wls-exporter-as.war.\n  Configure Prometheus Operator Prometheus enables you to collect metrics from the WebLogic Monitoring Exporter. The Prometheus Operator identifies the targets using service discovery. In order to Prometheus be able to discovery and scrape services inside the additional namespaces like wcpns, you must create a service monitor resource pointing to the services in wcpns namespace.\nSee the following sample service monitor deployment YAML configuration file located at\n\u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-monitoring-exporter/wls-exporter.yaml.\nServiceMonitor for wls-exporter:\napiVersion: v1 kind: Secret metadata: name: basic-auth namespace: monitoring data: password: d2VsY29tZTEK # welcome1 i.e.'WebLogic password' user: d2VibG9naWM= # weblogic i.e. 'WebLogic username' type: Opaque --- apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: wls-exporter-wcp-domain namespace: monitoring labels: k8s-app: wls-exporter spec: namespaceSelector: matchNames: - wcpns selector: matchLabels: weblogic.domainName: wcp-domain endpoints: - basicAuth: password: name: basic-auth key: password username: name: basic-auth key: user port: default relabelings: - action: labelmap regex: __meta_kubernetes_service_label_(.+) interval: 10s honorLabels: true path: /wls-exporter/metrics To export metrics using wls-exporter, you need to set basicAuth in Prometheus. So create a Kubernetes Secret with the user name and password that are base64 encoded. This Secret will be used in the ServiceMonitor deployment.\nWhen generating the base64 encoded strings for the user name and password, observe if a new line character is appended in the encoded string. This line character causes an authentication failure. To avoid a new line string, use the following example:\n$ echo -n \u0026quot;Welcome1\u0026quot; | base64 V2VsY29tZTE= In the deployment YAML configuration for wls-exporter shown above, weblogic.domainName: wcp-domain is used as a label under spec.selector.matchLabels, so all the services are selected for the service monitor. If you don\u0026rsquo;t use this label, you should create separate service monitors for each server\u0026ndash;if the server name is used as matching labels in spec.selector.matchLabels. Doing so will require you to relabel the configuration because Prometheus, by default, ignores the labels provided in the wls-exporter.\nBy default, Prometheus does not store all the labels provided by the target. In the service monitor deployment YAML configuration, you must mention the relabeling configuration (spec.endpoints.relabelings) so that certain labels provided by weblogic-monitoring-exporter (required for the Grafana dashboard) are stored in Prometheus. Do not delete the following section from the configuration YAML file:\nrelabelings: - action: labelmap regex: __meta_kubernetes_service_label_(.+) Add RoleBinding and Role for the WebLogic Domain Namespace The RoleBinding is required for Prometheus to access the endpoints provided by the WebLogic Monitoring Exporter. You need to add RoleBinding for the namespace under which the WebLogic Servers pods are running in the Kubernetes cluster. Edit the kube-prometheus/manifests/prometheus-roleBindingSpecificNamespaces.yaml file in the Prometheus Operator deployment manifests and add the RoleBinding for the namespace (wcpns) similar to the following example:\n- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: prometheus-k8s namespace: wcpns roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: prometheus-k8s subjects: - kind: ServiceAccount name: prometheus-k8s namespace: monitoring In the Prometheus Operator deployment manifests located at kube-prometheus/manifests/prometheus-roleSpecificNamespaces.yaml, add the Role for the namespace wcpns under which the WebLogic Servers pods are running in the Kubernetes cluster. See the following example:\n- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: prometheus-k8s namespace: wcpns rules: - apiGroups: - \u0026quot;\u0026quot; resources: - services - endpoints - pods verbs: - get - list - watch Then apply prometheus-roleBindingSpecificNamespaces.yaml and prometheus-roleSpecificNamespaces.yaml for the RoleBinding and Role to take effect in the cluster.\n$ kubectl apply -f kube-prometheus/manifests/prometheus-roleBindingSpecificNamespaces.yaml $ kubectl apply -f kube-prometheus/manifests/prometheus-roleSpecificNamespaces.yaml Deploy the Service Monitor To deploy the service monitor, use the above wls-exporter.yaml deployment YAML and run the following command:\n$ kubectl create -f \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-monitoring-exporter/wls-exporter.yaml Enable Prometheus to Discover the Service After deploying the service monitor, Prometheus should be able to discover wls-exporter and export metrics.\nYou can access the Prometheus dashboard at http://mycompany.com:32101/.\nDeploy Grafana Dashboard To view the domain metrics, deploy the Grafana dashboard provided in the WebLogic Monitoring Exporter.\nYou can access the Grafana dashboard at http://mycompany.com:32100/.\n  Log in to Grafana dashboard with admin/admin.\n  Go to Settings, then select DataSources, and then Add Data Source.\nHTTP URL: Prometheus URL http://mycompany.com:32101/\nAuth: Enable Basic Auth\nBasic Auth Details: Weblogic credentials provided in the step Configure Prometheus Operator\n  Download the weblogic_dashboard.json file from here.\n  Click Add and then Import. Paste the modified JSON in the Paste JSON block, and then load it.\nThis displays the WebLogic Server Dashboard.\n  "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/patch_and_upgrade/patch-an-image/",
	"title": "Patch an image",
	"tags": [],
	"description": "Create a patched Oracle WebCenter Content image using the WebLogic Image Tool.",
	"content": "Oracle aims to release Oracle WebCenter Content images regularly with latest bundle and recommended interim patches in My Oracle Support (MOS). However, if there is a need to create images with new bundle and interim patches, you can build these images using WebLogic Image Tool.\nIf you have access to the Oracle WebCenter Content patches, you can patch an existing Oracle WebCenter Content image with a bundle patch and interim patches. It is recommended to use the WebLogic Image Tool to patch the Oracle WebCenter Content image.\n Recommendations:\n Use the WebLogic Image Tool create feature for patching the Oracle WebCenter Content Docker image with a bundle patch and multiple interim patches. This is the recommended approach because it optimizes the size of the image. Use the WebLogic Image Tool update feature for patching the Oracle WebCenter Content Docker image with a single interim patch. Note that the patched image size may increase considerably due to additional image layers introduced by the patch application tool.   Apply the patched image   Update the image: field in domain.yaml configuration file with the patched image.\n  Apply the updated domain.yaml configuration file:\n$ kubectl apply -f domain.yaml    Note: The server pods will be automatically restarted (rolling restart).\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/release-notes/",
	"title": "Release Notes",
	"tags": [],
	"description": "",
	"content": "Review the latest changes for Oracle WebCenter Content on Kubernetes.\nRecent changes    Date Version Introduces backward incompatibilities Change     June 16, 2021 21.2.3 no Supports Oracle WebCenter Content 12.2.1.4 domains deployment using April 2021 PSU and known bug fixes. Oracle WebCenter Content 12.2.1.4 container image for this release can be downloaded from My Oracle Support (MOS patch 32822360).   February 28, 2021 21.1.2 no Certified Oracle WebLogic Kubernetes operator version 3.1.1. Kubernetes 1.14.8+, 1.15.7+, 1.16.0+, 1.17.0+, and 1.18.0+ support. Flannel is the only supported CNI in this release. SSL enabling for the Administration Server and Managed Servers is supported. For now, only Oracle WebCenter Content 12.2.1.4 is supported.    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/release-notes/",
	"title": "Release Notes",
	"tags": [],
	"description": "",
	"content": "Recent changes    Date Version Change     June 30, 2021 21.2.3 Only Oracle Portal 12.2.1.4 is supported and certified with the WebLogic Kubernetes operator version 3.1.1.    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/installguide/prerequisites/",
	"title": "Requirements and limitations",
	"tags": [],
	"description": "Understand the system requirements and limitations for deploying and running Oracle WebCenter Content with the WebLogic Kubernetes operator, including the Oracle WebCenter Content cluster sizing recommendations.",
	"content": "This section provides information about the system requirements and limitations for deploying and running Oracle WebCenter Content domains with the WebLogic Kubernetes operator.\nSystem requirements for Oracle WebCenter Content domains For the current production release 21.2.3:\n Oracle Linux 7 (UL6+) and Red Hat Enterprise Linux 7 (UL3+ only with standalone Kubernetes) are supported. Kubernetes 1.14.8+, 1.15.7+, 1.16.0+, 1.17.0+, and 1.18.0+ (check with kubectl version). Docker 18.09.1ce, 19.03.1 (check with docker version) or CRI-O 1.14.7 (check with crictl version | grep RuntimeVersion). Flannel networking v0.12.0-amd64 or later (check with docker images | grep flannel). Helm 3.4.1 (check with helm version --client --short). Oracle WebLogic Kubernetes operator 3.1.1 (see operator releases page). Oracle WebCenter Content 12.2.1.4 Docker image downloaded from My Oracle Support (MOS patch 32822360). This image contains the latest bundle patch and one-off patches for Oracle WebCenter Content. You must have the cluster-admin role to install the operator. The operator does not need the cluster-admin role at runtime. We do not currently support running Oracle WebCenter Content in non-Linux containers. Additionally, see the Oracle WebCenter Content documentation for other requirements such as database version.  See here for resourse sizing information for Oracle WebCenter Content domains setup on Kubernetes cluster.\nLimitations Compared to running a WebLogic Server domain in Kubernetes using the operator, the following limitations currently exist for Oracle WebCenter Content domains:\n In this release, Oracle WebCenter Content domains are supported using the domain on a persistent volume model only, where the domain home is located in a persistent volume (PV). The \u0026ldquo;domain in image\u0026rdquo; and \u0026ldquo;model in image\u0026rdquo; models are not supported. Also, \u0026ldquo;WebLogic Deploy Tooling (WDT)\u0026rdquo; based deployments are currently not supported. Only configured clusters are supported. Dynamic clusters are not supported for Oracle WebCenter Content domains. Note that you can still use all of the scaling features, but you need to define the maximum size of your cluster at domain creation time. Mixed clusters (configured servers targeted to a dynamic cluster) are not supported. The WebLogic Logging Exporter currently supports WebLogic Server logs only. Other logs will not be sent to Elasticsearch. Note, however, that you can use a sidecar with a log handling tool like Logstash or Fluentd to get logs. The WebLogic Monitoring Exporter currently supports WebLogic MBean trees only. Support for JRF and Oracle WebCenter Content MBeans is not available. Also, a metrics dashboard specific to Oracle WebCenter Content is not available. Instead, use the WebLogic Server dashboard to monitor the Oracle WebCenter Content server metrics in Grafana. Some features such as multicast, multitenancy, production redeployment, and Node Manager (although it is used internally for the liveness probe and to start WebLogic Server instances) are not supported in this release. Features such as Java Messaging Service whole server migration, consensus leasing, and maximum availability architecture (Oracle WebCenter Content setup) are not supported in this release. In this release, we are releasing with Oracle WebCenter Content server (UCM) and Oracle WebCenter Content Inbound Refinery server (IBR). Oracle WebCenter Enterprise Capture (Capture), Oracle WebCenter Imaging (Imaging) and ADFUI (WebCenter Content ADF based web user interface) servers are not yet added to the template. You can have multiple UCM servers on your domain but you can have only one IBR server. Presently launching JNLP applets is not supported with Voyager as load-balancer (for multi-pod UCM clusters). There is a generic limitation with all load-balancers in end-to-end SSL configuration - accessing multiple types of servers (different Managed Servers and/or Administration Server) at the same time, is currently not supported.  For up-to-date information about the features of WebLogic Server that are supported in Kubernetes environments, see My Oracle Support Doc ID 2349228.1.\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/installguide/prerequisites/",
	"title": "Requirements and limitations",
	"tags": [],
	"description": "Understand the system requirements and limitations for deploying and running Oracle WebCenter Portal with the WebLogic Kubernetes operator.",
	"content": "Contents  Introduction System Requirements Limitations  Introduction This document describes the special considerations for deploying and running a WebCenter Portal domain with the WebLogic Kubernetes Operator. Other than those considerations listed here, the WebCenter Portal domain works in the same way as Fusion Middleware Infrastructure and WebLogic Server domains do.\nIn this release, WebCenter Portal domain is based on the domain on a persistent volume model where a WebCenter Portal domain is located in a persistent volume (PV).\nSystem Requirements  Kubernetes 1.14.8+, 1.15.7+, 1.16.0+, 1.17.0+, and 1.18.0+ (check with kubectl version). Flannel networking v0.9.1-amd64 or later (check with docker images | grep flannel). Docker 18.9.1 or 19.03.1 (check with docker version). Helm 3.1.3+ (check with helm version). WebLogic Kubernetes operator 3.1.1 (see the operator releases page). Oracle WebCenter Portal 12.2.1.4.0 image. These proxy setups are used for pulling the required binaries and source code from the respective repositories:  export NO_PROXY=\u0026quot;localhost,127.0.0.0/8,$(hostname -i),.your-company.com,/var/run/docker.sock\u0026rdquo; export no_proxy=\u0026quot;localhost,127.0.0.0/8,$(hostname -i),.your-company.com,/var/run/docker.sock\u0026rdquo; export http_proxy=http://www-proxy-your-company.com:80 export https_proxy=http://www-proxy-your-company.com:80 export HTTP_PROXY=http://www-proxy-your-company.com:80 export HTTPS_PROXY=http://www-proxy-your-company.com:80    NOTE: Add your host IP by using hostname -i and nslookup IP addresses to the no_proxy, NO_PROXY list above.\nLimitations Compared to running a WebLogic Server domain in Kubernetes using the operator, the following limitations currently exist for a WebCenter Portal domain:\n Domain in image model is not supported in this version of the operator. Only configured clusters are supported. Dynamic clusters are not supported on WebCenter Portal domains. Note that you can still use all of the scaling features. You just need to define the maximum size of your cluster at the time when you create a domain. At present, WebCenter Portal doesn\u0026rsquo;t run on non-Linux containers. Deploying and running a WebCenter Portal domain is supported only in the operator versions 3.1.1 and later. The WebLogic Logging Exporter currently supports WebLogic Server logs only. Other logs are not sent to Elasticsearch. Note, however, that you can use a sidecar with a log handling tool like Fluentd to get logs. The WebLogic Monitoring Exporter currently supports the WebLogic MBean trees only. Support for JRF MBeans has not been added yet.  "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/configure-load-balancer/traefik/",
	"title": "Traefik",
	"tags": [],
	"description": "Configure the ingress-based Traefik load balancer for Oracle WebCenter Content domains.",
	"content": "This section provides information about how to install and configure the ingress-based Traefik load balancer (version 2.2.1 or later for production deployments) to load balance Oracle WebCenter Content domain clusters. You can configure Traefik for non-SSL, SSL termination and end-to-end SSL access of the application URL.\nFollow these steps to set up Traefik as a load balancer for an Oracle WebCenter Content\tdomain in a Kubernetes cluster:\n  Non-SSL and SSL termination\n Install the Traefik (ingress-based) load balancer Configure Traefik to manage ingresses Create an Ingress for the domain Verify domain application URL access Uninstall the Traefik ingress    End-to-end SSL configuration\n Install the Traefik load balancer for End-to-end SSL Configure Traefik to manage domain Create IngressRouteTCP Verify end-to-end SSL access Uninstall Traefik    Non-SSL and SSL termination Install the Traefik (ingress-based) load balancer   Use Helm to install the Traefik (ingress-based) load balancer. For detailed information, see here. Use the values.yaml file in the sample but set kubernetes.namespaces specifically.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --set \u0026#34;service.type=NodePort\u0026#34; --wait    Click here to see the sample output.   NAME: traefik LAST DEPLOYED: Sun Jan 17 23:30:20 2021 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None    A sample values.yaml for deployment of Traefik 2.2.x:\nimage: name: traefik tag: 2.2.8 pullPolicy: IfNotPresent ingressRoute: dashboard: enabled: true # Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class) annotations: {} # Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels) labels: {} providers: kubernetesCRD: enabled: true kubernetesIngress: enabled: true # IP used for Kubernetes Ingress endpoints ports: traefik: port: 9000 expose: true # The exposed port for this service exposedPort: 9000 # The port protocol (TCP/UDP) protocol: TCP web: port: 8000 # hostPort: 8000 expose: true exposedPort: 30305 nodePort: 30305 # The port protocol (TCP/UDP) protocol: TCP # Use nodeport if set. This is useful if you have configured Traefik in a # LoadBalancer # nodePort: 32080 # Port Redirections # Added in 2.2, you can make permanent redirects via entrypoints. # https://docs.traefik.io/routing/entrypoints/#redirection # redirectTo: websecure websecure: port: 8443 # # hostPort: 8443 expose: true exposedPort: 30443 # The port protocol (TCP/UDP) protocol: TCP nodePort: 30443   Verify the Traefik status and find the port number of the SSL and non-SSL services:\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-f9cf58697-p57nt 1/1 Running 0 22d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik NodePort 10.96.95.253 \u0026lt;none\u0026gt; 9000:32306/TCP,30305:30305/TCP,30443:30443/TCP 22d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 22d NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-f9cf58697 1 1 1 22d      Access the Traefik dashboard through the URL http://$(hostname -f):32306, with the HTTP host traefik.example.com:\n$ curl -H \u0026#34;host: $(hostname -f)\u0026#34; http://$(hostname -f):32306/dashboard/  Note: Make sure that you specify a fully qualified node name for $(hostname -f)\n   Configure Traefik to manage ingresses Configure Traefik to manage ingresses created in this namespace, where traefik is the Traefik namespace and wccns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik --namespace traefik --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik,wccns}\u0026#34;    Click here to see the sample output.   Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Sun Jan 17 23:43:02 2021 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create an ingress for the domain Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK , tls is Non-SSL, and domainType is wccinfra. These values can be overridden by passing values through the command line or can be edited in the sample file values.yaml based on the type of configuration (non-SSL or SSL). If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. The template YAML file for the Traefik (ingress-based) load balancer is located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/traefik-ingress.yaml\n  Install ingress-per-domain using Helm for non-SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --set type=TRAEFIK \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=$(hostname -f)\u0026#34; --set tls=NONSSL Sample output:\nNAME: wcc-traefik-ingress LAST DEPLOYED: Sun Jan 17 23:49:09 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate a Kubernetes secret:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Create Traefik Middleware custom resource\nIn case of SSL termination, Traefik must pass a custom header WL-Proxy-SSL:true to the WebLogic Server endpoints. Create the Middleware using the following command:\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: wls-proxy-ssl namespace: wccns spec: headers: customRequestHeaders: WL-Proxy-SSL: \u0026#34;true\u0026#34; EOF   Create the Traefik TLSStore custom resource.\nIn case of SSL termination, Traefik should be configured to use the user-defined SSL certificate. If the user-defined SSL certificate is not configured, Traefik will create a default SSL certificate. To configure a user-defined SSL certificate for Traefik, use the TLSStore custom resource. The Kubernetes secret created with the SSL certificate should be referenced in the TLSStore object. Run the following command to create the TLSStore:\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: traefik.containo.us/v1alpha1 kind: TLSStore metadata: name: default namespace: wccns spec: defaultCertificate: secretName: domain1-tls-cert EOF   Install ingress-per-domain using Helm for SSL configuration.\nThe Kubernetes secret name should be updated in the template file.\nThe template file also contains the following annotations:\ntraefik.ingress.kubernetes.io/router.entrypoints: websecure traefik.ingress.kubernetes.io/router.tls: \u0026#34;true\u0026#34; traefik.ingress.kubernetes.io/router.middlewares: wccns-wls-proxy-ssl@kubernetescrd The entry point for SSL access and the Middleware name should be updated in the annotation. The Middleware name should be in the form \u0026lt;namespace\u0026gt;-\u0026lt;middleware name\u0026gt;@kubernetescrd.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress \\  kubernetes/samples/charts/ingress-per-domain \\  --set type=TRAEFIK \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;traefik.hostname=$(hostname -f)\u0026#34; \\  --set tls=SSL Sample output:\nNAME: wcc-traefik-ingress LAST DEPLOYED: Mon Jul 20 11:44:13 2020 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For non-SSL access to the Oracle WebCenter Content application, get the details of the services by the ingress:\n$ kubectl describe ingress wccinfra-traefik -n wccns     Click here to see all services supported by the above deployed ingress.    Name: wccinfra-traefik Namespace: wccns Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- domain1.org /console wccinfra-adminserver:7001 (10.244.0.58:7001) /em wccinfra-adminserver:7001 (10.244.0.58:7001) /wls-exporter wccinfra-adminserver:7001 (10.244.0.58:7001) /cs wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /adfAuthentication wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /wls-exporter wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /ibr wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /ibr/adfAuthentication wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /weblogic/ready wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) Annotations: kubernetes.io/ingress.class: traefik meta.helm.sh/release-name: wccinfra-traefik meta.helm.sh/release-namespace: wccns Events: \u0026lt;none\u0026gt;      For SSL access to the Oracle WebCenter Content application, get the details of the services by the above deployed ingress:\n$ kubectl describe ingress wccinfra-traefik -n wccns     Click here to see all services supported by the above deployed ingress.    Name: wccinfra-traefik Namespace: wccns Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- domain1.org /console wccinfra-adminserver:7001 (10.244.0.58:7001) /em wccinfra-adminserver:7001 (10.244.0.58:7001) /wls-exporter wccinfra-adminserver:7001 (10.244.0.58:7001) /cs wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /adfAuthentication wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /wls-exporter wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /ibr wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /ibr/adfAuthentication wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /weblogic/ready wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) Annotations: kubernetes.io/ingress.class: traefik meta.helm.sh/release-name: wccinfra-traefik meta.helm.sh/release-namespace: wccns Events: \u0026lt;none\u0026gt;     To confirm that the load balancer noticed the new ingress and is successfully routing to the domain server pods, you can send a request to the URL for the \u0026ldquo;WebLogic ReadyApp framework\u0026rdquo;, which should return an HTTP 200 status code, as follows: $ curl -v http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER_PORT}/weblogic/ready * About to connect() to abc.com port 30305 (#0) * Trying 100.111.156.246... * Connected to abc.com (100.111.156.246) port 30305 (#0) \u0026gt; GET /weblogic/ready HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Host: domain1.org:30305 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Content-Length: 0 \u0026lt; Date: Thu, 03 Dec 2020 13:16:19 GMT \u0026lt; Vary: Accept-Encoding \u0026lt; * Connection #0 to host abc.com left intact   Verify domain application URL access For non-SSL configuration After setting up the Traefik (ingress-based) load balancer, verify that the domain application URLs are accessible through the non-SSL load balancer port 30305 for HTTP access. The sample URLs for Oracle WebCenter Content domain of type wcc are:\nhttp://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em\tFor SSL configuration After setting up the Traefik (ingress-based) load balancer, verify that the domain applications are accessible through the SSL load balancer port 30443 for HTTPS access. The sample URLs for Oracle WebCenter Content domain are:\nhttps://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/em Uninstall the Traefik ingress Uninstall and delete the ingress deployment:\n$ helm delete wcc-traefik-ingress -n wccns End-to-end SSL configuration Install the Traefik load balancer for end-to-end SSL   Use Helm to install the Traefik (ingress-based) load balancer. For detailed information, see here. Use the values.yaml file in the sample but set kubernetes.namespaces specifically.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ kubectl create namespace traefik $ helm repo add traefik https://containous.github.io/traefik-helm-chart Sample output:\n\u0026#34;traefik\u0026#34; has been added to your repositories   Install Traefik:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\  --namespace traefik \\  --values kubernetes/samples/scripts/charts/traefik/values.yaml \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --wait    Click here to see the sample output.   NAME: traefik LAST DEPLOYED: Sun Jan 17 23:30:20 2021 NAMESPACE: traefik STATUS: deployed REVISION: 1 TEST SUITE: None      Verify the Traefik operator status and find the port number of the SSL and non-SSL services:\n$ kubectl get all -n traefik    Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/traefik-operator-676fc64d9c-skppn 1/1 Running 0 78d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik-operator NodePort 10.109.223.59 \u0026lt;none\u0026gt; 443:30443/TCP,80:30305/TCP 78d service/traefik-operator-dashboard ClusterIP 10.110.85.194 \u0026lt;none\u0026gt; 80/TCP 78d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik-operator 1/1 1 1 78d NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-operator-676fc64d9c 1 1 1 78d replicaset.apps/traefik-operator-cb78c9dc9 0 0 0 78d      Access the Traefik dashboard through the URL http://$(hostname -f):32306, with the HTTP host traefik.example.com:\n$ curl -H \u0026#34;host: $(hostname -f)\u0026#34; http://$(hostname -f):32306/dashboard/  Note: Make sure that you specify a fully qualified node name for $(hostname -f).\n   Configure Traefik to manage the domain Configure Traefik to manage the domain application service created in this namespace, where traefik is the Traefik namespace and wccns is the namespace of the domain:\n$ helm upgrade traefik traefik/traefik --namespace traefik --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik,wccns}\u0026#34;    Click here to see the sample output.   Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Sun Jan 17 23:43:02 2021 NAMESPACE: traefik STATUS: deployed REVISION: 2 TEST SUITE: None    Create IngressRouteTCP   To enable SSL passthrough in Traefik, you can configure a TCP router. A sample YAML for IngressRouteTCP is available at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls/traefik-tls.yaml. The following should be updated in traefik-tls.yaml:\n The service name and the SSL port should be updated in the Services. The load balancer hostname should be updated in the HostSNI rule.  Sample traefik-tls.yaml:\n  apiVersion: traefik.containo.us/v1alpha1 kind: IngressRouteTCP metadata: name: wcc-ucm-routetcp namespace: wccns spec: entryPoints: - websecure routes: - match: HostSNI(`${LOADBALANCER_HOSTNAME}`) services: - name: wccinfra-cluster-ucm-cluster port: 16201 weight: 3 TerminationDelay: 400 tls: passthrough: true  Create the IngressRouteTCP:  $ kubectl apply -f traefik-tls.yaml Verify end-to-end SSL access Verify the access to application URLs exposed through the configured service. You should be able to access the following Oracle WebCenter Content domain URLs:\nLOADBALANCER-SSLPORT is 30443\nhttps://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr Uninstall Traefik $ helm delete traefik -n wccns "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/installguide/",
	"title": "Install Guide",
	"tags": [],
	"description": "",
	"content": "Install the WebLogic Kubernetes operator to prepare and deploy Oracle WebCenter Content domain.\n Requirements and limitations  Understand the system requirements and limitations for deploying and running Oracle WebCenter Content with the WebLogic Kubernetes operator, including the Oracle WebCenter Content cluster sizing recommendations.\n Prepare your environment  Prepare for creating Oracle WebCenter Content domain, including required secrets creation, persistent volume and volume claim creation, database creation, and database schema creation.\n Create Oracle WebCenter Content domain  Create Oracle WebCenter Content domain home on an existing PV or PVC and create the domain resource YAML file for deploying the generated Oracle WebCenter Content domain.\n Launch Oracle Webcenter Content Native Applications in Containers  How to launch Oracle WebCenter Content native binaries from inside containerized environment.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/installguide/prepare-your-environment/",
	"title": "Prepare your environment",
	"tags": [],
	"description": "Prepare for creating Oracle WebCenter Content domain, including required secrets creation, persistent volume and volume claim creation, database creation, and database schema creation.",
	"content": "To prepare your Oracle WebCenter Content in Kubernetes environment, complete the following steps:\n  Set up your Kubernetes cluster\n  Install Helm\n  Pull dependent images\n  Set up the code repository to deploy Oracle WebCenter Content domain\n  Obtain the Oracle WebCenter Content Docker image\n  Install the WebLogic Kubernetes operator\n  Prepare the environment for Oracle WebCenter Content domain\na. Create a namespace for the Oracle WebCenter Content domain\nb. Create a persistent storage for the Oracle WebCenter Content domain\nc. Create a Kubernetes secret with domain credentials\nd. Create a Kubernetes secret with the RCU credentials\ne. Configure access to your database\nf. Run the Repository Creation Utility to set up your database schemas\n  Create Oracle WebCenter Content domain\n  Set up your Kubernetes cluster If you need help setting up a Kubernetes environment, check the cheat sheet.\nInstall Helm The operator uses Helm to create and deploy the necessary resources and then run the operator in a Kubernetes cluster. For Helm installation and usage information, see here.\nPull dependent images Obtain dependent images and add them to your local registry. Dependent images include WebLogic Kubernetes Operator, Traefik. Pull these images and add them to your local registry:\n Pull these docker images and re-tag them as shown:  To pull an image from the Oracle Container Registry, in a web browser, navigate to https://container-registry.oracle.com and log in using the Oracle Single Sign-On authentication service. If you do not already have SSO credentials, at the top of the page, click the Sign In link to create them.\nUse the web interface to accept the Oracle Standard Terms and Restrictions for the Oracle software images that you intend to deploy. Your acceptance of these terms are stored in a database that links the software images to your Oracle Single Sign-On login credentials.\nThen, pull these docker images and re-tag them:\ndocker login https://container-registry.oracle.com (enter your Oracle email Id and password) This step is required once at every node to get access to the Oracle Container Registry. WebLogic Kubernetes Operator image:\n$ docker pull container-registry.oracle.com/middleware/weblogic-kubernetes-operator:3.1.1 $ docker tag container-registry.oracle.com/middleware/weblogic-kubernetes-operator:3.1.1 oracle/weblogic-kubernetes-operator:3.1.1 Pull Traefik Image\n$ docker pull traefik:2.2.8 Set up the code repository to deploy Oracle WebCenter Content domain Oracle WebCenter Content domain deployment on Kubernetes leverages the WebLogic Kubernetes operator infrastructure. To deploy an Oracle WebCenter Content domain, you must set up the deployment scripts.\n  Create a working directory to set up the source code:\n$ export WORKDIR=$HOME/wcc_3.1.1 $ mkdir ${WORKDIR}   Download the supported version of the WebLogic Kubernetes operator source code from the operator github project. Currently the supported operator version is 3.1.1:\n$ git clone https://github.com/oracle/weblogic-kubernetes-operator.git --branch release/3.1.1   Download the Oracle WebCenter Content Kubernetes deployment scripts from the WCC repository and copy them to the WebLogic Kubernetes operator samples location:\n$ git clone https://github.com/oracle/fmw-kubernetes.git --branch release/21.2.3 $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/create-wcc-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/\t$ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/ingress-per-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/charts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterContent/kubernetes/imagetool-scripts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ ``\n  Obtain the Oracle WebCenter Content Docker image The Oracle WebCenter Content image with latest bundle patch and required interim patches can be obtained from My Oracle Support (MOS). This is the only image supported for production deployments. Follow the below steps to download the Oracle WebCenter Content image from My Oracle Support.\n  Download patch 32822360 from My Oracle Support (MOS).\n  Unzip the downloaded patch zip file.\nFor example:\n$ unzip p32822360_122140_Linux-x86-64.zip # sample output Archive: p32822360_122140_Linux-x86-64.zip inflating: wccontent-12.2.1.4.0-8-ol7-210507.0906.tar inflating: README.html   Load the image archive using the docker load command.\nFor example:\n$ docker load \u0026lt; wccontent-12.2.1.4.0-8-ol7-210507.0906.tar    Click here to see sample output   d0df970fe76a: Loading layer [==================================================\u0026gt;] 138.3MB/138.3MB 3b64a4bdc552: Loading layer [==================================================\u0026gt;] 13.45MB/13.45MB ee5141cc5c13: Loading layer [==================================================\u0026gt;] 20.99kB/20.99kB 51f637dc720f: Loading layer [==================================================\u0026gt;] 334MB/334MB ffc8b247ad07: Loading layer [==================================================\u0026gt;] 3.98GB/3.98GB cd87862f5c14: Loading layer [==================================================\u0026gt;] 4.608kB/4.608kB 12661fb5186c: Loading layer [==================================================\u0026gt;] 137.2kB/137.2kB f84db83c8dfa: Loading layer [==================================================\u0026gt;] 69.12kB/69.12kB Loaded image: oracle/wccontent:12.2.1.4.0-8-ol7-210507.0906      Run the docker inspect command to verify that the downloaded image is the latest released image. The value of label com.oracle.weblogic.imagetool.buildid must match to 29ff0886-a299-4860-9b13-fd6bb80ec354.\nFor example:\n$ docker inspect --format=\u0026#39;{{ index .Config.Labels \u0026#34;com.oracle.weblogic.imagetool.buildid\u0026#34; }}\u0026#39; oracle/wccontent:12.2.1.4.0-8-ol7-210507.0906 29ff0886-a299-4860-9b13-fd6bb80ec354   Alternatively, if you want to build and use Oracle WebCenter Content Container image, using WebLogic Image Tool, with any additional bundle patch or interim patches, then follow these steps to create the image.\n Note: The default Oracle WebCenter Content image name used for Oracle WebCenter Content domain deployment is oracle/wccontent:12.2.1.4.0. The image created must be tagged as oracle/wccontent:12.2.1.4.0 using the docker tag command. If you want to use a different name for the image, make sure to update the new image tag name in the create-domain-inputs.yaml file and also in other instances where the oracle/wccontent:12.2.1.4.0 image name is used.\n Install the WebLogic Kubernetes operator The WebLogic Kubernetes operator supports the deployment of Oracle WebCenter Content domain in the Kubernetes environment. Follow the steps in this document to install the operator.\n Note: Optionally, you can execute these steps to send the contents of the operator’s logs to Elasticsearch.\n In the following example commands to install the WebLogic Kubernetes operator, opns is the namespace and op-sa is the service account created for the operator:\nCreating namespace and service account for operator $ kubectl create namespace opns $ kubectl create serviceaccount -n opns op-sa Install operator $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator --namespace opns --set image=oracle/weblogic-kubernetes-operator:3.1.1 --set serviceAccount=op-sa --set \u0026quot;domainNamespaces={}\u0026quot; --set \u0026quot;javaLoggingLevel=FINE\u0026quot; --wait Prepare the environment for Oracle WebCenter Content domain Create a namespace for the Oracle WebCenter Content domain Create a Kubernetes namespace (for example, wccns) for the domain unless you intend to use the default namespace. Use the new namespace in the remaining steps in this section. For details, see Prepare to run a domain.\n $ kubectl create namespace wccns $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade --reuse-values --namespace opns --set \u0026quot;domainNamespaces={wccns}\u0026quot; --wait weblogic-kubernetes-operator kubernetes/charts/weblogic-operator Create a persistent storage for the Oracle WebCenter Content domain In the Kubernetes namespace you created, create the PV and PVC for the domain by running the create-pv-pvc.sh script. Follow the instructions for using the script to create a dedicated PV and PVC for the Oracle WebCenter Content domain.\n  Review the configuration parameters for PV creation here. Based on your requirements, update the values in the create-pv-pvc-inputs.yaml file located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc/. Sample configuration parameter values for the Oracle WebCenter Content domain are:\n baseName: domain domainUID: wccinfra namespace: wccns weblogicDomainStorageType: HOST_PATH weblogicDomainStoragePath: /net/\u0026lt;your_host_name\u0026gt;/scratch/k8s_dir/wcc    Ensure that the path for the weblogicDomainStoragePath property exists (if not, please refer subsection 4 of this document to create it first) and has full access permissions, and that the folder is empty.\n  Run the create-pv-pvc.sh script:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ rm -rf output/ $ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output   The create-pv-pvc.sh script will create a subdirectory pv-pvcs under the given /path/to/output-directory directory and creates two YAML configuration files for PV and PVC. Apply these two YAML files to create the PV and PVC Kubernetes resources using the kubectl create -f command:\n$ kubectl create -f output/pv-pvcs/wccinfra-domain-pv.yaml -n wccns $ kubectl create -f output/pv-pvcs/wccinfra-domain-pvc.yaml -n wccns   Get the details of PV and PVC:\n$ kubectl describe pv wccinfra-domain-pv $ kubectl describe pvc wccinfra-domain-pvc -n wccns   Create a Kubernetes secret with domain credentials Create the Kubernetes secrets username and password of the administrative account in the same Kubernetes namespace as the domain:\n $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-credentials $ ./create-weblogic-credentials.sh -u weblogic -p welcome1 -n wccns -d wccinfra -s wccinfra-domain-credentials For more details, see this document.\nYou can check the secret with the kubectl get secret command.\nFor example:\n  Click here to see the sample secret description.   $ kubectl get secret wccinfra-domain-credentials -o yaml -n wccns apiVersion: v1 data: password: d2VsY29tZTE= username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: \u0026quot;2020-09-16T08:22:50Z\u0026quot; labels: weblogic.domainName: wccinfra weblogic.domainUID: wccinfra managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:password: {} f:username: {} f:metadata: f:labels: .: {} f:weblogic.domainName: {} f:weblogic.domainUID: {} f:type: {} manager: kubectl operation: Update time: \u0026quot;2020-09-16T08:22:50Z\u0026quot; name: wccinfra-domain-credentials namespace: wccns resourceVersion: \u0026quot;3277100\u0026quot; selfLink: /api/v1/namespaces/wccns/secrets/wccinfra-domain-credentials uid: 35a8313f-1ec2-44b0-a2bf-fee381eed57f type: Opaque    Create a Kubernetes secret with the RCU credentials You also need to create a Kubernetes secret containing the credentials for the database schemas. When you create your domain, it will obtain the RCU credentials from this secret.\nUse the provided sample script to create the secret:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-rcu-credentials $ ./create-rcu-credentials.sh -u weblogic -p welcome1 -a sys -q welcome1 -d wccinfra -n wccns -s wccinfra-rcu-credentials The parameter values are:\n-u username for schema owner (regular user), required.\n-p password for schema owner (regular user), required.\n-a username for SYSDBA user, required.\n-q password for SYSDBA user, required.\n-d domainUID. Example: wccinfra\n-n namespace. Example: wccns\n-s secretName. Example: wccinfra-rcu-credentials\nYou can confirm the secret was created as expected with the kubectl get secret command.\nFor example:\n  Click here to see the sample secret description.   $ kubectl get secret wccinfra-rcu-credentials -o yaml -n wccns apiVersion: v1 data: password: d2VsY29tZTE= sys_password: d2VsY29tZTE= sys_username: c3lz username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: \u0026#34;2020-09-16T08:23:04Z\u0026#34; labels: weblogic.domainName: wccinfra weblogic.domainUID: wccinfra managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:password: {} f:sys_password: {} f:sys_username: {} f:username: {} f:metadata: f:labels: .: {} f:weblogic.domainName: {} f:weblogic.domainUID: {} f:type: {} manager: kubectl operation: Update time: \u0026#34;2020-09-16T08:23:04Z\u0026#34; name: wccinfra-rcu-credentials namespace: wccns resourceVersion: \u0026#34;3277132\u0026#34; selfLink: /api/v1/namespaces/wccns/secrets/wccinfra-rcu-credentials uid: b75f4e13-84e6-40f5-84ba-0213d85bdf30 type: Opaque    Configure access to your database Run a container to create rcu pod\nkubectl run rcu --generator=run-pod/v1 --image oracle/wccontent:12.2.1.4 -n wccns -- sleep infinity #check the status of rcu pod kubectl get pods -n wccns Run the Repository Creation Utility to set up your database schemas Create OR Drop schemas To create the database schemas for Oracle WebCenter Content, run the create-rcu-schema.sh script.\nFor example:\n# make sure rcu pod status is running before executing this kubectl exec -n wccns -ti rcu /bin/bash # DB details export CONNECTION_STRING=your_db_host:1521/your_db_service export RCUPREFIX=your_schema_prefix echo -e welcome1\u0026#34;\\n\u0026#34;welcome1\u0026gt; /tmp/pwd.txt # Create schemas /u01/oracle/oracle_common/bin/rcu -silent -createRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -useSamePasswordForAllSchemaUsers true -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component CONTENT -component MDS -component STB -component OPSS -component IAU -component IAU_APPEND -component IAU_VIEWER -component WLS -tablespace USERS -tempTablespace TEMP -f \u0026lt; /tmp/pwd.txt # Drop schemas /u01/oracle/oracle_common/bin/rcu -silent -dropRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component CONTENT -component MDS -component STB -component OPSS -component IAU -component IAU_APPEND -component IAU_VIEWER -component WLS -f \u0026lt; /tmp/pwd.txt #exit from the container exit Create Oracle WebCenter Content domain Now that you have your Docker images and you have created your RCU schemas, you are ready to create your domain. To continue, follow the instructions in Create Oracle WebCenter Content domains.\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/appendix/quickstart-deployment-guide/",
	"title": "Quick start deployment guide",
	"tags": [],
	"description": "Describes how to quickly get an Oracle WebCenter Content domain instance running (using the defaults, nothing special) for development and test purposes.",
	"content": "Use this Quick Start to create an Oracle WebCenter Content domain deployment in a Kubernetes cluster (on-premise environments) with the Oracle WebLogic Server Kubernetes operator. Note that this walkthrough is for demonstration purposes only, not for use in production. These instructions assume that you are already familiar with Kubernetes. If you need more detailed instructions, refer to the Install Guide.\nHardware requirements Supported Linux kernel for deploying and running Oracle WebCenter Content domain with the operator is Oracle Linux 7 (UL6+) and Red Hat Enterprise Linux 7 (UL3+ only with standalone Kubernetes). Refer to the prerequisites for more details.\nFor this exercise the minimum hardware requirement to create a single node Kubernetes cluster and deploy Oracle WebCenter Content domain with one UCM and IBR Cluster each.\n   Hardware Size     RAM 32GB   Disk Space 250GB+   CPU core(s) 6    See here for resourse sizing information for Oracle WebCenter Content domain setup on Kubernetes cluster.\nSet up Oracle WebCenter Content in an on-premise environment Perform the steps in this topic to create a single instance on-premise Kubernetes cluster and create an Oracle WebCenter Content domain which deploys Oracle WebCenter Content Server and Oracle WebCenter Inbound Refinery Server.\n Step 1 - Prepare a virtual machine for the Kubernetes cluster Step 2 - Set up a single instance Kubernetes cluster Step 3 - Get scripts and images Step 4 - Install the WebLogic Kubernetes Operator Step 5 - Install the Traefik (ingress-based) load balancer Step 6 - Create and configure an Oracle WebCenter Content Domain  1. Prepare a virtual machine for the Kubernetes cluster For illustration purposes, these instructions are for Oracle Linux 7u6+. If you are using a different flavor of Linux, you will need to adjust the steps accordingly.\nThese steps must be run with the root user, unless specified otherwise. Any time you see YOUR_USERID in a command, you should replace it with your actual userid.\n 1.1 Prerequisites   Choose the directories where your Docker and Kubernetes files will be stored. The Docker directory should be on a disk with a lot of free space (more than 100GB) because it will be used for the Docker file system, which contains all of your images and containers. The Kubernetes directory is used for the /var/lib/kubelet file system and persistent volume storage.\n$ export docker_dir=/u01/docker $ export kubelet_dir=/u01/kubelet $ mkdir -p $docker_dir $kubelet_dir $ ln -s $kubelet_dir /var/lib/kubelet   Verify that IPv4 forwarding is enabled on your host.\nNote: Replace eth0 with the ethernet interface name of your compute resource if it is different.\n$ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.docker0.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.eth0.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.lo.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.ip_nonlocal_bind' For example: Verify that all are set to 1\n$ net.ipv4.conf.docker0.forwarding = 1 $ net.ipv4.conf.eth0.forwarding = 1 $ net.ipv4.conf.lo.forwarding = 1 $ net.ipv4.ip_nonlocal_bind = 1 Solution: Set all values to 1 immediately with the following commands:\n$ /sbin/sysctl net.ipv4.conf.docker0.forwarding=1 $ /sbin/sysctl net.ipv4.conf.eth0.forwarding=1 $ /sbin/sysctl net.ipv4.conf.lo.forwarding=1 $ /sbin/sysctl net.ipv4.ip_nonlocal_bind=1 To preserve the settings post-reboot: Update the above values to 1 in files in /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/\n  Verify the iptables rule for forwarding.\nKubernetes uses iptables to handle many networking and port forwarding rules. A standard Docker installation may create a firewall rule that prevents forwarding.\nVerify if the iptables rule to accept forwarding traffic is set:\n$ /sbin/iptables -L -n | awk '/Chain FORWARD / {print $4}' | tr -d \u0026quot;)\u0026quot; If the output is \u0026ldquo;DROP\u0026rdquo;, then run the following command:\n$ /sbin/iptables -P FORWARD ACCEPT Verify if the iptables rule is set properly to \u0026ldquo;ACCEPT\u0026rdquo;:\n$ /sbin/iptables -L -n | awk '/Chain FORWARD / {print $4}' | tr -d \u0026quot;)\u0026quot;   Disable and stop firewalld:\n$ systemctl disable firewalld $ systemctl stop firewalld   1.2 Install and configure Docker  Note : If you have already installed Docker with version 18.03+ and configured Docker daemon root to sufficient disk space along with proxy settings, continue to Install and configure Kubernetes\n   Make sure that you have the right operating system version:\n$ uname -a $ more /etc/oracle-release For example:\nLinux xxxxxxx 4.1.12-124.27.1.el7uek.x86_64 #2 SMP Mon May 13 08:56:17 PDT 2019 x86_64 x86_64 x86_64 GNU/Linux Oracle Linux Server release 7.6   Install the latest docker-engine and start the Docker service:\n$ yum-config-manager --enable ol7_addons $ yum install docker-engine $ systemctl enable docker $ systemctl start docker   Add your userid to the Docker group. This will allow you to run the Docker commands without root access:\n$ /sbin/usermod -a -G docker \u0026lt;YOUR_USERID\u0026gt;   Check your Docker version. It must be at least 18.03.\n$ docker version For example:\nClient: Docker Engine - Community Version: 19.03.1-ol API version: 1.40 Go version: go1.12.5 Git commit: ead9442 Built: Wed Sep 11 06:40:28 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.1-ol API version: 1.40 (minimum version 1.12) Go version: go1.12.5 Git commit: ead9442 Built: Wed Sep 11 06:38:43 2019 OS/Arch: linux/amd64 Experimental: false Default Registry: docker.io containerd: Version: v1.2.0-rc.0-108-gc444666 GitCommit: c4446665cb9c30056f4998ed953e6d4ff22c7c39 runc: Version: 1.0.0-rc5+dev GitCommit: 4bb1fe4ace1a32d3676bb98f5d3b6a4e32bf6c58 docker-init: Version: 0.18.0 GitCommit: fec3683   Update the Docker engine configuration:\n$ mkdir -p /etc/docker $ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/docker/daemon.json { \u0026quot;group\u0026quot;: \u0026quot;docker\u0026quot;, \u0026quot;data-root\u0026quot;: \u0026quot;/u01/docker\u0026quot; } EOF   Configure proxy settings if you are behind an HTTP proxy. On some hosts /etc/systemd/system/docker.service.d may not be available. Create this directory if it is not available.\n ### Create the drop-in file /etc/systemd/system/docker.service.d/http-proxy.conf that contains proxy details: $ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/docker.service.d/http-proxy.conf [Service] Environment=\u0026quot;HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT\u0026quot; Environment=\u0026quot;HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT\u0026quot; Environment=\u0026quot;NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock\u0026quot; EOF   Restart the Docker daemon to load the latest changes:\n$ systemctl daemon-reload $ systemctl restart docker   Verify that the proxy is configured with Docker:\n$ docker info|grep -i proxy For example:\nHTTP Proxy: http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT HTTPS Proxy: http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT No Proxy: localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock   Verify Docker installation:\n$ docker run hello-world For example:\nHello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/   1.3 Install and configure Kubernetes   Add the external Kubernetes repository:\n$ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF   Set SELinux in permissive mode (effectively disabling it):\n$ export PATH=/sbin:$PATH $ setenforce 0 $ sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config   Export proxy and install kubeadm, kubelet, and kubectl:\n### Get the nslookup IP address of the master node to use with apiserver-advertise-address during setting up Kubernetes master ### as the host may have different internal ip (hostname -i) and nslookup $HOSTNAME $ ip_addr=`nslookup $(hostname -f) | grep -m2 Address | tail -n1| awk -F: '{print $2}'| tr -d \u0026quot; \u0026quot;` $ echo $ip_addr ### Set the proxies $ export NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr $ export no_proxy=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr $ export http_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export https_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT ### install kubernetes 1.18.4-1 $ VERSION=1.18.4-1 $ yum install -y kubelet-$VERSION kubeadm-$VERSION kubectl-$VERSION --disableexcludes=kubernetes ### enable kubelet service so that it auto-restart on reboot $ systemctl enable --now kubelet   Ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl to avoid traffic routing issues:\n$ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sysctl --system   Disable swap check:\n$ sed -i 's/KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\u0026quot;--fail-swap-on=false\u0026quot;/' /etc/sysconfig/kubelet $ cat /etc/sysconfig/kubelet ### Reload and restart kubelet $ systemctl daemon-reload $ systemctl restart kubelet   1.4 Set up Helm   Install Helm v3.x.\na. Download Helm from https://github.com/helm/helm/releases. Example to download Helm v3.2.4:\n$ wget https://get.helm.sh/helm-v3.2.4-linux-amd64.tar.gz b. Unpack tar.gz:\n$ tar -zxvf helm-v3.2.4-linux-amd64.tar.gz c. Find the Helm binary in the unpacked directory, and move it to its desired destination:\n$ mv linux-amd64/helm /usr/bin/helm   Run helm version to verify its installation:\n$ helm version version.BuildInfo{Version:\u0026quot;v3.2.4\u0026quot;, GitCommit:\u0026quot;0ad800ef43d3b826f31a5ad8dfbb4fe05d143688\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, GoVersion:\u0026quot;go1.13.12\u0026quot;}   2. Set up a single instance Kubernetes cluster  Notes:\n These steps must be run with the root user, unless specified otherwise! If you choose to use a different cidr block (that is, other than 10.244.0.0/16 for the --pod-network-cidr= in the kubeadm init command), then also update NO_PROXY and no_proxy with the appropriate value.  Also make sure to update kube-flannel.yaml with the new value before deploying.   Replace the following with appropriate values:  ADD-YOUR-INTERNAL-NO-PROXY-LIST REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT     2.1 Set up the master node   Create a shell script that sets up the necessary environment variables. You can append this to the user’s .bashrc so that it will run at login. You must also configure your proxy settings here if you are behind an HTTP proxy:\n## grab my IP address to pass into kubeadm init, and to add to no_proxy vars ip_addr=`nslookup $(hostname -f) | grep -m2 Address | tail -n1| awk -F: '{print $2}'| tr -d \u0026quot; \u0026quot;` export pod_network_cidr=\u0026quot;10.244.0.0/16\u0026quot; export service_cidr=\u0026quot;10.96.0.0/12\u0026quot; export PATH=$PATH:/sbin:/usr/sbin ### Set the proxies export NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr,$pod_network_cidr,$service_cidr export no_proxy=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr,$pod_network_cidr,$service_cidr export http_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export https_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT   Source the script to set up your environment variables:\n$ . ~/.bashrc   To implement command completion, add the following to the script:\n$ [ -f /usr/share/bash-completion/bash_completion ] \u0026amp;\u0026amp; . /usr/share/bash-completion/bash_completion $ source \u0026lt;(kubectl completion bash)   Run kubeadm init to create the master node:\n$ kubeadm init \\ --pod-network-cidr=$pod_network_cidr \\ --apiserver-advertise-address=$ip_addr \\ --ignore-preflight-errors=Swap \u0026gt; /tmp/kubeadm-init.out 2\u0026gt;\u0026amp;1   Log in to the terminal with YOUR_USERID:YOUR_GROUP. Then set up the ~/.bashrc similar to steps 1 to 3 with YOUR_USERID:YOUR_GROUP.\n Note that from now on we will be using YOUR_USERID:YOUR_GROUP to execute any kubectl commands and not root.\n   Set up YOUR_USERID:YOUR_GROUP to access the Kubernetes cluster:\n$ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config   Verify that YOUR_USERID:YOUR_GROUP is set up to access the Kubernetes cluster using the kubectl command:\n$ kubectl get nodes  Note: At this step, the node is not in ready state as we have not yet installed the pod network add-on. After the next step, the node will show status as Ready.\n   Install a pod network add-on (flannel) so that your pods can communicate with each other.\n Note: If you are using a different cidr block than 10.244.0.0/16, then download and update kube-flannel.yml with the correct cidr address before deploying into the cluster:\n $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.12.0/Documentation/kube-flannel.yml   Verify that the master node is in Ready status:\n$ kubectl get nodes For example:\nNAME STATUS ROLES AGE VERSION mymasternode Ready master 8m26s v1.18.4 or:\n$ kubectl get pods -n kube-system For example:\nNAME READY STATUS RESTARTS AGE pod/coredns-86c58d9df4-58p9f 1/1 Running 0 3m59s pod/coredns-86c58d9df4-mzrr5 1/1 Running 0 3m59s pod/etcd-mymasternode 1/1 Running 0 3m4s pod/kube-apiserver-node 1/1 Running 0 3m21s pod/kube-controller-manager-mymasternode 1/1 Running 0 3m25s pod/kube-flannel-ds-amd64-6npx4 1/1 Running 0 49s pod/kube-proxy-4vsgm 1/1 Running 0 3m59s pod/kube-scheduler-mymasternode 1/1 Running 0 2m58s   To schedule pods on the master node, taint the node:\n$ kubectl taint nodes --all node-role.kubernetes.io/master-   Congratulations! Your Kubernetes cluster environment is ready to deploy your Oracle WebCenter Content domain.\nFor additional references on Kubernetes cluster setup, check the cheat sheet.\n3. Get scripts and images 3.1 Set up the code repository to deploy Oracle WebCenter Content domains Follow these steps to set up the source code repository required to deploy Oracle WebCenter Content domains.\n3.2 Get required Docker images and add them to your local registry Follow these steps to set up the source code repository required to deploy Oracle WebCenter Content domains.\n3.3 Build Oracle WebCenter Content Docker image and add it to your local registry Follow these steps to set up the source code repository required to deploy Oracle WebCenter Content domains.\n Note: For test and development purposes this Oracle WebCenter Content image need not contain any product patches.\n 4. Install the WebLogic Kubernetes operator 4.1 Prepare for the WebLogic Kubernetes operator.   Create a namespace opns for the operator:\n$ kubectl create namespace opns   Create a service account op-sa for the operator in the operator’s namespace:\n$ kubectl create serviceaccount -n opns op-sa   4.2 Install the WebLogic Kubernetes operator Use Helm to install and start the operator from the directory you just cloned:\n $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator \\ --namespace opns \\ --set image=oracle/weblogic-kubernetes-operator:3.1.1 \\ --set serviceAccount=op-sa \\ --set \u0026quot;domainNamespaces={}\u0026quot; \\ --wait 4.3 Verify the WebLogic Kubernetes operator   Verify that the operator’s pod is running by listing the pods in the operator’s namespace. You should see one for the operator:\n$ kubectl get pods -n opns   Verify that the operator is up and running by viewing the operator pod\u0026rsquo;s logs:\n$ kubectl logs -n opns -c weblogic-operator deployments/weblogic-operator   The WebLogic Kubernetes operator v3.1.1 has been installed. Continue with the load balancer and Oracle WebCenter Content domain setup.\n5. Install the Traefik (ingress-based) load balancer The Oracle WebLogic Server Kubernetes operator supports three load balancers: Traefik, Voyager, NGINX and Apache. Samples are provided in the documentation.\nThis Quick Start demonstrates how to install the Traefik ingress controller to provide load balancing for an Oracle WebCenter Content domain.\n  Create a namespace for Traefik:\n$ kubectl create namespace traefik   Set up Helm for 3rd party services:\n$ helm repo add traefik https://containous.github.io/traefik-helm-chart   Install the Traefik operator in the traefik namespace with the provided sample values:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\ --namespace traefik \\ --values kubernetes/samples/scripts/charts/traefik/values.yaml \\ --set \u0026quot;kubernetes.namespaces={traefik}\u0026quot; \\ --set \u0026quot;service.type=NodePort\u0026quot; \\ --wait   6. Create and configure an Oracle WebCenter Content domain 6.1 Prepare for an Oracle WebCenter Content domain   Create a namespace that can host Oracle WebCenter Content domain:\n$ kubectl create namespace wccns   Use Helm to configure the operator to manage Oracle WebCenter Content domains in this namespace:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade weblogic-kubernetes-operator kubernetes/charts/weblogic-operator \\ --reuse-values \\ --namespace opns \\ --set \u0026quot;domainNamespaces={wccns}\u0026quot; \\ --wait   Create Kubernetes secrets.\na. Create a Kubernetes secret for the domain in the same Kubernetes namespace as the domain. In this example, the username is weblogic, the password in welcome1, and the namespace is wccns:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-credentials $ ./create-weblogic-credentials.sh \\ -u weblogic \\ -p welcome1 \\ -n wccns \\ -d wccinfra \\ -s wccinfra-domain-credentials b. Create a Kubernetes secret for the RCU in the same Kubernetes namespace as the domain:\n Schema user : WCC1 Schema password : Oradoc_db1 DB sys user password : Oradoc_db1 Domain name : wccinfra Domain Namespace : wccns Secret name : wccinfra-rcu-credentials  $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-rcu-credentials $ ./create-rcu-credentials.sh \\ -u WCC1 \\ -p Oradoc_db1 \\ -a sys \\ -q Oradoc_db1 \\ -d wccinfra \\ -n wccns \\ -s wccinfra-rcu-credentials   Create the Kubernetes persistence volume and persistence volume claim.\n Notes:\n If you are using Oracle WebCenter Content pre-built image, downloaded from My Oracle Support (MOS patch 32822360), then please use the below command to create the directory -   a. Create the Oracle WebCenter Content domain home directory. Determine if a user already exists on your host system with uid:gid of 1000:1000:\n$ sudo getent passwd 1000 If this command returns a username (which is the first field), you can skip the following useradd command. If not, create the oracle user with useradd:\n$ sudo useradd -u 1000 -g 1000 oracle Create the directory that will be used for the Oracle WebCenter Content domain home:\n$ sudo mkdir /scratch/k8s_dir $ sudo chown -R 1000:1000 /scratch/k8s_dir  Notes:\n If you choose to build Oracle WebCenter Content image, instead of downloading from My Oracle Support, then please use the below command to create the directory with updated user permission -   #Determine if a user already exists on your host system with `uid:gid` of `1000:0`: $ sudo getent passwd 1000 $ sudo useradd -u 1000 -g 0 oracle $ sudo mkdir /scratch/k8s_dir $ sudo chown -R 1000:0 /scratch/k8s_dir b. Update create-pv-pvc-inputs.yaml with the following values:\n baseName: domain domainUID: wccinfra namespace: wccns weblogicDomainStoragePath: /scratch/k8s_dir  $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ cp create-pv-pvc-inputs.yaml create-pv-pvc-inputs.yaml.orig $ sed -i -e \u0026quot;s:baseName\\: weblogic-sample:baseName\\: domain:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:domainUID\\::domainUID\\: wccinfra:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:namespace\\: default:namespace\\: wccns:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:#weblogicDomainStoragePath\\: /scratch/k8s_dir:weblogicDomainStoragePath\\: /scratch/k8s_dir:g\u0026quot; create-pv-pvc-inputs.yaml c. Run the create-pv-pvc.sh script to create the PV and PVC configuration files:\n$ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output d. Create the PV and PVC using the configuration files created in the previous step:\n$ kubectl create -f output/pv-pvcs/wccinfra-domain-pv.yaml $ kubectl create -f output/pv-pvcs/wccinfra-domain-pvc.yaml   Configure the database and create schemas for the Oracle WebCenter Content domain.\nFollow configure-database-access step and run-RCU step to set up the database connection and configure product schemas required to deploy Oracle WebCenter Content domain.\n  Now the environment is ready to start the Oracle WebCenter Content domain creation.\n6.2 Create an Oracle WebCenter Content domain   The sample scripts for Oracle WebCenter Content domain deployment are available at \u0026lt;weblogic-kubernetes-operator-project\u0026gt;/kubernetes/samples/scripts/create-wcc-domain. You must edit create-domain-inputs.yaml (or a copy of it) to provide the details for your domain.\n  Run the create-domain.sh script to create a domain:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./create-domain.sh -i create-domain-inputs.yaml -o output   Create a Kubernetes domain object:\nOnce the create-domain.sh is successful, it generates the output/weblogic-domains/wccinfra/domain.yaml that you can use to create the Kubernetes resource domain, which starts the domain and servers:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv $ kubectl create -f output/weblogic-domains/wccinfra/domain.yaml   Verify that the Kubernetes domain object named wccinfra is created:\n$ kubectl get domain -n wccns NAME AGE wccinfra 3m18s   Once you create the domain, introspect pod is created. This inspects the domain home and then starts the wccinfra-adminserver pod. Once the wccinfra-adminserver pod starts successfully, then the Managed Server pods are started in parallel. Watch the wccns namespace for the status of domain creation:\n$ kubectl get pods -n wccns   Verify that the Oracle WebCenter Content domain server pods and services are created and in Ready state:\n$ kubectl get all -n wccns   6.3 Configure Traefik to access in Oracle WebCenter Content domain services   Configure Traefik to manage ingresses created in the Oracle WebCenter Content domain namespace (wccns):\n$ helm upgrade traefik traefik/traefik \\ --reuse-values \\ --namespace traefik \\ --set \u0026quot;kubernetes.namespaces={traefik,wccns}\u0026quot; \\ --wait   Create an ingress for the domain in the domain namespace by using the sample Helm chart:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcc-traefik-ingress kubernetes/samples/charts/ingress-per-domain \\ --namespace wccns \\ --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\ --set \u0026quot;traefik.hostname=$(hostname -f)\u0026quot;   Verify the created ingress per domain details:\n$ kubectl describe ingress wccinfra-traefik -n wccns   6.4 Verify that you can access the Oracle WebCenter Content domain URL   Get the LOADBALANCER_HOSTNAME for your environment:\nexport LOADBALANCER_HOSTNAME=$(hostname -f)   The following URLs are available for Oracle WebCenter Content domain:\nCredentials: username: weblogic password: welcome1\nhttp://${LOADBALANCER_HOSTNAME}:30305/console http://${LOADBALANCER_HOSTNAME}:30305/em http://${LOADBALANCER_HOSTNAME}:30305/cs http://${LOADBALANCER_HOSTNAME}:30305/ibr   "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/configure-load-balancer/nginx/",
	"title": "NGINX",
	"tags": [],
	"description": "Configure the ingress-based NGINX load balancer for Oracle WebCenter Content domain.",
	"content": "This section provides information about how to install and configure the ingress-based NGINX load balancer to load balance Oracle WebCenter Content domain clusters. You can configure NGINX for non-SSL, SSL termination, and end-to-end SSL access of the application URL.\nFollow these steps to set up NGINX as a load balancer for an Oracle WebCenter Content domain in a Kubernetes cluster:\nSee the official installation document for prerequisites.\n  Non-SSL and SSL termination\n Install the NGINX load balancer Configure NGINX to manage ingresses Verify non-SSL and SSL termination access    End-to-end SSL configuration\n Install the NGINX load balancer for End-to-end SSL Deploy tls to access UCM and IBR Managed Servers Deploy tls to access Administration Server    To get repository information, enter the following Helm commands:\n$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx $ helm repo update Non-SSL and SSL termination Install the NGINX load balancer   Deploy the ingress-nginx controller by using Helm on the domain namespace:\n$ helm install nginx-ingress -n wccns \\  --set controller.service.type=NodePort \\  --set controller.admissionWebhooks.enabled=false \\  ingress-nginx/ingress-nginx     Click here to see the sample output.   NAME: nginx-ingress LAST DEPLOYED: Sun Feb 7 23:19:30 2021 NAMESPACE: wccns STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export HTTP_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export HTTPS_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[1].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export NODE_IP=$(kubectl --namespace wccns get nodes -o jsonpath=\u0026#34;{.items[0].status.addresses[1].address}\u0026#34;) echo \u0026#34;Visit http://$NODE_IP:$HTTP_NODE_PORTto access your application via HTTP.\u0026#34; echo \u0026#34;Visit https://$NODE_IP:$HTTPS_NODE_PORTto access your application via HTTPS.\u0026#34; An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls      Check the status of the deployed ingress controller:\n$ kubectl --namespace wccns get services | grep ingress-nginx-controller Sample output:\nnginx-ingress-ingress-nginx-controller NodePort 10.97.189.122 \u0026lt;none\u0026gt; 80:30993/TCP,443:30232/TCP 7d2h   Configure NGINX to manage ingresses  Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK, tls is Non-SSL, and domainType is wccinfra. These values can be overridden by passing values through the command line or can be edited in the sample file values.yaml. If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. Update the template YAML file for the NGINX load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/nginx-ingress.yaml  $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wccinfra-nginx-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;nginx.hostname=$(hostname -f)\u0026#34; \\  --set type=NGINX \\  --set tls=NONSSL Sample output:\nNAME: wccinfra-nginx-ingress LAST DEPLOYED: Sun Feb 7 23:52:38 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate a Kubernetes secret:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Install ingress-per-domain using Helm for SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wccinfra-nginx-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;nginx.hostname=$(hostname -f)\u0026#34; \\  --set type=NGINX --set tls=SSL Sample output:\nNAME: wccinfra-nginx-ingress LAST DEPLOYED: Mon Feb 8 00:01:13 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None   For non-SSL access or SSL to the Oracle WebCenter Content application, get the details of the services by the ingress:\n$ kubectl describe ingress wccinfra-nginx -n wccns     Click here to see the sample output of the services supported by the above deployed ingress.   Name: wccinfra-nginx Namespace: wccns Address: 10.97.189.122 Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026#34;default-http-backend\u0026#34; not found\u0026gt;) TLS: domain1-tls-cert terminates domain1.org Rules: Host Path Backends ---- ---- -------- domain1.org /console wccinfra-adminserver:7001 (10.244.0.58:7001) /em wccinfra-adminserver:7001 (10.244.0.58:7001) /servicebus wccinfra-adminserver:7001 (10.244.0.58:7001) /cs wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /adfAuthentication wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) /ibr wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /ibr/adfAuthentication wccinfra-cluster-ibr-cluster:16250 (10.244.0.59:16250) /weblogic/ready wccinfra-cluster-ucm-cluster:16200 (10.244.0.60:16200,10.244.0.61:16200) Annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: wccinfra-nginx-ingress meta.helm.sh/release-namespace: wccns nginx.ingress.kubernetes.io/configuration-snippet: more_set_input_headers \u0026#34;X-Forwarded-Proto: https\u0026#34;; more_set_input_headers \u0026#34;WL-Proxy-SSL: true\u0026#34;; nginx.ingress.kubernetes.io/ingress.allow-http: false Events: \u0026lt;none\u0026gt;    Verify non-SSL and SSL termination access Non-SSL configuration Verify that the Oracle WebCenter Content domain application URLs are accessible through the LOADBALANCER-Non-SSLPORT:\nhttp://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr SSL configuration Verify that the Oracle WebCenter Content domain application URLs are accessible through the LOADBALANCER-SSLPORT:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr Uninstall the ingress Uninstall and delete the ingress-nginx deployment:\n$ helm delete wccinfra-nginx -n wccns End-to-end SSL configuration Install the NGINX load balancer for End-to-end SSL   For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate secrets:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Deploy the ingress-nginx controller by using Helm on the domain namespace:\n$ helm install nginx-ingress -n wccns \\  --set controller.extraArgs.default-ssl-certificate=wccns/domain1-tls-cert \\  --set controller.service.type=NodePort \\  --set controller.admissionWebhooks.enabled=false \\  --set controller.extraArgs.enable-ssl-passthrough=true \\  ingress-nginx/ingress-nginx\t   Click here to see the sample output.   Release \u0026#34;nginx-ingress\u0026#34; has been upgraded. Happy Helming! NAME: nginx-ingress LAST DEPLOYED: Mon Feb 8 02:07:26 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export HTTP_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export HTTPS_NODE_PORT=$(kubectl --namespace wccns get services -o jsonpath=\u0026#34;{.spec.ports[1].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export NODE_IP=$(kubectl --namespace wccns get nodes -o jsonpath=\u0026#34;{.items[0].status.addresses[1].address}\u0026#34;) echo \u0026#34;Visit http://$NODE_IP:$HTTP_NODE_PORTto access your application via HTTP.\u0026#34; echo \u0026#34;Visit https://$NODE_IP:$HTTPS_NODE_PORTto access your application via HTTPS.\u0026#34; An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls      Check the status of the deployed ingress controller:\n$ kubectl --namespace wccns get services | grep ingress-nginx-controller Sample output:\nnginx-ingress-ingress-nginx-controller NodePort 10.97.189.122 \u0026lt;none\u0026gt; 80:30993/TCP,443:30232/TCP 168m   Deploy tls to access UCM and IBR Managed Servers   Deploy tls to securely access the services. Only one application can be configured with ssl-passthrough. A sample tls file for NGINX is shown below for the service wccinfra-cluster-ucm-cluster and port 16201. All the applications running on port 16201 can be securely accessed through this ingress. For each backend service, create different ingresses as NGINX does not support multiple path/rules with annotation ssl-passthrough. That is, for wccinfra-cluster-ucm-cluster, wccinfra-cluster-ibr-cluster and wccinfra-adminserver, different ingresses must be created.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls Sample nginx-ucm-tls.yaml:\n  Click here to see the content of the file nginx-ucm-tls.yaml   apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wcc-ucm-ingress namespace: wccns annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: \u0026#34;true\u0026#34; spec: tls: - hosts: - \u0026#39;domain1.org\u0026#39; secretName: domain1-tls-cert rules: - host: \u0026#39;domain1.org\u0026#39; http: paths: - path: backend: serviceName: wccinfra-cluster-ucm-cluster servicePort: 16201     Note: host is the server on which this ingress is deployed.\n   Deploy the secured ingress:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl create -f nginx-ucm-tls.yaml   Check the services supported by the ingress:\n$ kubectl describe ingress wcc-ucm-ingress -n wccns    Click here check the services supported by the ingress.   Name: wcc-ucm-ingress Namespace: wccns Address: 10.102.97.237 Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026#34;default-http-backend\u0026#34; not found\u0026gt;) TLS: domain1-tls-cert terminates domain1.org Rules: Host Path Backends ---- ---- -------- domain1.org wccinfra-cluster-ucm-cluster:16201 (10.244.238.136:16201,10.244.253.132:16201) Annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: true Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Sync 62s (x2 over 106s) nginx-ingress-controller Scheduled for sync      Verify end-to-end SSL access Verify that the Oracle WebCenter Content domain application URLs are accessible through the LOADBALANCER-SSLPORT:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs Deploy tls to access Administration Server   As ssl-passthrough in NGINX works on the clusterIP of the backing service instead of individual endpoints, you must expose adminserver service created by the operator with clusterIP.\nFor example:\na. Get the name of Administration Server service:\n$ kubectl get svc -n wccns | grep wccinfra-adminserver Sample output:\nwccinfra-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP,7002/TCP 7 b. Expose the Administration Server service wccinfra-adminserver and use the new service name wccinfra-adminserver-nginx-ssl:\n$ kubectl expose svc wccinfra-adminserver -n wccns --name=wccinfra-adminserver-nginx-ssl --port=7002 c. Deploy the secured ingress:\nSample nginx-admin-tls.yaml:\n  Click here to see the content of the file nginx-admin-tls.yaml   apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wcc-admin-ingress namespace: wccns annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: \u0026#34;true\u0026#34; spec: tls: - hosts: - \u0026#39;domain1.org\u0026#39; secretName: domain1-tls-cert rules: - host: \u0026#39;domain1.org\u0026#39; http: paths: - path: backend: serviceName: wccinfra-adminserver-nginx-ssl servicePort: 7002     Note: host is the server on which this ingress is deployed.\n $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl create -f nginx-admin-tls.yaml   Verify end-to-end SSL access Verify that the Oracle WebCenter Content Administration Server URL is accessible through the LOADBALANCER-SSLPORT:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console Uninstall ingress-nginx tls $ cd weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl delete -f nginx-ucm-tls.yaml "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/installguide/",
	"title": "Install Guide",
	"tags": [],
	"description": "",
	"content": "Install the WebLogic Kubernetes operator and prepare and deploy the Oracle WebCenter Portal domain.\n Requirements and limitations  Understand the system requirements and limitations for deploying and running Oracle WebCenter Portal with the WebLogic Kubernetes operator.\n Prepare your environment  Prepare for creating the Oracle WebCenter Portal domain, This preparation includes but not limited to creating required secrets, persistent volume and volume claim, and database schema.\n Create WebCenter Portal domain  Create an Oracle WebCenter Portal domain home on an existing PV or PVC, and create the domain resource YAML file for deploying the generated Oracle WebCenter Portal domain.\n Configure WebCenter Portal For Search  Set up search functionality in Oracle WebCenter Portal using Elasticsearch.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/appendix/quickstart-deployment-on-prem/",
	"title": "Quick start deployment on-premise",
	"tags": [],
	"description": "Describes how to quickly get an Oracle WebCenter Portal domain instance running (using the defaults, nothing special) for development and test purposes.",
	"content": "Use this Quick Start to create an Oracle WebCenter Portal domain deployment in a Kubernetes cluster (on-premise environments) with the WebLogic Kubernetes Operator. Note that this walkthrough is for demonstration purposes only, not for use in production. These instructions assume that you are already familiar with Kubernetes. If you need more detailed instructions, refer to the Install Guide.\nHardware requirements The Linux kernel supported for deploying and running Oracle WebCenter Portal domains with the operator is Oracle Linux 7 (UL6+) and Red Hat Enterprise Linux 7 (UL3+ only with standalone Kubernetes). Refer to the prerequisites for more details.\nFor this exercise, the minimum hardware requirements to create a single-node Kubernetes cluster and then deploy the domain type with one Managed Server along with Oracle Database running as a container are:\n   Hardware Size     RAM 32GB   Disk Space 250GB+   CPU core(s) 6    See here for resource sizing information for Oracle WebCenter Portal domain set up on a Kubernetes cluster.\nSet up Oracle WebCenter Portal in an on-premise environment Use the steps in this topic to create a single-instance on-premise Kubernetes cluster and then create an Oracle WebCenter Portal domain.\n Step 1 - Prepare a virtual machine for the Kubernetes cluster Step 2 - Set up a single instance Kubernetes cluster Step 3 - Get scripts and images Step 4 - Install the WebLogic Kubernetes operator Step 5 - Install the Traefik (ingress-based) load balancer Step 6 - Create and configure an Oracle WebCenter Portal domain  1. Prepare a virtual machine for the Kubernetes cluster For illustration purposes, these instructions are for Oracle Linux 7u6+. If you are using a different flavor of Linux, you will need to adjust the steps accordingly.\nThese steps must be run with the root user, unless specified otherwise. Any time you see YOUR_USERID in a command, you should replace it with your actual userid.\n 1.1 Prerequisites   Choose the directories where your Docker and Kubernetes files will be stored. The Docker directory should be on a disk with a lot of free space (more than 100GB) because it will be used for the Docker file system, which contains all of your images and containers. The Kubernetes directory is used for the /var/lib/kubelet file system and persistent volume storage.\n$ export docker_dir=/u01/docker $ export kubelet_dir=/u01/kubelet $ mkdir -p $docker_dir $kubelet_dir $ ln -s $kubelet_dir /var/lib/kubelet   Verify that IPv4 forwarding is enabled on your host.\nNote: Replace eth0 with the ethernet interface name of your compute resource if it is different.\n$ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.docker0.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.eth0.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.conf.lo.forwarding' $ /sbin/sysctl -a 2\u0026gt;\u0026amp;1|grep -s 'net.ipv4.ip_nonlocal_bind' For example: Verify that all are set to 1:\n$ net.ipv4.conf.docker0.forwarding = 1 $ net.ipv4.conf.eth0.forwarding = 1 $ net.ipv4.conf.lo.forwarding = 1 $ net.ipv4.ip_nonlocal_bind = 1 Solution: Set all values to 1 immediately:\n$ /sbin/sysctl net.ipv4.conf.docker0.forwarding=1 $ /sbin/sysctl net.ipv4.conf.eth0.forwarding=1 $ /sbin/sysctl net.ipv4.conf.lo.forwarding=1 $ /sbin/sysctl net.ipv4.ip_nonlocal_bind=1   To preserve the settings permanently: Update the above values to 1 in files in /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/.\n  Verify the iptables rule for forwarding.\nKubernetes uses iptables to handle many networking and port forwarding rules. A standard Docker installation may create a firewall rule that prevents forwarding.\nVerify if the iptables rule to accept forwarding traffic is set:\n$ /sbin/iptables -L -n | awk '/Chain FORWARD / {print $4}' | tr -d \u0026quot;)\u0026quot; If the output is \u0026ldquo;DROP\u0026rdquo;, then run the following command:\n$ /sbin/iptables -P FORWARD ACCEPT Verify if the iptables rule is properly set to \u0026ldquo;ACCEPT\u0026rdquo;:\n$ /sbin/iptables -L -n | awk '/Chain FORWARD / {print $4}' | tr -d \u0026quot;)\u0026quot;   Disable and stop firewalld:\n$ systemctl disable firewalld $ systemctl stop firewalld   1.2 Install and configure Docker  Note: If you have already installed Docker with version 18.03+ and configured the Docker daemon root to sufficient disk space along with proxy settings, continue to Install and configure Kubernetes.\n   Make sure that you have the right operating system version:\n$ uname -a $ more /etc/oracle-release Example output:\nLinux xxxxxxx 4.1.12-124.27.1.el7uek.x86_64 #2 SMP Mon May 13 08:56:17 PDT 2019 x86_64 x86_64 x86_64 GNU/Linux Oracle Linux Server release 7.6   Install the latest docker-engine and start the Docker service:\n$ yum-config-manager --enable ol7_addons $ docker_version=\u0026quot;19.03.1.ol\u0026quot; $ yum install docker-engine-$docker_version $ systemctl enable docker $ systemctl start docker   Add your user ID to the Docker group to allow you to run Docker commands without root access:\n$ /sbin/usermod -a -G docker \u0026lt;YOUR_USERID\u0026gt;   Check that your Docker version is at least 18.03:\n$ docker version Example output:\nClient: Docker Engine - Community Version: 19.03.1-ol API version: 1.40 Go version: go1.12.5 Git commit: ead9442 Built: Wed Sep 11 06:40:28 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.1-ol API version: 1.40 (minimum version 1.12) Go version: go1.12.5 Git commit: ead9442 Built: Wed Sep 11 06:38:43 2019 OS/Arch: linux/amd64 Experimental: false Default Registry: docker.io containerd: Version: v1.2.0-rc.0-108-gc444666 GitCommit: c4446665cb9c30056f4998ed953e6d4ff22c7c39 runc: Version: 1.0.0-rc5+dev GitCommit: 4bb1fe4ace1a32d3676bb98f5d3b6a4e32bf6c58 docker-init: Version: 0.18.0 GitCommit: fec3683   Update the Docker engine configuration:\n$ mkdir -p /etc/docker $ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/docker/daemon.json { \u0026quot;group\u0026quot;: \u0026quot;docker\u0026quot;, \u0026quot;data-root\u0026quot;: \u0026quot;/u01/docker\u0026quot; } EOF   Configure proxy settings if you are behind an HTTP proxy:\n ### Create the drop-in file /etc/systemd/system/docker.service.d/http-proxy.conf that contains proxy details: $ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/docker.service.d/http-proxy.conf [Service] Environment=\u0026quot;HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT\u0026quot; Environment=\u0026quot;HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT\u0026quot; Environment=\u0026quot;NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock\u0026quot; EOF  Note: On some hosts /etc/systemd/system/docker.service.d may not be available. Create this directory if it is not available.\n   Restart the Docker daemon to load the latest changes:\n$ systemctl daemon-reload $ systemctl restart docker   Verify that the proxy is configured with Docker:\n$ docker info|grep -i proxy Example output:\nHTTP Proxy: http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT HTTPS Proxy: http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT No Proxy: localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock   Verify Docker installation:\n$ docker run hello-world Example output:\nHello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/   1.3 Install and configure Kubernetes   Add the external Kubernetes repository:\n$ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF   Set SELinux in permissive mode (effectively disabling it):\n$ export PATH=/sbin:$PATH $ setenforce 0 $ sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config   Export proxy and install kubeadm, kubelet, and kubectl:\n### Get the nslookup IP address of the master node to use with apiserver-advertise-address during setting up Kubernetes master ### as the host may have different internal ip (hostname -i) and nslookup $HOSTNAME $ ip_addr=`nslookup $(hostname -f) | grep -m2 Address | tail -n1| awk -F: '{print $2}'| tr -d \u0026quot; \u0026quot;` $ echo $ip_addr ### Set the proxies $ export NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr $ export no_proxy=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr $ export http_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export https_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT $ export HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT ### install kubernetes 1.18.4-1 $ VERSION=1.18.4-1 $ yum install -y kubelet-$VERSION kubeadm-$VERSION kubectl-$VERSION --disableexcludes=kubernetes ### enable kubelet service so that it auto-restart on reboot $ systemctl enable --now kubelet   Ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl to avoid traffic routing issues:\n$ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sysctl --system   Disable swap check:\n$ sed -i 's/KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\u0026quot;--fail-swap-on=false\u0026quot;/' /etc/sysconfig/kubelet $ cat /etc/sysconfig/kubelet ### Reload and restart kubelet $ systemctl daemon-reload $ systemctl restart kubelet   1.4 Set up Helm   Install Helm v3.x.\na. Download Helm from https://github.com/helm/helm/releases.\nFor example, to download Helm v3.1.3:\n$ wget https://get.helm.sh/helm-v3.1.3-linux-amd64.tar.gz b. Unpack tar.gz:\n$ tar -zxvf helm-v3.1.3-linux-amd64.tar.gz c. Find the Helm binary in the unpacked directory, and move it to its desired destination:\n$ mv linux-amd64/helm /usr/bin/helm   Run helm version to verify its installation:\n$ helm version version.BuildInfo{Version:\u0026quot;v3.1.3\u0026quot;, GitCommit:\u0026quot;0ad800ef43d3b826f31a5ad8dfbb4fe05d143688\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, GoVersion:\u0026quot;go1.13.12\u0026quot;}   2. Set up a single instance Kubernetes cluster  Notes:\n These steps must be run with the root user, unless specified otherwise! If you choose to use a different CIDR block (that is, other than 10.244.0.0/16 for the --pod-network-cidr= in the kubeadm init command), then also update NO_PROXY and no_proxy with the appropriate value.  Also make sure to update kube-flannel.yaml with the new value before deploying.   Replace the following with appropriate values:  ADD-YOUR-INTERNAL-NO-PROXY-LIST REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT     2.1 Set up the master node   Create a shell script that sets up the necessary environment variables. You can append this to the user’s .bashrc so that it will run at login. You must also configure your proxy settings here if you are behind an HTTP proxy:\n## grab my IP address to pass into kubeadm init, and to add to no_proxy vars ip_addr=`nslookup $(hostname -f) | grep -m2 Address | tail -n1| awk -F: '{print $2}'| tr -d \u0026quot; \u0026quot;` export pod_network_cidr=\u0026quot;10.244.0.0/16\u0026quot; export service_cidr=\u0026quot;10.96.0.0/12\u0026quot; export PATH=$PATH:/sbin:/usr/sbin ### Set the proxies export NO_PROXY=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr,$pod_network_cidr,$service_cidr export no_proxy=localhost,127.0.0.0/8,ADD-YOUR-INTERNAL-NO-PROXY-LIST,/var/run/docker.sock,$ip_addr,$pod_network_cidr,$service_cidr export http_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export https_proxy=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export HTTPS_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT export HTTP_PROXY=http://REPLACE-WITH-YOUR-COMPANY-PROXY-HOST:PORT   Source the script to set up your environment variables:\n$ . ~/.bashrc   To implement command completion, add the following to the script:\n$ [ -f /usr/share/bash-completion/bash_completion ] \u0026amp;\u0026amp; . /usr/share/bash-completion/bash_completion $ source \u0026lt;(kubectl completion bash)   Run kubeadm init to create the master node:\n$ kubeadm init \\ --pod-network-cidr=$pod_network_cidr \\ --apiserver-advertise-address=$ip_addr \\ --ignore-preflight-errors=Swap \u0026gt; /tmp/kubeadm-init.out 2\u0026gt;\u0026amp;1   Log in to the terminal with YOUR_USERID:YOUR_GROUP. Then set up the ~/.bashrc similar to steps 1 to 3 with YOUR_USERID:YOUR_GROUP.\n Note that from now on we will be using YOUR_USERID:YOUR_GROUP to execute any kubectl commands and not root.\n   Set up YOUR_USERID:YOUR_GROUP to access the Kubernetes cluster:\n$ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config   Verify that YOUR_USERID:YOUR_GROUP is set up to access the Kubernetes cluster using the kubectl command:\n$ kubectl get nodes  Note: At this step, the node is not in ready state as we have not yet installed the pod network add-on. After the next step, the node will show status as Ready.\n   Install a pod network add-on (flannel) so that your pods can communicate with each other.\n Note: If you are using a different CIDR block than 10.244.0.0/16, then download and update kube-flannel.yml with the correct CIDR address before deploying into the cluster:\n $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.12.0/Documentation/kube-flannel.yml   Verify that the master node is in Ready status:\n$ kubectl get nodes Sample output:\nNAME STATUS ROLES AGE VERSION mymasternode Ready master 8m26s v1.18.4 or:\n$ kubectl get pods -n kube-system Sample output:\nNAME READY STATUS RESTARTS AGE pod/coredns-86c58d9df4-58p9f 1/1 Running 0 3m59s pod/coredns-86c58d9df4-mzrr5 1/1 Running 0 3m59s pod/etcd-mymasternode 1/1 Running 0 3m4s pod/kube-apiserver-node 1/1 Running 0 3m21s pod/kube-controller-manager-mymasternode 1/1 Running 0 3m25s pod/kube-flannel-ds-amd64-6npx4 1/1 Running 0 49s pod/kube-proxy-4vsgm 1/1 Running 0 3m59s pod/kube-scheduler-mymasternode 1/1 Running 0 2m58s   To schedule pods on the master node, taint the node:\n$ kubectl taint nodes --all node-role.kubernetes.io/master-   Congratulations! Your Kubernetes cluster environment is ready to deploy your Oracle WebCenter Portal domain.\nFor additional references on Kubernetes cluster setup, check the cheat sheet.\n3. Get scripts and images 3.1 Set up the code repository to deploy Oracle WebCenter Portal Follow these steps to set up the source code repository required to deploy Oracle WebCenter Portal domain.\n3.2 Get required Docker images and add them to your local registry   Pull the operator image:\n$ docker pull ghcr.io/oracle/weblogic-kubernetes-operator:3.1.1   Obtain the Oracle Database image from the Oracle Container Registry:\na. For first time users, to pull an image from the Oracle Container Registry, navigate to https://container-registry.oracle.com and log in using the Oracle Single Sign-On (SSO) authentication service. If you do not already have SSO credentials, you can create an Oracle Account using:\nhttps://profile.oracle.com/myprofile/account/create-account.jspx.\nUse the web interface to accept the Oracle Standard Terms and Restrictions for the Oracle software images that you intend to deploy. Your acceptance of these terms are stored in a database that links the software images to your Oracle Single Sign-On login credentials.\nTo obtain the image, log in to the Oracle Container Registry:\n$ docker login container-registry.oracle.com b. Find and then pull the Oracle Database image for 12.2.0.1:\n$ docker pull container-registry.oracle.com/database/enterprise:12.2.0.1-slim c. Build Oracle WebCenter Portal 12.2.1.4 Image by following steps from this document.\n  4. Install the WebLogic Kubernetes operator 4.1 Prepare for the WebLogic Kubernetes operator.   Create a namespace operator-ns for the operator:\n$ kubectl create namespace operator-ns   Create a service account operator-sa for the operator in the operator’s namespace:\n$ kubectl create serviceaccount -n operator-ns operator-sa   4.2 Install the WebLogic Kubernetes operator Use Helm to install and start the operator from the directory you just cloned:\n $ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator \\ --namespace operator-ns \\ --set image=oracle/weblogic-kubernetes-operator:3.1.1 \\ --set serviceAccount=operator-sa \\ --set \u0026quot;domainNamespaces={}\u0026quot; \\ --wait 4.3 Verify the WebLogic Kubernetes operator   Verify that the operator’s pod is running by listing the pods in the operator’s namespace. You should see one for the operator:\n$ kubectl get pods -n operator-ns   Verify that the operator is up and running by viewing the operator pod\u0026rsquo;s logs:\n$ kubectl logs -n operator-ns -c weblogic-operator deployments/weblogic-operator   The WebLogic Kubernetes operator v3.1.1 has been installed. Continue with the load balancer and Oracle WebCenter Portal domain setup.\n5. Install the Traefik (ingress-based) load balancer The WebLogic Kubernetes Operator supports three load balancers: Traefik, Voyager, and Apache. Samples are provided in the documentation.\nThis Quick Start demonstrates how to install the Traefik ingress controller to provide load balancing for an Oracle WebCenter Portal domain.\n  Create a namespace for Traefik:\n$ kubectl create namespace traefik   Set up Helm for 3rd party services:\n$ helm repo add traefik https://containous.github.io/traefik-helm-chart   Install the Traefik operator in the traefik namespace with the provided sample values:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install traefik traefik/traefik \\ --namespace traefik \\ --values kubernetes/samples/scripts/charts/traefik/values.yaml \\ --set \u0026quot;kubernetes.namespaces={traefik}\u0026quot; \\ --set \u0026quot;service.type=NodePort\u0026quot; \\ --wait   6. Create and configure an Oracle WebCenter Portal domain 6.1 Prepare for an Oracle WebCenter Portal domain   Create a namespace that can host Oracle WebCenter Portal domain:\n$ kubectl create namespace wcpns   Use Helm to configure the operator to manage Oracle WebCenter Portal domain in this namespace:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade weblogic-kubernetes-operator kubernetes/charts/weblogic-operator \\ --reuse-values \\ --namespace operator-ns \\ --set \u0026quot;domainNamespaces={wcpns}\u0026quot; \\ --wait   Create Kubernetes secrets.\na. Create a Kubernetes secret for the domain in the same Kubernetes namespace as the domain. In this example, the username is weblogic, the password is welcome1, and the namespace is wcpns:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-credentials $ sh create-weblogic-credentials.sh -u weblogic -p welcome1 -n wcpns -d wcp-domain -s wcpinfra-domain-credentials b. Create a Kubernetes secret for the RCU in the same Kubernetes namespace as the domain:\n Schema user : WCP1 Schema password : Oradoc_db1 DB sys user password : Oradoc_db1 Domain name : wcp-domain Domain Namespace : wcpns Secret name : wcpinfra-rcu-credentials  $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-rcu-credentials $ sh create-rcu-credentials.sh -u WCP1 -p Oradoc_db1 -a sys -q Oradoc_db1 -n wcpns -d wcp-domain -s wcpinfra-rcu-credentials   Create the Kubernetes persistence volume and persistence volume claim.\na. Create the Oracle WebCenter Portal domain home directory. Determine if a user already exists on your host system with uid:gid of 1000:\n$ sudo getent passwd 1000 If this command returns a username (which is the first field), you can skip the following useradd command. If not, create the oracle user with useradd:\n$ sudo useradd -u 1000 -g 1000 oracle Create the directory that will be used for the Oracle WebCenter Portal domain home:\n$ sudo mkdir /scratch/k8s_dir $ sudo chown -R 1000:1000 /scratch/k8s_dir b. Update create-pv-pvc-inputs.yaml with the following values:\n baseName: domain domainUID: wcp-domain namespace: wcpns weblogicDomainStoragePath: /scratch/k8s_dir  $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ cp create-pv-pvc-inputs.yaml create-pv-pvc-inputs.yaml.orig $ sed -i -e \u0026quot;s:baseName\\: weblogic-sample:baseName\\: domain:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:domainUID\\::domainUID\\: wcp-domain:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:namespace\\: default:namespace\\: wcpns:g\u0026quot; create-pv-pvc-inputs.yaml $ sed -i -e \u0026quot;s:#weblogicDomainStoragePath\\: /scratch/k8s_dir:weblogicDomainStoragePath\\: /scratch/k8s_dir:g\u0026quot; create-pv-pvc-inputs.yaml c. Run the create-pv-pvc.sh script to create the PV and PVC configuration files:\n$ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output d. Create the PV and PVC using the configuration files created in the previous step:\n $ kubectl create -f output/pv-pvcs/wcp-domain-domain-pv.yaml $ kubectl create -f output/pv-pvcs/wcp-domain-domain-pvc.yaml   Install and configure the database for the Oracle WebCenter Portal domain.\nThis step is required only when a standalone database is not already set up and you want to use the database in a container.\nThe Oracle Database Docker images are supported only for non-production use. For more details, see My Oracle Support note: Oracle Support for Database Running on Docker (Doc ID 2216342.1). For production, it is suggested to use a standalone database. This example provides steps to create the database in a container.\n a. Create a database in a container:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-oracle-db-service $ ./start-db-service.sh -i container-registry.oracle.com/database/enterprise:12.2.0.1-slim -p none Once the database is successfully created, you can use the database connection string oracle-db.default.svc.cluster.local:1521/devpdb.k8s as an rcuDatabaseURL parameter in the create-domain-inputs.yaml file.\nb. Create Oracle WebCenter Portal schemas.\nTo create the Oracle WebCenter Portal schemas, run the following commands:\n $ kubectl run rcu --generator=run-pod/v1 --image oracle/wcportal:12.2.1.4 -n wcpns -- sleep infinity #check the status of rcu pod $ kubectl get pods -n wcpns #make sure rcu pod status is running before executing this $ kubectl exec -n wcpns -ti rcu /bin/bash #After Getting Shell in RCU Container run the below command. export CONNECTION_STRING=oracle-db.default.svc.cluster.local:1521/devpdb.k8s export RCUPREFIX=WCP1 echo -e Oradoc_db1\u0026quot;\\n\u0026quot;Oradoc_db1 \u0026gt; /tmp/pwd.txt /u01/oracle/oracle_common/bin/rcu -silent -dropRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component OPSS -component IAU_VIEWER -component WEBCENTER -component MDS -component IAU_APPEND -component STB -component IAU -component WLS -f \u0026lt; /tmp/pwd.txt /u01/oracle/oracle_common/bin/rcu -silent -createRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -useSamePasswordForAllSchemaUsers true -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component OPSS -component IAU_VIEWER -component WEBCENTER -component MDS -component IAU_APPEND -component STB -component IAU -component WLS -tablespace USERS -tempTablespace TEMP -f \u0026lt; /tmp/pwd.txt #exit from the container exit   Now the environment is ready to start the Oracle WebCenter Portal domain creation.\n6.2 Create an Oracle WebCenter Portal domain   The sample scripts for Oracle WebCenter Portal domain deployment are available at \u0026lt;weblogic-kubernetes-operator-project\u0026gt;/kubernetes/samples/scripts/create-wcp-domain. You must edit create-domain-inputs.yaml (or a copy of it) to provide the details for your domain.\nUpdate create-domain-inputs.yaml with the following values for domain creation:\n rcuDatabaseURL: oracle-db.default.svc.cluster.local:1521/devpdb.k8s    Run the create-domain.sh script to create a domain:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/domain-home-on-pv/ $ ./create-domain.sh -i create-domain-inputs.yaml -o output   Create a Kubernetes domain object:\nOnce the create-domain.sh is successful, it generates output/weblogic-domains/wcp-domain/domain.yaml, which you can use to create the Kubernetes resource domain to start the domain and servers:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/domain-home-on-pv $ kubectl create -f output/weblogic-domains/wcp-domain/domain.yaml   Verify that the Kubernetes domain object named wcp-domain is created:\n$ kubectl get domain -n wcpns NAME AGE wcp-domain 3m18s   Once you create the domain, the introspect pod is created. This inspects the domain home and then starts the wcp-domain-adminserver pod. Once the wcp-domain-adminserver pod starts successfully, the Managed Server pods are started in parallel. Watch the wcpns namespace for the status of domain creation:\n$ kubectl get pods -n wcpns -w   Verify that the Oracle WebCenter Portal domain server pods and services are created and in Ready state:\n$ kubectl get all -n wcpns   6.3 Configure Traefik to access Oracle WebCenter Portal domain services   Configure Traefik to manage ingresses created in the Oracle WebCenter Portal domain namespace (wcpns):\n$ helm upgrade traefik traefik/traefik \\ --reuse-values \\ --namespace traefik \\ --set \u0026quot;kubernetes.namespaces={traefik,wcpns}\u0026quot; \\ --wait   Create an ingress for the domain in the domain namespace by using the sample Helm chart:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator helm install wcp-traefik-ingress \\ kubernetes/samples/charts/ingress-per-domain \\ --namespace wcpns \\ --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\ --set \u0026quot;traefik.hostname=$(hostname -f)\u0026quot;   Verify the created ingress per domain details:\n$ kubectl describe ingress wcp-domain-traefik -n wcpns   6.4 Verify that you can access the Oracle WebCenter Portal domain URL   Get the LOADBALANCER_HOSTNAME for your environment:\nexport LOADBALANCER_HOSTNAME=$(hostname -f)   Verify the following URLs are available for Oracle WebCenter Portal domain.\nCredentials:\nusername: weblogic password: welcome1\nhttp://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenter http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rsscrawl http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rest http://${LOADBALANCER_HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenterhelp   "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/monitoring-and-publishing-logs/",
	"title": "Monitor a domain and publish logs",
	"tags": [],
	"description": "Monitor Oracle WebCenter Portal and publishing logs to Elasticsearch.",
	"content": "  Monitor a WebCenter Portal domain  Monitor an WebCenter Portal instance using Prometheus and Grafana.\n Publish WebLogic Server logs into Elasticsearch  Publish WebLogic Server logs into Elasticsearch.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/configure-load-balancer/nginx/",
	"title": "NGINX",
	"tags": [],
	"description": "Configure the ingress-based NGINX load balancer for an Oracle WebCenter Portal domain.",
	"content": "To load balance Oracle WebCenter Portal domain clusters, you can install the ingress-based NGINX load balancer and configure NGINX for non-SSL, SSL termination, and end-to-end SSL access of the application URL. Follow these steps to set up NGINX as a load balancer for an Oracle WebCenter Portal domain in a Kubernetes cluster:\nSee the official installation document for prerequisites.\n  Non-SSL and SSL termination\n Install the NGINX load balancer Configure NGINX to manage ingresses Verify non-SSL and SSL termination access    End-to-end SSL configuration\n Install the NGINX load balancer for End-to-end SSL Deploy tls to access the services Verify end-to-end SSL access    Non-SSL and SSL termination To get repository information, enter the following Helm commands:\n$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx $ helm repo update Install the NGINX load balancer   Deploy the ingress-nginx controller by using Helm on the domain namespace:\n$ helm install nginx-ingress ingress-nginx/ingress-nginx -n wcpns \\ --set controller.service.type=NodePort \\ --set controller.admissionWebhooks.enabled=false    Click here to see the sample output.    NAME: nginx-ingress LAST DEPLOYED: Tue Jan 12 21:13:54 2021 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export HTTP_NODE_PORT=30305 export HTTPS_NODE_PORT=$(kubectl --namespace wcpns get services -o jsonpath=\u0026quot;{.spec.ports[1].nodePort}\u0026quot; nginx-ingress-ingress-nginx-controller) export NODE_IP=$(kubectl --namespace wcpns get nodes -o jsonpath=\u0026quot;{.items[0].status.addresses[1].address}\u0026quot;) echo \u0026quot;Visit http://$NODE_IP:$HTTP_NODE_PORT to access your application via HTTP.\u0026quot; echo \u0026quot;Visit https://$NODE_IP:$HTTPS_NODE_PORT to access your application via HTTPS.\u0026quot; An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls      Check the status of the deployed ingress controller:\n$ kubectl --namespace wcpns get services | grep ingress-nginx-controller Sample output:\nnginx-ingress-ingress-nginx-controller NodePort 10.101.123.106 \u0026lt;none\u0026gt; 80:30305/TCP,443:31856/TCP 2m12s   Configure NGINX to manage ingresses   Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK, tls is Non-SSL. You can override these values by passing values through the command line or edit them in the sample values.yaml file. If needed, you can update the ingress YAML file to define more path rules (in section spec.rules.host.http.paths) based on the domain application URLs that need to be accessed. Update the template YAML file for the NGINX load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/nginx-ingress.yaml\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcp-nginx-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wcpns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;nginx.hostname=$(hostname -f)\u0026#34; \\  --set type=NGINX Sample output:\nNAME: wcp-nginx-ingress LAST DEPLOYED: Fri Jul 24 09:34:03 2020 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None   For secured access (SSL) to the Oracle WebCenter Portal application, create a certificate and generate a Kubernetes secret:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wcpns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Install ingress-per-domain using Helm for SSL configuration:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcp-nginx-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wcpns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set \u0026#34;nginx.hostname=$(hostname -f)\u0026#34; \\  --set type=NGINX --set tls=SSL   For non-SSL access to the Oracle WebCenter Portal application, get the details of the services by the ingress:\n$ kubectl describe ingress wcp-domain-ingress -n wcpns    Click here to see the sample output of the services supported by the above deployed ingress.    Name: wcp-domain-ingress Namespace: wcpns Address: 10.101.123.106 Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- * /webcenter wcp-domain-cluster-wcp-cluster:8888 (10.244.0.52:8888,10.244.0.53:8888) /console wcp-domain-adminserver:7001 (10.244.0.51:7001) /rsscrawl wcp-domain-cluster-wcp-cluster:8888 (10.244.0.53:8888) /rest wcp-domain-cluster-wcp-cluster:8888 (10.244.0.53:8888) /webcenterhelp wcp-domain-cluster-wcp-cluster:8888 (10.244.0.53:8888) /em wcp-domain-adminserver:7001 (10.244.0.51:7001) Annotations: meta.helm.sh/release-name: wcp-nginx-ingress meta.helm.sh/release-namespace: wcpns nginx.com/sticky-cookie-services: serviceName=wcp-domain-cluster-wcp-cluster srv_id expires=1h path=/; nginx.ingress.kubernetes.io/proxy-connect-timeout: 1800 nginx.ingress.kubernetes.io/proxy-read-timeout: 1800 nginx.ingress.kubernetes.io/proxy-send-timeout: 1800 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Sync 48m (x2 over 48m) nginx-ingress-controller Scheduled for sync      For SSL access to the Oracle WebCenter Portal application, get the details of the services by the above deployed ingress:\n$ kubectl describe ingress wcp-domain-ingress -n wcpns    Click here to see the sample output of the services supported by the above deployed ingress.   Name: wcp-domain-ingress Namespace: wcpns Address: 10.106.220.140 Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) TLS: domain1-tls-cert terminates mydomain.com Rules: Host Path Backends ---- ---- -------- * /webcenter wcp-domain-cluster-wcp-cluster:8888 (10.244.0.43:8888,10.244.0.44:8888) /console wcp-domain-adminserver:7001 (10.244.0.42:7001) /rsscrawl wcp-domain-cluster-wcp-cluster:8888 (10.244.0.43:8888,10.244.0.44:8888) /webcenterhelp wcp-domain-cluster-wcp-cluster:8888 (10.244.0.43:8888,10.244.0.44:8888) /rest wcp-domain-cluster-wcp-cluster:8888 (10.244.0.43:8888,10.244.0.44:8888) /em wcp-domain-adminserver:7001 (10.244.0.42:7001) Annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: wcp-nginx-ingress meta.helm.sh/release-namespace: wcpns nginx.ingress.kubernetes.io/affinity: cookie nginx.ingress.kubernetes.io/affinity-mode: persistent nginx.ingress.kubernetes.io/configuration-snippet: more_set_input_headers \u0026quot;X-Forwarded-Proto: https\u0026quot;; more_set_input_headers \u0026quot;WL-Proxy-SSL: true\u0026quot;; nginx.ingress.kubernetes.io/ingress.allow-http: false nginx.ingress.kubernetes.io/proxy-connect-timeout: 1800 nginx.ingress.kubernetes.io/proxy-read-timeout: 1800 nginx.ingress.kubernetes.io/proxy-send-timeout: 1800 nginx.ingress.kubernetes.io/session-cookie-expires: 172800 nginx.ingress.kubernetes.io/session-cookie-max-age: 172800 nginx.ingress.kubernetes.io/session-cookie-name: stickyid nginx.ingress.kubernetes.io/ssl-redirect: false Events: \u0026lt;none\u0026gt;      Verify non-SSL and SSL termination access Verify that the Oracle WebCenter Portal domain application URLs are accessible through the ngnix NodePort LOADBALANCER-NODEPORT 30305:\nhttp://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-NODEPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-NODEPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-NODEPORT}/webcenter http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-NODEPORT}/rsscrawl http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-NODEPORT}/rest http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-NODEPORT}/webcenterhelp Uninstall the ingress Uninstall and delete the ingress-nginx deployment:\n$ helm delete wcp-nginx-ingress -n wcpns $ helm delete nginx-ingress -n wcpns End-to-end SSL configuration Install the NGINX load balancer for End-to-end SSL   For secured access (SSL) to the Oracle WebCenter Portal application, create a certificate and generate secrets:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=domain1.org\u0026#34; $ kubectl -n wcpns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt  Note: The value of CN is the host on which this ingress is to be deployed.\n   Deploy the ingress-nginx controller by using Helm on the domain namespace:\n$ helm install nginx-ingress -n wcpns \\  --set controller.extraArgs.default-ssl-certificate=wcpns/domain1-tls-cert \\  --set controller.service.type=NodePort \\  --set controller.admissionWebhooks.enabled=false \\  --set controller.extraArgs.enable-ssl-passthrough=true \\  ingress-nginx/ingress-nginx    Click here to see the sample output.   NAME: nginx-ingress LAST DEPLOYED: Tue Sep 15 08:40:47 2020 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The ingress-nginx controller has been installed. Get the application URL by running these commands: export HTTP_NODE_PORT=$(kubectl --namespace wcpns get services -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export HTTPS_NODE_PORT=$(kubectl --namespace wcpns get services -o jsonpath=\u0026#34;{.spec.ports[1].nodePort}\u0026#34; nginx-ingress-ingress-nginx-controller) export NODE_IP=$(kubectl --namespace wcpns get nodes -o jsonpath=\u0026#34;{.items[0].status.addresses[1].address}\u0026#34;) echo \u0026#34;Visit http://$NODE_IP:$HTTP_NODE_PORTto access your application via HTTP.\u0026#34; echo \u0026#34;Visit https://$NODE_IP:$HTTPS_NODE_PORTto access your application via HTTPS.\u0026#34; An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls      Check the status of the deployed ingress controller:\n$ kubectl --namespace wcpns get services | grep ingress-nginx-controller Sample output:\nnginx-ingress-ingress-nginx-controller NodePort 10.96.177.215 \u0026lt;none\u0026gt; 80:32748/TCP,443:31940/TCP 23s   Deploy tls to access services   Deploy tls to securely access the services. Only one application can be configured with ssl-passthrough. A sample tls file for NGINX is shown below for the service wcp-domain-cluster-wcp-cluster and port 8889. All the applications running on port 8889 can be securely accessed through this ingress.\n  For each backend service, create different ingresses, as NGINX does not support multiple paths or rules with annotation ssl-passthrough. For example, for wcp-domain-adminserver and wcp-domain-cluster-wcp-cluster, different ingresses must be created.\n  As ssl-passthrough in NGINX works on the clusterIP of the backing service instead of individual endpoints, you must expose wcp-domain-cluster-wcp-cluster created by the operator with clusterIP.\nFor example:\na. Get the name of wcp-domain cluster service:\n$ kubectl get svc -n wcpns | grep wcp-domain-cluster-wcp-cluster Sample output:\nwcp-domain-cluster-wcp-cluster ClusterIP 10.102.128.124 \u0026lt;none\u0026gt; 8888/TCP,8889/TCP 62m   Deploy the secured ingress:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl create -f nginx-tls.yaml  Note: The default nginx-tls.yaml contains the backend for WebCenter Portal service with domainUID wcp-domain. You need to create similar tls configuration YAML files separately for each backend service.\n   Click here to check the content of the file nginx-tls.yaml    apiVersion: extensions/v1beta1 kind: Ingress metadata: name: wcpns-ingress namespace: wcpns annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: \u0026quot;true\u0026quot; spec: tls: - hosts: - domain1.org secretName: domain1-tls-cert rules: - host: domain1.org http: paths: - path: backend: serviceName: wcp-domain-cluster-wcp-cluster servicePort: 8889     Note: Host is the server on which this ingress is deployed.\n   Check the services supported by the ingress:\n$ kubectl describe ingress wcpns-ingress -n wcpns   Verify end-to-end SSL access Verify that the Oracle WebCenter Portal domain application URLs are accessible through the LOADBALANCER-SSLPORT 30233:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenter https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rsscrawl https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenterhelp https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rest Uninstall ingress-nginx tls $ cd weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl delete -f nginx-tls.yaml $ helm delete nginx-ingress -n wcpns "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/monitoring-and-publishing-logs/publishing-logs/",
	"title": "Publish WebLogic Server logs into Elasticsearch",
	"tags": [],
	"description": "Publish WebLogic Server logs into Elasticsearch.",
	"content": "To publish WebLogic Server logs into Elasticsearch, you can configure your WebCenter Portal domain to use Fluentd or WebLogic Logging Exporter.  Fluentd  Describes how to configure a WebCenter Portal domain to use Fluentd to send log information to Elasticsearch.\n WebLogic logging exporter  Use the WebLogic Logging Exporter to publish the WebLogic Server logs to Elasticsearch.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/weblogic-monitoring-exporter-setup/",
	"title": "Monitor an Oracle WebCenter Content domain",
	"tags": [],
	"description": "Use the WebLogic Monitoring Exporter to monitor an Oracle WebCenter Content instance using Prometheus and Grafana.",
	"content": "You can monitor a WebCenter Content domain using Prometheus and Grafana by exporting the metrics from the domain instance using the WebLogic Monitoring Exporter. This sample shows you how to set up the WebLogic Monitoring Exporter to push the data to Prometheus.\nPrerequisites This document assumes that the Prometheus Operator is deployed on the Kubernetes cluster. If it is not already deployed, follow the steps below for deploying the Prometheus Operator.\nDeploy Prometheus and Grafana Refer to the compatibility matrix of Kube Prometheus and clone the release version of the kube-prometheus repository according to the Kubernetes version of your cluster.\nClone the kube-prometheus project $ git clone https://github.com/coreos/kube-prometheus.git Label the nodes Kube-Prometheus requires all the exporter nodes to be labelled with kubernetes.io/os=linux. If a node is not labelled, then you must label it using the following command:\n$ kubectl label nodes --all kubernetes.io/os=linux Create Prometheus and Grafana resources Change to the kube-prometheus directory and execute the following commands to create the namespace and CRDs:\nNOTE: Wait for a minute for each command to process.\n$ cd kube-prometheus $ kubectl create -f manifests/setup $ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo \u0026#34;\u0026#34;; done $ kubectl create -f manifests/ Provide external access To provide external access for Grafana, Prometheus, and Alertmanager, execute the commands below:\n$ kubectl patch svc grafana -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32100 }]\u0026#39; $ kubectl patch svc prometheus-k8s -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32101 }]\u0026#39; $ kubectl patch svc alertmanager-main -n monitoring --type=json -p \u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/type\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NodePort\u0026#34; },{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/ports/0/nodePort\u0026#34;, \u0026#34;value\u0026#34;: 32102 }]\u0026#39; NOTE:\n 32100 is the external port for Grafana 32101 is the external port for Prometheus 32102 is the external port for Alertmanager   Set Up the WebLogic Monitoring Exporter Set up the WebLogic Monitoring Exporter that will collect WebLogic Server metrics and monitor your Oracle WebCenter Content domain.\nGenerate the WebLogic Monitoring Exporter Deployment Package Two packages are required as the listening ports are different for the Administration Server and Managed Servers. One binary required for the Admin Server (wls-exporter-as.war) and one for Managed Cluster (wls-exporter-ms.war). Set the required proxies and then run the script getX.X.X.sh to generate two binaries:\nDownload WebLogic Monitoring Exporter Download WebLogic Monitoring Exporter package from https://github.com/oracle/weblogic-monitoring-exporter/releases Download wls-exporter.war and getX.X.X.sh\nCreate configuration file for WebLogic Monitoring Exporter In this step we will create the configuration file for WebLogic Monitoring Exporter.The configuration will have the server port for serving the webapp, metrics to be scraped from the WebLogic server etc.\n  Click here to see sample content for config-admin `config-admin.yaml`.   metricsNameSnakeCase: true restPort: 7001 queries: - key: name keyName: location prefix: wls_server_ applicationRuntimes: key: name keyName: app componentRuntimes: prefix: wls_webapp_config_ type: WebAppComponentRuntime key: name values: [deploymentState, contextRoot, sourceInfo, openSessionsHighCount, openSessionsCurrentCount, sessionsOpenedTotalCount, sessionCookieMaxAgeSecs, sessionInvalidationIntervalSecs, sessionTimeoutSecs, singleThreadedServletPoolSize, sessionIDLength, servletReloadCheckSecs, jSPPageCheckSecs] servlets: prefix: wls_servlet_ key: servletName - JVMRuntime: prefix: wls_jvm_ key: name - executeQueueRuntimes: prefix: wls_socketmuxer_ key: name values: [pendingRequestCurrentCount] - workManagerRuntimes: prefix: wls_workmanager_ key: name values: [stuckThreadCount, pendingRequests, completedRequests] - threadPoolRuntime: prefix: wls_threadpool_ key: name values: [executeThreadTotalCount, queueLength, stuckThreadCount, hoggingThreadCount] - JMSRuntime: key: name keyName: jmsruntime prefix: wls_jmsruntime_ JMSServers: prefix: wls_jms_ key: name keyName: jmsserver destinations: prefix: wls_jms_dest_ key: name keyName: destination - persistentStoreRuntimes: prefix: wls_persistentstore_ key: name - JDBCServiceRuntime: JDBCDataSourceRuntimeMBeans: prefix: wls_datasource_ key: name - JTARuntime: prefix: wls_jta_ key: name    In this step we will generate the deployemt package. We have to generate three separate packages with restPort as 7001 16200 and 16250 in config.yaml. The three packages are required as the listening ports for AdminServer, Oracle WebCenter Content server \u0026amp; Oracle WebCenter Inbound Refinery server.\nUse getX.X.X.sh script to update the configuration file into wls-exporter package. Below a sample usage\nSet the required proxies and then run the script getX.X.X.sh\n$ cd kubernetes/samples/scripts/create-wcc-domain/utils/weblogic-monitoring-exporter $ sh get1.2.0.sh config-admin.yaml Output:\n./get1.2.0.sh config-admin.yaml % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 642 100 642 0 0 1186 0 --:--:-- --:--:-- --:--:-- 1184 100 2033k 100 2033k 0 0 846k 0 0:00:02 0:00:02 --:--:-- 1527k created /tmp/ci-6gGPjopn3l /tmp/ci-6gGPjopn3l /\u0026lt;your_path\u0026gt;/prometheus/weblogic_monitor_exporter in temp dir adding: config.yml (deflated 63%) Generate the packages for Managed Servers/clusters with the different configuration file.\nDeploy the WebLogic Monitoring Exporter Follow these steps to deploy the package in the WebLogic Server instances:\n  In the Administration Server and Managed Servers, deploy the WebLogic Monitoring Exporter (wls-exporter.war) separately using the Oracle Enterprise Manager.\n  Select the servers to which the Exporter WAR should be deployed:\n  Set the application name. The application name must be different if it is deployed separately in the Administration Server and Managed Servers. Make sure the context-root for both the deployments is wls-exporter:\n  Click Install and start application.\n  Then deploy the WebLogic Monitoring Exporter application.\n  Activate the changes to start the application. If the application is started and the port is exposed, then you can access the WebLogic Monitoring Exporter console using this URL: http://\u0026lt;server:port\u0026gt;/wls-exporter.\n  Repeat same steps for ucm \u0026amp; ibr servers.\n  Configure Prometheus Operator Prometheus enables you to collect metrics from the WebLogic Monitoring Exporter. The Prometheus Operator identifies the targets using service discovery. To get the WebLogic Monitoring Exporter end point discovered as a target, you must create a service monitor pointing to the service.\nSee the following sample service monitor deployment YAML configuration file located at\nkubernetes/samples/scripts/create-wccontent-domains/utils/weblogic-monitoring-exporter/wls-exporter.yaml.\nServiceMonitor for wls-exporter:\n  Click here to see sample content for wls-exporter.yaml   apiVersion: v1 kind: Secret metadata: name: basic-auth namespace: monitoring data: password: d2VsY29tZTE= # welcome1 i.e.'WebLogic password' user: d2VibG9naWM= # weblogic i.e. 'WebLogic username' type: Opaque --- apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: wls-exporter-wccinfra namespace: monitoring labels: k8s-app: wls-exporter spec: namespaceSelector: matchNames: - wccns selector: matchLabels: weblogic.domainName: wccinfra endpoints: - basicAuth: password: name: basic-auth key: password username: name: basic-auth key: user port: default relabelings: - action: labelmap regex: __meta_kubernetes_service_label_(.+) interval: 10s honorLabels: true path: /wls-exporter/metrics    The exporting of metrics from wls-exporter requires basicAuth so a Kubernetes Secret is created with the user name and password that are base64 encoded. This Secret will be used in the ServiceMonitor deployment.\nWhen generating the base64 encoded strings for the user name and password, observe if a new line character is appended in the encoded string. This line character causes an authentication failure. To avoid a new line string, use the following example:\n$ echo -n \u0026quot;welcome1\u0026quot; | base64 d2VsY29tZTE= In the deployment YAML configuration for wls-exporter shown above, weblogic.domainName: wccinfra is used as a label under spec.selector.matchLabels, so all the services will be selected for the service monitor. If you don\u0026rsquo;t use this label, you should create separate service monitors for each server - if the server name is used as matching labels in spec.selector.matchLabels. Doing so will require you to relabel the configuration because Prometheus, by default, ignores the labels provided in the wls-exporter.\nBy default, Prometheus does not store all the labels provided by the target. In the service monitor deployment YAML configuration, you must mention the relabeling configuration (spec.endpoints.relabelings) so that certain labels provided by weblogic-monitoring-exporter (required for the Grafana dashboard) are stored in Prometheus. Do not delete the following section from the configuration YAML file:\nrelabelings: - action: labelmap regex: __meta_kubernetes_service_label_(.+) Add RoleBinding and Role for the WebLogic Domain Namespace The RoleBinding is required for Prometheus to access the endpoints provided by the WebLogic Monitoring Exporter. You need to add RoleBinding for the namespace under which the WebLogic Servers pods are running in the Kubernetes cluster. Edit the kube-prometheus/manifests/prometheus-roleBindingSpecificNamespaces.yaml file in the Prometheus Operator deployment manifests and add the RoleBinding for the namespace (wccns) similar to the following example:\n- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: prometheus-k8s namespace: wccns roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: prometheus-k8s subjects: - kind: ServiceAccount name: prometheus-k8s namespace: monitoring Similarly, add the Role for the namespace under which the WebLogic Servers pods are running in the Kubernetes cluster. Edit kube-prometheus/manifests/prometheus-roleSpecificNamespaces.yaml in the Prometheus Operator deployment manifests and add the Role for the namespace (wccns) similar to the following example:\n- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: prometheus-k8s namespace: wccns rules: - apiGroups: - \u0026quot;\u0026quot; resources: - services - endpoints - pods verbs: - get - list - watch Then apply prometheus-roleBindingSpecificNamespaces.yaml and prometheus-roleSpecificNamespaces.yaml for the RoleBinding and Role to take effect in the cluster.\n$ kubectl apply -f kube-prometheus/manifests/prometheus-roleBindingSpecificNamespaces.yaml $ kubectl apply -f kube-prometheus/manifests/prometheus-roleSpecificNamespaces.yaml Deploy the Service Monitor To deploy the service monitor, use the above wls-exporter.yaml deployment YAML and run the following command:\n$ cd kubernetes/samples/scripts/create-wccontent-domains/utils/weblogic-monitoring-exporter/ $ kubectl create -f wls-exporter.yaml Enable Prometheus to Discover the Service After the deployment of the service monitor, Prometheus should be able to discover wls-exporter and export metrics.\nYou can access the Prometheus dashboard at http://mycompany.com:32101/.\nDeploy Grafana Dashboard To view the domain metrics, deploy the Grafana dashboard provided in the WebLogic Monitoring Exporter.\nYou can access the Grafana dashboard at http://mycompany.com:32100/.\n  Log in to Grafana dashboard with admin/admin.\n  Go to Settings, then select DataSources, and then Add Data Source.\nHTTP URL: Prometheus URL http://mycompany.com:32101/\nAuth: Enable Basic Auth\nBasic Auth Details: WebLogic credentials provided in step Configure Prometheus Operator\n  Download the weblogic_dashboard.json file from here.\n  Click Add and then Import. Paste the modified JSON in the Paste JSON block, and then load it.\nThis displays the WebLogic Server Dashboard.\n  "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/installguide/prepare-your-environment/",
	"title": "Prepare your environment",
	"tags": [],
	"description": "Prepare for creating the Oracle WebCenter Portal domain, This preparation includes but not limited to creating required secrets, persistent volume and volume claim, and database schema.",
	"content": "Set up the environment, including setting up a Kubernetes cluster and the Weblogic Kubernetes Operator.\n  Install Helm\n  Set Up your Kubernetes Cluster\n  Obtain the Oracle WebCenter Portal Docker Image\n  Pull Other Dependent Images\n  Set Up the Code Repository to Deploy Oracle WebCenter Portal Domain\n  Grant Roles and Clear Stale Resources\n  Install the WebLogic Kubernetes Operator\n  Prepare the Environment for the WebCenter Portal Domain\na. Create a namespace for an Oracle WebCenter Portal domain\nb. Create a Kubernetes secret with domain credentials\nc. Create a Kubernetes secret with the RCU credentials\nd. Create a persistent storage for an Oracle WebCenter Portal domain\ne. Configure access to your database\nf. Run the Repository Creation Utility to set up your database schemas\n  Install Helm The operator uses Helm to create and deploy the necessary resources and then run the operator in a Kubernetes cluster. For Helm installation and usage information, see here.\nSet Up your Kubernetes Cluster If you need help in setting up a Kubernetes environment, check our cheat sheet.\nAfter creating Kubernetes clusters, you can optionally:\n Create load balancers to direct traffic to backend domain Configure Kibana and Elasticsearch for your operator logs  Obtain the Oracle WebCenter Portal Docker Image The Oracle WebCenter Portal image with latest bundle patch and required interim patches can be obtained from My Oracle Support (MOS). This is the only image supported for production deployments. Follow the below steps to download the Oracle WebCenter Portal image from My Oracle Support.\n  Download patch 32688937 from My Oracle Support (MOS).\n  Unzip the downloaded patch zip file.\n  Load the image archive using the docker load command.\nFor example:\n$ docker load \u0026lt; wcportal-12.2.1.4.0-210326.0857.320.tar Loaded image: oracle/wcportal:12.2.1.4.0-210326.0857.320   If you want to build and use an Oracle WebCenter Portal Docker image with any additional bundle patch or interim patches that are not part of the image obtained from My Oracle Support, then follow these steps to create the image.\n Note: The default Oracle WebCenter Portal image name used for Oracle WebCenter Portal domain deployment is oracle/wcportal:12.2.1.4. The image obtained must be tagged as oracle/wcportal:12.2.1.4 using the docker tag command. If you want to use a different name for the image, make sure to update the new image tag name in the create-domain-inputs.yaml file and also in other instances where the oracle/wcportal:12.2.1.4 image name is used.\n Pull Other Dependent Images Dependent images include WebLogic Kubernetes Operator, database, and Traefik. Pull these images and add them to your local registry:\n Pull these docker images and re-tag them as shown:  To pull an image from the Oracle Container Registry, in a web browser, navigate to https://container-registry.oracle.com and log in using the Oracle Single Sign-On authentication service. If you do not already have SSO credentials, at the top of the page, click the Sign In link to create them.\nUse the web interface to accept the Oracle Standard Terms and Restrictions for the Oracle software images that you intend to deploy. Your acceptance of these terms are stored in a database that links the software images to your Oracle Single Sign-On login credentials.\nThen, pull these docker images:\n$ docker login https://container-registry.oracle.com (enter your Oracle email Id and password) #This step is required once at every node to get access to the Oracle Container Registry. WebLogic Kubernetes Operator image:\n$ docker pull ghcr.io/oracle/weblogic-kubernetes-operator:3.1.1 Copy all the built and pulled images to all the nodes in your cluster or add to a Docker registry that your cluster can access.  NOTE: If you\u0026rsquo;re not running Kubernetes on your development machine, you\u0026rsquo;ll need to make the Docker image available to a registry visible to your Kubernetes cluster. Upload your image to a machine running Docker and Kubernetes as follows:\n# on your build machine $ docker save Image_Name:Tag \u0026gt; Image_Name-Tag.tar $ scp Image_Name-Tag.tar YOUR_USER@YOUR_SERVER:/some/path/Image_Name-Tag.tar # on the Kubernetes server $ docker load \u0026lt; /some/path/Image_Name-Tag.tar Set Up the Code Repository to Deploy Oracle WebCenter Portal Domain Oracle WebCenter Portal domain deployment on Kubernetes leverages the WebLogic Kubernetes Operator infrastructure. For deploying the Oracle WebCenter Portal domain, you need to set up the deployment scripts as below:\n  Create a working directory to set up the source code.\n$ export WORKDIR=$HOME/wcp_3.1.1 $ mkdir \u0026lt;WORKDIR\u0026gt; $ cd \u0026lt;WORKDIR\u0026gt;   Download the supported version of WebLogic Kubernetes Operator source code archive file (.zip/.tar.gz) from the operator relases page. You can also download the supported operator version from 3.1.1.\n$ git clone https://github.com/oracle/weblogic-kubernetes-operator.git --branch release/3.1.1   Download the WebCenter Portal Kubernetes deployment scripts from this repository and copy them in to WebLogic operator samples location.\n$ git clone https://github.com/oracle/fmw-kubernetes.git --branch release/21.2.3 $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterPortal/kubernetes/create-wcp-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterPortal/kubernetes/ingress-per-domain ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterPortal/kubernetes/create-wcp-es-cluster ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterPortal/kubernetes/imagetool-scripts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/ $ cp -rf ${WORKDIR}/fmw-kubernetes/OracleWebCenterPortal/kubernetes/charts ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/   You can now use the deployment scripts from \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator to set up the WebCenter Portal domain as described later in this document.\nYour home directory for running all the required scripts:\n$ cd \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator Grant Roles and Clear Stale Resources   To confirm if there is already a WebLogic custom resource definition, execute the following command:\n$ kubectl get crd NAME CREATED AT domains.weblogic.oracle 2020-03-14T12:10:21Z   Delete the WebLogic custom resource definition, if you find any, by executing the following command:\n$ kubectl delete crd domains.weblogic.oracle customresourcedefinition.apiextensions.k8s.io \u0026#34;domains.weblogic.oracle\u0026#34; deleted   Install the WebLogic Kubernetes Operator   Create a namespace for the WebLogic Kubernetes Operator:\n$ kubectl create namespace operator-ns namespace/operator-ns created NOTE: In this procedure, the namespace is called “operator-ns”. You can use any name.\nYou can use:\n domainUID/domainname as wcp-domain Domain namespace as wcpns Operator namespace as operator-ns traefik namespace as traefik    Create a service account for the WebLogic Kubernetes Operator in the operator\u0026rsquo;s namespace:\n$ kubectl create serviceaccount -n operator-ns operator-sa serviceaccount/operator-sa created   To be able to set up the log-stash and Elasticsearch after creating the domain, set the value of the field elkIntegrationEnabled to true in the file kubernetes/charts/weblogic-operator/values.yaml.\n  Use helm to install and start the WebLogic Kubernetes Operator from the downloaded repository:\n Helm install weblogic-operator\n $ helm install weblogic-kubernetes-operator kubernetes/charts/weblogic-operator --namespace operator-ns --set serviceAccount=operator-sa --set \u0026#34;domainNamespaces={}\u0026#34; --wait NAME: weblogic-kubernetes-operator LAST DEPLOYED: Wed Jan 6 01:47:33 2021 NAMESPACE: operator-ns STATUS: deployed REVISION: 1 TEST SUITE: None ``\n  To verify that the operator\u0026rsquo;s pod is running, list the pods in the operator\u0026rsquo;s namespace. You should see one for the WebLogic Kubernetes Operator:\n$ kubectl get pods -n operator-ns NAME READY STATUS RESTARTS AGE weblogic-operator-67df5fddc5-tlc4b 2/2 Running 0 3m15s   Then, check by viewing the Operator pod\u0026rsquo;s log as shown in the following sample log snippet:\n$ kubectl logs -n operator-ns -c weblogic-operator deployments/weblogic-operator Launching Oracle WebLogic Server Kubernetes Operator... Importing keystore /operator/internal-identity/temp/weblogic-operator.jks to /operator/internal-identity/temp/weblogic-operator.p12... Entry for alias weblogic-operator-alias successfully imported. Import command completed: 1 entries successfully imported, 0 entries failed or cancelled Warning: The -srcstorepass option is specified multiple times. All except the last one will be ignored. MAC verified OK % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 4249 0 2394 100 1855 6884 5334 --:--:-- --:--:-- --:--:-- 6899 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 5558 0 3028 100 2530 22704 18970 --:--:-- --:--:-- --:--:-- 22766 OpenJDK 64-Bit Server VM warning: Option MaxRAMFraction was deprecated in version 10.0 and will likely be removed in a future release. VM settings: Max. Heap Size (Estimated): 14.08G Using VM: OpenJDK 64-Bit Server VM {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:53.438+0000\u0026#34;,\u0026#34;thread\u0026#34;:1,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.TuningParametersImpl\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;update\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168593438,\u0026#34;message\u0026#34;:\u0026#34;Reloading tuning parameters from Operator\u0026#39;s config map\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;} {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:53.944+0000\u0026#34;,\u0026#34;thread\u0026#34;:1,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.Main\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;main\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168593944,\u0026#34;message\u0026#34;:\u0026#34;Oracle WebLogic Server Kubernetes Operator, version: 3.0.4, implementation: master.4d4fe0a, build time: 2019-11-15T21:19:56-0500\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;} {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:53.972+0000\u0026#34;,\u0026#34;thread\u0026#34;:11,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.Main\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;begin\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168593972,\u0026#34;message\u0026#34;:\u0026#34;Operator namespace is: operator-ns\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;} {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:54.009+0000\u0026#34;,\u0026#34;thread\u0026#34;:11,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.Main\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;begin\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168594009,\u0026#34;message\u0026#34;:\u0026#34;Operator target namespaces are: operator-ns\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;} {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:54.013+0000\u0026#34;,\u0026#34;thread\u0026#34;:11,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.Main\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;begin\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168594013,\u0026#34;message\u0026#34;:\u0026#34;Operator service account is: operator-sa\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:54.031+0000\u0026#34;,\u0026#34;thread\u0026#34;:11,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.helpers.HealthCheckHelper\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;performK8sVersionCheck\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168594031,\u0026#34;message\u0026#34;:\u0026#34;Verifying Kubernetes minimum version\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:54.286+0000\u0026#34;,\u0026#34;thread\u0026#34;:11,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.helpers.ClientPool\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;getApiClient\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168594286,\u0026#34;message\u0026#34;:\u0026#34;The Kuberenetes Master URL is set to https://10.96.0.1:443\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:54.673+0000\u0026#34;,\u0026#34;thread\u0026#34;:11,\u0026#34;fiber\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.helpers.HealthCheckHelper\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;createAndValidateKubernetesVersion\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168594673,\u0026#34;message\u0026#34;:\u0026#34;Kubernetes version is: v1.13.7\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:55.259+0000\u0026#34;,\u0026#34;thread\u0026#34;:12,\u0026#34;fiber\u0026#34;:\u0026#34;engine-operator-thread-2-fiber-1\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.helpers.CrdHelper$CrdContext$CreateResponseStep\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;onSuccess\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168595259,\u0026#34;message\u0026#34;:\u0026#34;Create Custom Resource Definition: oracle.kubernetes.operator.calls.CallResponse@470b40c\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:55.356+0000\u0026#34;,\u0026#34;thread\u0026#34;:16,\u0026#34;fiber\u0026#34;:\u0026#34;fiber-1-child-2\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.helpers.HealthCheckHelper\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;performSecurityChecks\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168595356,\u0026#34;message\u0026#34;:\u0026#34;Verifying that operator service account can access required operations on required resources in namespace operator-ns\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:55.598+0000\u0026#34;,\u0026#34;thread\u0026#34;:18,\u0026#34;fiber\u0026#34;:\u0026#34;fiber-1-child-2\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.helpers.ConfigMapHelper$ScriptConfigMapContext$CreateResponseStep\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;onSuccess\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168595598,\u0026#34;message\u0026#34;:\u0026#34;Creating domain config map, operator-ns, for namespace: {1}.\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:55.937+0000\u0026#34;,\u0026#34;thread\u0026#34;:21,\u0026#34;fiber\u0026#34;:\u0026#34;fiber-1\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;WARNING\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.utils.Certificates\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;getCertificate\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168595937,\u0026#34;message\u0026#34;:\u0026#34;Can\u0026#39;t read certificate at /operator/external-identity/externalOperatorCert\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\\njava.nio.file.NoSuchFileException: /operator/external-identity/externalOperatorCert\\n\\tat java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)\\n\\tat java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)\\n\\tat java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)\\n\\tat java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:215)\\n\\tat java.base/java.nio.file.Files.newByteChannel(Files.java:370)\\n\\tat java.base/java.nio.file.Files.newByteChannel(Files.java:421)\\n\\tat java.base/java.nio.file.Files.readAllBytes(Files.java:3205)\\n\\tat oracle.kubernetes.operator.utils.Certificates.getCertificate(Certificates.java:48)\\n\\tat oracle.kubernetes.operator.utils.Certificates.getOperatorExternalCertificateData(Certificates.java:39)\\n\\tat oracle.kubernetes.operator.rest.RestConfigImpl.getOperatorExternalCertificateData(RestConfigImpl.java:52)\\n\\tat oracle.kubernetes.operator.rest.RestServer.isExternalSslConfigured(RestServer.java:383)\\n\\tat oracle.kubernetes.operator.rest.RestServer.start(RestServer.java:199)\\n\\tat oracle.kubernetes.operator.Main.startRestServer(Main.java:353)\\n\\tat oracle.kubernetes.operator.Main.completeBegin(Main.java:198)\\n\\tat oracle.kubernetes.operator.Main$NullCompletionCallback.onCompletion(Main.java:701)\\n\\tat oracle.kubernetes.operator.work.Fiber.completionCheck(Fiber.java:475)\\n\\tat oracle.kubernetes.operator.work.Fiber.run(Fiber.java:448)\\n\\tat oracle.kubernetes.operator.work.ThreadLocalContainerResolver.lambda$wrapExecutor$0(ThreadLocalContainerResolver.java:87)\\n\\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\\n\\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\\n\\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:834)\\n\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;} {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:55.967+0000\u0026#34;,\u0026#34;thread\u0026#34;:21,\u0026#34;fiber\u0026#34;:\u0026#34;fiber-1\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.rest.RestServer\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;start\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168595967,\u0026#34;message\u0026#34;:\u0026#34;Did not start the external ssl REST server because external ssl has not been configured.\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;} {\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:57.910+0000\u0026#34;,\u0026#34;thread\u0026#34;:21,\u0026#34;fiber\u0026#34;:\u0026#34;fiber-1\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.rest.RestServer\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;start\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168597910,\u0026#34;message\u0026#34;:\u0026#34;Started the internal ssl REST server on https://0.0.0.0:8082/operator\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}\t{\u0026#34;timestamp\u0026#34;:\u0026#34;03-14-2020T06:49:57.913+0000\u0026#34;,\u0026#34;thread\u0026#34;:21,\u0026#34;fiber\u0026#34;:\u0026#34;fiber-1\u0026#34;,\u0026#34;domainUID\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;class\u0026#34;:\u0026#34;oracle.kubernetes.operator.Main\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;markReadyAndStartLivenessThread\u0026#34;,\u0026#34;timeInMillis\u0026#34;:1584168597913,\u0026#34;message\u0026#34;:\u0026#34;Starting Operator Liveness Thread\u0026#34;,\u0026#34;exception\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;headers\u0026#34;:{},\u0026#34;body\u0026#34;:\u0026#34;\u0026#34;}   Prepare the Environment for the WebCenter Portal Domain Create a namespace for an Oracle WebCenter Portal domain Unless you want to use the default namespace, create a Kubernetes namespace that can host one or more domains:\n$ kubectl create namespace wcpns namespace/wcpns created To manage domain in this namespace, configure the operator using helm:\n Helm upgrade weblogic-operator\n $ helm upgrade --reuse-values --set \u0026#34;domainNamespaces={wcpns}\u0026#34; \\  --wait weblogic-kubernetes-operator kubernetes/charts/weblogic-operator --namespace operator-ns NAME: weblogic-kubernetes-operator LAST DEPLOYED: Wed Jan 6 01:52:58 2021 NAMESPACE: operator-ns STATUS: deployed REVISION: 2 Create a Kubernetes secret with domain credentials Using the create-weblogic-credentials script, create a Kubernetes secret that contains the user name and password for the domain in the same Kubernetes namespace as the domain:\n$ sh kubernetes/samples/scripts/create-weblogic-domain-credentials/create-weblogic-credentials.sh \\  -u weblogic -p welcome1 -n wcpns \\  -d wcp-domain -s wcpinfra-domain-credentials secret/wcpinfra-domain-credentials created secret/wcpinfra-domain-credentials labeled The secret wcpinfra-domain-credentials has been successfully created in the wcpns namespace. Where: * weblogic is the weblogic username * welcome1 is the weblogic password * wcp-domain is the domain name * wcpns is the domain namespace * wcpinfra-domain-credentials is the secret name Note: You can inspect the credentials as follows:  $ kubectl get secret wcpinfra-domain-credentials -o yaml -n wcpns Create a Kubernetes secret with the RCU credentials Create a Kubernetes secret for the Repository Configuration Utility (user name and password) using the create-rcu-credentials.sh script in the same Kubernetes namespace as the domain:\n$ sh kubernetes/samples/scripts/create-rcu-credentials/create-rcu-credentials.sh \\  -u WCP1 -p welcome1 -a sys -q Oradoc_db1 -n wcpns \\  -d wcp-domain -s wcpinfra-rcu-credentials secret/wcpinfra-rcu-credentials created secret/wcpinfra-rcu-credentials labeled The secret wcpinfra-rcu-credentials has been successfully created in the wcpns namespace. Where: * WCP1 is the schema user * welcome1 is the schema password * Oradoc_db1 is the database SYS users password * wcp-domain is the domain name * wcpns is the domain namespace * wcpinfra-rcu-credentials is the secret name Note: You can inspect the credentials as follows:  $ kubectl get secret wcpinfra-rcu-credentials -o yaml -n wcpns Create a persistent storage for an Oracle WebCenter Portal domain Create a Kubernetes PV and PVC (Persistent Volume and Persistent Volume Claim):\nIn the Kubernetes namespace you created, create the PV and PVC for the domain by running the create-pv-pvc.sh script. Follow the instructions for using the script to create a dedicated PV and PVC for the Oracle WebCenter Portal domain.\n  Review the configuration parameters for PV creation here. Based on your requirements, update the values in the create-pv-pvc-inputs.yaml file located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc/. Sample configuration parameter values for an Oracle WebCenter Portal domain are:\n baseName: domain domainUID: wcp-domain namespace: wcpns weblogicDomainStorageType: HOST_PATH weblogicDomainStoragePath: /scratch/kubevolume    Ensure that the path for the weblogicDomainStoragePath property exists (create one if it doesn\u0026rsquo;t exist), that it has full access permissions, and that the folder is empty.\n  Run the create-pv-pvc.sh script:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-weblogic-domain-pv-pvc $ ./create-pv-pvc.sh -i create-pv-pvc-inputs.yaml -o output Input parameters being used export version=\u0026#34;create-weblogic-sample-domain-pv-pvc-inputs-v1\u0026#34; export baseName=\u0026#34;domain\u0026#34; export domainUID=\u0026#34;wcp-domain\u0026#34; export namespace=\u0026#34;wcpns\u0026#34; export weblogicDomainStorageType=\u0026#34;HOST_PATH\u0026#34; export weblogicDomainStoragePath=\u0026#34;/scratch/kubevolume\u0026#34; export weblogicDomainStorageReclaimPolicy=\u0026#34;Retain\u0026#34; export weblogicDomainStorageSize=\u0026#34;10Gi\u0026#34; Generating output/pv-pvcs/wcp-domain-domain-pv.yaml Generating output/pv-pvcs/wcp-domain-domain-pvc.yaml The following files were generated: output/pv-pvcs/wcp-domain-domain-pv.yaml output/pv-pvcs/wcp-domain-domain-pvc.yaml   The create-pv-pvc.sh script creates a subdirectory pv-pvcs under the given /path/to/output-directory directory and creates two YAML configuration files for PV and PVC. Apply these two YAML files to create the PV and PVC Kubernetes resources using the kubectl create -f command:\n$ kubectl create -f output/pv-pvcs/wcp-domain-domain-pv.yaml $ kubectl create -f output/pv-pvcs/wcp-domain-domain-pvc.yaml   Configure access to your database Oracle WebCenter Portal domain requires a database which is configured with the necessary schemas. The Repository Creation Utility (RCU) allows you to create those schemas. You must set up the database before you create your domain.\nFor production deployments, you must set up and use a standalone (non-container) database running outside of Kubernetes.\nBefore creating a domain, you need to set up the necessary schemas in your database.\nRun the Repository Creation Utility to set up your database schemas Run a container to create Repository Creation Utility.\n$ kubectl run rcu --generator=run-pod/v1 --image oracle/wcportal:12.2.1.4 -n wcpns -- sleep infinity #check the status of rcu pod $ kubectl get pods -n wcpns #make sure rcu pod status is running before executing this $ kubectl exec -n wcpns -ti rcu /bin/bash export CONNECTION_STRING=databasehostname:\u0026lt;port\u0026gt;/\u0026lt;servicename\u0026gt; export RCUPREFIX=WCP1 echo -e \u0026lt;Sys_User_Password\u0026gt;\u0026#34;\\n\u0026#34;\u0026lt;Schema_User_Password\u0026gt; \u0026gt; /tmp/pwd.txt /u01/oracle/oracle_common/bin/rcu -silent -dropRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component OPSS -component IAU_VIEWER -component WEBCENTER -component MDS -component IAU_APPEND -component STB -component IAU -component WLS -component ACTIVITIES -f \u0026lt; /tmp/pwd.txt /u01/oracle/oracle_common/bin/rcu -silent -createRepository -databaseType ORACLE -connectString $CONNECTION_STRING -dbUser sys -dbRole sysdba -useSamePasswordForAllSchemaUsers true -selectDependentsForComponents true -schemaPrefix $RCUPREFIX -component OPSS -component IAU_VIEWER -component WEBCENTER -component MDS -component IAU_APPEND -component STB -component IAU -component WLS -component ACTIVITIES -tablespace USERS -tempTablespace TEMP -f \u0026lt; /tmp/pwd.txt #exit from the container exit "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/patch_and_upgrade/upgrade-operator-release/",
	"title": "Upgrade an operator release",
	"tags": [],
	"description": "Upgrade the WebLogic Kubernetes operator release to a newer version.",
	"content": "These instructions apply to upgrading operators within the 3.x release family as additional versions are released.\nTo upgrade the Kubernetes operator, use the helm upgrade command. Make sure that the weblogic-kubernetes-operator repository on your local machine is at the operator release to which you are upgrading. When upgrading the operator, the helm upgrade command requires that you supply a new Helm chart and image. For example:\n$ helm upgrade \\ --reuse-values \\ --set image=oracle/weblogic-kubernetes-operator:3.1.1 \\ --namespace weblogic-operator-namespace \\ --wait \\ weblogic-kubernetes-operator \\ kubernetes/charts/weblogic-operator "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/monitoring-and-publishing-logs/publishing-logs/weblogiclogging/",
	"title": "WebLogic logging exporter",
	"tags": [],
	"description": "Use the WebLogic Logging Exporter to publish the WebLogic Server logs to Elasticsearch.",
	"content": "The WebLogic Logging Exporter adds a log event handler to WebLogic Server which enables WebLogic Server to push the logs to Elasticsearch in Kubernetes by using the Elasticsearch REST API. For more details, see to the WebLogic Logging Exporter project.\nThis sample shows you how to publish WebLogic Server logs to Elasticsearch and view them in Kibana. For publishing operator logs, see this sample.\nPrerequisites This document assumes that you have already set up Elasticsearch and Kibana for logs collection. If you have not, please see this document.\n Download the WebLogic Logging Exporter binaries The pre-built binaries are available on the WebLogic Logging Exporter Releases page.\nDownload:\n weblogic-logging-exporter-1.0.0.jar from the release page snakeyaml-1.25.jar from Maven Central  These identifiers are used in the sample commands.\n wcpns: WebCenter Portal domain namespace wcp-domain: domainUID wcp-domain-adminserver: Administration Server pod name   Copy the JAR Files to the WebLogic Domain Home Copy the weblogic-logging-exporter-1.0.0.jar and snakeyaml-1.25.jar files to the domain home directory in the Administration Server pod.\n$ kubectl cp \u0026lt;file-to-copy\u0026gt; \u0026lt;namespace\u0026gt;/\u0026lt;Administration-Server-pod\u0026gt;:\u0026lt;domainhome\u0026gt; $ kubectl cp snakeyaml-1.25.jar wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/ $ kubectl cp weblogic-logging-exporter-1.0.0.jar wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/ Add a Startup Class to the Domain Configuration   In the WebLogic Server Administration Console, in the left navigation pane, expand Environment, and then select Startup and Shutdown Classes.\n  Add a new startup class. You may choose any descriptive name, however, the class name must be weblogic.logging.exporter.Startup.\n  Target the startup class to each server from which you want to export logs.\n  In your config.xml file located at, /u01/oracle/user_projects/domains/wcp-domain/config/config.xml the newly added startup-class must exist as shown below:\n$ kubectl exec -it wcp-domain-adminserver -n wcpns cat /u01/oracle/user_projects/domains/wcp-domain/config/config.xml \u0026lt;startup-class\u0026gt; \u0026lt;name\u0026gt;weblogic-logging-exporter\u0026lt;/name\u0026gt; \u0026lt;target\u0026gt;AdminServer,wcp_cluster\u0026lt;/target\u0026gt; \u0026lt;class-name\u0026gt;weblogic.logging.exporter.Startup\u0026lt;/class-name\u0026gt; \u0026lt;/startup-class\u0026gt;   Update the WebLogic Server CLASSPATH  Copy the setDomainEnv.sh file from the pod to a local folder:  $ kubectl cp wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/bin/setDomainEnv.sh $PWD/setDomainEnv.sh tar: Removing leading `/\u0026#39; from member names Ignore exception: tar: Removing leading '/' from member names\n Update the server class path in setDomainEnv.sh:  CLASSPATH=/u01/oracle/user_projects/domains/wcp-domain/weblogic-logging-exporter-1.0.0.jar:/u01/oracle/user_projects/domains/wcp-domain/snakeyaml-1.25.jar:${CLASSPATH} export CLASSPATH  Copy back the modified setDomainEnv.sh file to the pod:  $ kubectl cp setDomainEnv.sh wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/bin/setDomainEnv.sh Create a Configuration File for the WebLogic Logging Exporter   Specify the Elasticsearch server host and port number in the file: \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-logging-exporter/WebLogicLoggingExporter.yaml\nExample:\nweblogicLoggingIndexName: wls publishHost: elasticsearch.default.svc.cluster.local publishPort: 9300 domainUID: wcp-domain weblogicLoggingExporterEnabled: true weblogicLoggingExporterSeverity: TRACE weblogicLoggingExporterBulkSize: 1   Copy the WebLogicLoggingExporter.yaml file to the domain home directory in the WebLogic Administration Server pod:\n  $ kubectl cp \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/utils/weblogic-logging-exporter/WebLogicLoggingExporter.yaml wcpns/wcp-domain-adminserver:/u01/oracle/user_projects/domains/wcp-domain/config/ Edit the WebCenter Portal ingress (Only for Voyager Loadbalancer) By default, paths for wls-exporter are commented in the ingress template. In order to expose the wls-exporter end-point externally, you must edit the WebCenter Portal ingress reapply them if necessary. (See Using Voyager Loadbalacer)\nRestart the Servers in the Domain To restart the servers, stop and then start them using the following commands:\nTo stop the servers:\n$ kubectl patch domain wcp-domain -n wcpns --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/serverStartPolicy\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NEVER\u0026#34; }]\u0026#39; To start the servers:\n$ kubectl patch domain wcp-domain -n wcpns --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/serverStartPolicy\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;IF_NEEDED\u0026#34; }]\u0026#39; After all the servers are restarted, see their server logs to check that the weblogic-logging-exporter class is called, as shown below:\n======================= WebLogic Logging Exporter Startup class called Reading configuration from file name: /u01/oracle/user_projects/domains/wcp-domain/config/WebLogicLoggingExporter.yaml Config{weblogicLoggingIndexName='wls', publishHost='domain.host.com', publishPort=9200, weblogicLoggingExporterSeverity='Notice', weblogicLoggingExporterBulkSize='2', enabled=true, weblogicLoggingExporterFilters=FilterConfig{expression='NOT(MSGID = 'BEA-000449')', servers=[]}], domainUID='wcp-domain'} Create an Index Pattern in Kibana Create an index pattern wls* in Kibana by navigating to the dashboard through the Management option. After the servers are started, the log data is displayed on the Kibana dashboard:\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/",
	"title": "Administration Guide",
	"tags": [],
	"description": "Describes how to use some of the common utility tools and configurations to administer Oracle WebCenter Content domains.",
	"content": "Administer Oracle WebCenter Content domains in Kubernetes.\n Set up a load balancer  Configure different load balancers for Oracle WebCenter Content domains.\n Monitor an Oracle WebCenter Content domain  Use the WebLogic Monitoring Exporter to monitor an Oracle WebCenter Content instance using Prometheus and Grafana.\n Elasticsearch integration for logs  Monitor an Oracle WebCenter Sites domain and publish the WebLogic Server logs to Elasticsearch.\n Publish logs to Elasticsearch  Use the WebLogic Logging Exporter to publish the WebLogic Server logs to Elasticsearch.\n Publish logs to Elasticsearch Using Fluentd  Configure a WebLogic domain to use Fluentd to send log information to Elasticsearch.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/installguide/create-wccontent-domains/",
	"title": "Create Oracle WebCenter Content domain",
	"tags": [],
	"description": "Create Oracle WebCenter Content domain home on an existing PV or PVC and create the domain resource YAML file for deploying the generated Oracle WebCenter Content domain.",
	"content": "The WebCenter Content deployment scripts demonstrate the creation of Oracle WebCenter Content domain home on an existing Kubernetes persistent volume (PV) and persistent volume claim (PVC). The scripts also generate the domain YAML file, which can then be used to start the Kubernetes artifacts of the corresponding domain.\nPrerequisites Before you begin, complete the following steps:\n Review the Domain resource documentation. Review the requirements and limitations. Ensure that you have executed all the preliminary steps in Prepare your environment. Ensure that the database schemas were created and the WebLogic Kubernetes operator are running.  Prepare to use the create domain script The sample scripts for Oracle WebCenter Content domain deployment are available at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain.\nYou must edit create-domain-inputs.yaml (or a copy of it) located under ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domian-home-on-pv to provide the details for your domain. Refer to the configuration parameters below to understand the information that you must provide in this file.\nConfiguration parameters The following parameters can be provided in the inputs file.\n   Parameter Definition Default     sslEnabled Boolean indicating whether to enable SSL for each WebLogic Server instance. false   adminPort Port number for the Administration Server inside the Kubernetes cluster. 7001   adminServerSSLPort SSL port number of the Administration Server inside the Kubernetes cluster. 7002   adminNodePort Port number of the Administration Server outside the Kubernetes cluster. 30701   adminServerName Name of the Administration Server. AdminServer   clusterName Name of the WebLogic cluster instance to generate for the domain. By default the cluster name is ucm_cluster \u0026amp; ibr_cluster for the WebCenter Content domain. ucm_cluster   configuredManagedServerCount Number of Managed Server instances to generate for the domain. 5   createDomainFilesDir Directory on the host machine to locate all the files to create a WebLogic domain, including the script that is specified in the createDomainScriptName property. By default, this directory is set to the relative path wlst, and the create script will use the built-in WLST offline scripts in the wlst directory to create the WebLogic domain. An absolute path is also supported to point to an arbitrary directory in the file system. The built-in scripts can be replaced by the user-provided scripts as long as those files are in the specified directory. Files in this directory are put into a Kubernetes config map, which in turn is mounted to the createDomainScriptsMountPath, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. wlst   createDomainScriptsMountPath Mount path where the create domain scripts are located inside a pod. The create-domain.sh script creates a Kubernetes job to run the script (specified in the createDomainScriptName property) in a Kubernetes pod to create a domain home. Files in the createDomainFilesDir directory are mounted to this location in the pod, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. /u01/weblogic   createDomainScriptName Script that the create domain script uses to create a WebLogic domain. The create-domain.sh script creates a Kubernetes job to run this script to create a domain home. The script is located in the in-pod directory that is specified in the createDomainScriptsMountPath property. If you need to provide your own scripts to create the domain home, instead of using the built-it scripts, you must use this property to set the name of the script that you want the create domain job to run. create-domain-job.sh   domainHome Home directory of the WebCenter Content domain. If not specified, the value is derived from the domainUID as /shared/domains/\u0026lt;domainUID\u0026gt;. /u01/oracle/user_projects/domains/wccinfra   domainPVMountPath Mount path of the domain persistent volume. /u01/oracle/user_projects   domainUID Unique ID that will be used to identify this particular domain. Used as the name of the generated WebLogic domain as well as the name of the Kubernetes domain resource. This ID must be unique across all domains in a Kubernetes cluster. This ID cannot contain any character that is not valid in a Kubernetes service name. wccinfra   exposeAdminNodePort Boolean indicating if the Administration Server is exposed outside of the Kubernetes cluster. false   exposeAdminT3Channel Boolean indicating if the T3 administrative channel is exposed outside the Kubernetes cluster. false   image WebCenter Content Docker image. The operator requires Oracle WebCenter Content 12.2.1.4.0 Refer to Obtain the Oracle WebCenter Content Docker image for details on how to obtain or create the image. oracle/wccontent:12.2.1.4.0   imagePullPolicy WebLogic Docker image pull policy. Legal values are IfNotPresent, Always, or Never. IfNotPresent   imagePullSecretName Name of the Kubernetes secret to access the Docker Store to pull the WebLogic Server Docker image. The presence of the secret will be validated when this parameter is specified.    includeServerOutInPodLog Boolean indicating whether to include the server .out to the pod\u0026rsquo;s stdout. true   initialManagedServerReplicas Number of Managed Servers to initially start for the domain. 3   javaOptions Java options for starting the Administration Server and Managed Servers. A Java option can have references to one or more of the following pre-defined variables to obtain WebLogic domain information: $(DOMAIN_NAME), $(DOMAIN_HOME), $(ADMIN_NAME), $(ADMIN_PORT), and $(SERVER_NAME). If sslEnabled is set to true and the WebLogic demo certificate is used, add -Dweblogic.security.SSL.ignoreHostnameVerification=true to allow the Managed Servers to connect to the Administration Server while booting up. The WebLogic generated demo certificate in this environment typically contains a host name that is different from the runtime container\u0026rsquo;s host name. -Dweblogic.StdoutDebugEnabled=false   logHome The in-pod location for the domain log, server logs, server out, and Node Manager log files. If not specified, the value is derived from the domainUID as /shared/logs/\u0026lt;domainUID\u0026gt;. /u01/oracle/user_projects/domains/logs/wccinfra   managedServerNameBase Base string used to generate Managed Server names. ucm_server   managedServerPort Port number for each Managed Server. By default the managedServerPort is 16200 for the ucm_server \u0026amp; managedServerPort is 16250 for the ibr_server. 16200   managedServerSSLPort SSL port number for each Managed Server. By default the managedServerSSLPort is 16201 for the ucm_server \u0026amp; managedServerSSLPort is 16251 for the ibr_server. 16201   namespace Kubernetes namespace in which to create the domain. wccns   persistentVolumeClaimName Name of the persistent volume claim created to host the domain home. If not specified, the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-sample-pvc. wccinfra-domain-pvc   productionModeEnabled Boolean indicating if production mode is enabled for the domain. true   serverStartPolicy Determines which WebLogic Server instances will be started. Legal values are NEVER, IF_NEEDED, ADMIN_ONLY. IF_NEEDED   t3ChannelPort Port for the t3 channel of the NetworkAccessPoint. 30012   t3PublicAddress Public address for the T3 channel. This should be set to the public address of the Kubernetes cluster. This would typically be a load balancer address. For development environments only: In a single server (all-in-one) Kubernetes deployment, this may be set to the address of the master, or at the very least, it must be set to the address of one of the worker nodes. If not provided, the script will attempt to set it to the IP address of the Kubernetes cluster   weblogicCredentialsSecretName Name of the Kubernetes secret for the Administration Server\u0026rsquo;s user name and password. If not specified, then the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-credentials. wccinfra-domain-credentials   weblogicImagePullSecretName Name of the Kubernetes secret for the Docker Store, used to pull the WebLogic Server image.    serverPodCpuRequest, serverPodMemoryRequest, serverPodCpuCLimit, serverPodMemoryLimit The maximum amount of compute resources allowed, and minimum amount of compute resources required, for each server pod. Please refer to the Kubernetes documentation on Managing Compute Resources for Containers for details. Resource requests and resource limits are not specified.   rcuSchemaPrefix The schema prefix to use in the database, for example WCC1. You may wish to make this the same as the domainUID in order to simplify matching domains to their RCU schemas. WCC1   rcuDatabaseURL The database URL. \u0026lt;YOUR DATABASE CONNECTION DETAILS\u0026gt;   rcuCredentialsSecret The Kubernetes secret containing the database credentials. wccinfra-rcu-credentials    Note that the names of the Kubernetes resources in the generated YAML files may be formed with the value of some of the properties specified in the create-inputs.yaml file. Those properties include the adminServerName, clusterName and managedServerNameBase. If those values contain any characters that are invalid in a Kubernetes service name, those characters are converted to valid values in the generated YAML files. For example, an uppercase letter is converted to a lowercase letter and an underscore (\u0026quot;_\u0026quot;) is converted to a hyphen (\u0026quot;-\u0026quot;).\nThe sample demonstrates how to create the Oracle WebCenter Content domain home and associated Kubernetes resources for that domain. In addition, the sample provides the capability for users to supply their own scripts to create the domain home for other use cases. The generated domain YAML file could also be modified to cover more use cases.\nRun the create domain script Run the create domain script, specifying your inputs file and an output directory to store the generated artifacts:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./create-domain.sh \\ -i create-domain-inputs.yaml \\ -o \u0026lt;path to output-directory\u0026gt; The script will perform the following steps:\n  Create a directory for the generated Kubernetes YAML files for this domain if it does not already exist. The path name is \u0026lt;path to output-directory\u0026gt;/weblogic-domains/\u0026lt;domainUID\u0026gt;. If the directory already exists, its contents must be removed before using this script.\n  Create a Kubernetes job that will start up a utility Oracle WebCenter Content container and run offline WLST scripts to create the domain on the shared storage.\n  Run and wait for the job to finish.\n  Create a Kubernetes domain YAML file, domain.yaml, in the \u0026ldquo;output\u0026rdquo; directory that was created above. This YAML file can be used to create the Kubernetes resource using the kubectl create -f or kubectl apply -f command.\n  Run managed-server-wrapper script, which intrenally applies the domain YAML. This script also applies initial configurations for Managed Server containers and readies Managed Servers for future inter-container communications.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcc-domain/domain-home-on-pv/ $ ./start-managed-servers-wrapper.sh -p \u0026lt;load_balancer_port\u0026gt;   Create a convenient utility script, delete-domain-job.yaml, to clean up the domain home created by the create script.\n  The default domain created by the script has the following characteristics:\n An Administration Server named AdminServer listening on port 7001. A configured cluster named ucm_cluster of size 3. A configured cluster named ibr_cluster of size 1. Managed Servers, named ucm_cluster listening on port 16200. Managed Servers, named ibr_cluster listening on port 16250. Log files that are located in /shared/logs/\u0026lt;domainUID\u0026gt;.  Verify the results The create domain script will verify that the domain was created, and will report failure if there was any error. However, it may be desirable to manually verify the domain, even if just to gain familiarity with the various Kubernetes objects that were created by the script.\nGenerated YAML files with the default inputs   Click here to see sample content of the generated `domain.yaml`.   $ cat output/weblogic-domains/wccinfra/domain.yaml # Copyright (c) 2021, Oracle and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # apiVersion: \u0026quot;weblogic.oracle/v8\u0026quot; kind: Domain metadata: name: wccinfra namespace: wccns labels: weblogic.domainUID: wccinfra spec: # The WebLogic Domain Home domainHome: /u01/oracle/user_projects/domains/wccinfra maxClusterConcurrentStartup: 1 # The domain home source type # Set to PersistentVolume for domain-in-pv, Image for domain-in-image, or FromModel for model-in-image domainHomeSourceType: PersistentVolume # The WebLogic Server Docker image that the Operator uses to start the domain image: \u0026quot;oracle/wccontent:12.2.1.4.0\u0026quot; # imagePullPolicy defaults to \u0026quot;Always\u0026quot; if image version is :latest imagePullPolicy: \u0026quot;IfNotPresent\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: # Identify which Secret contains the WebLogic Admin credentials (note that there is an example of # how to create that Secret at the end of this file) webLogicCredentialsSecret: name: wccinfra-domain-credentials # Whether to include the server out file into the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable log home logHomeEnabled: true # Whether to write HTTP access log file to log home httpAccessLogInLogHome: true # The in-pod location for domain log, server logs, server out, and Node Manager log files logHome: /u01/oracle/user_projects/domains/logs/wccinfra # An (optional) in-pod location for data storage of default and custom file stores. # If not specified or the value is either not set or empty (e.g. dataHome: \u0026quot;\u0026quot;) then the # data storage directories are determined from the WebLogic domain home configuration. dataHome: \u0026quot;\u0026quot; # serverStartPolicy legal values are \u0026quot;NEVER\u0026quot;, \u0026quot;IF_NEEDED\u0026quot;, or \u0026quot;ADMIN_ONLY\u0026quot; # This determines which WebLogic Servers the Operator will start up when it discovers this Domain # - \u0026quot;NEVER\u0026quot; will not start any server in the domain # - \u0026quot;ADMIN_ONLY\u0026quot; will start up only the administration server (no managed servers will be started) # - \u0026quot;IF_NEEDED\u0026quot; will start all non-clustered servers, including the administration server and clustered servers up to the replica count serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; serverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026quot;-Dweblogic.StdoutDebugEnabled=false\u0026quot; - name: USER_MEM_ARGS value: \u0026quot;-Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx512m \u0026quot; volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume # adminServer is used to configure the desired behavior for starting the administration server. adminServer: # serverStartState legal values are \u0026quot;RUNNING\u0026quot; or \u0026quot;ADMIN\u0026quot; # \u0026quot;RUNNING\u0026quot; means the listed server will be started up to \u0026quot;RUNNING\u0026quot; mode # \u0026quot;ADMIN\u0026quot; means the listed server will be start up to \u0026quot;ADMIN\u0026quot; mode serverStartState: \u0026quot;RUNNING\u0026quot; adminService: channels: # The Admin Server's NodePort - channelName: default nodePort: 30701 # Uncomment to export the T3Channel as a service # - channelName: T3Channel # clusters is used to configure the desired behavior for starting member servers of a cluster. # If you use this entry, then the rules will be applied to ALL servers that are members of the named clusters. clusters: - clusterName: ibr_cluster serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 1 serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; # The number of managed servers to start for unlisted clusters # replicas: 1 # Istio # configuration: # istio: # enabled: # readinessPort: - clusterName: ucm_cluster serverService: precreateService: true serverStartState: \u0026quot;RUNNING\u0026quot; serverPod: # Instructs Kubernetes scheduler to prefer nodes for new cluster members where there are not # already members of the same cluster. affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: \u0026quot;weblogic.clusterName\u0026quot; operator: In values: - $(CLUSTER_NAME) topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; replicas: 3 serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; # The number of managed servers to start for unlisted clusters # replicas: 1    Verify the domain To confirm that the domain was created, enter the following command:\n$ kubectl describe domain DOMAINUID -n NAMESPACE Replace DOMAINUID with the domainUID and NAMESPACE with the actual namespace.\n  Click here to see a sample domain description.   $ kubectl describe domain wccinfra -n wccns Name: wccinfra Namespace: wccns Labels: weblogic.domainUID=wccinfra Annotations: API Version: weblogic.oracle/v8 Kind: Domain Metadata: Creation Timestamp: 2020-11-23T12:48:13Z Generation: 7 Managed Fields: API Version: weblogic.oracle/v8 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:kubectl.kubernetes.io/last-applied-configuration: f:labels: .: f:weblogic.domainUID: Manager: kubectl Operation: Update Time: 2020-11-23T13:50:28Z API Version: weblogic.oracle/v8 Fields Type: FieldsV1 fieldsV1: f:status: .: f:clusters: f:conditions: f:servers: f:startTime: Manager: OpenAPI-Generator Operation: Update Time: 2020-12-03T10:20:52Z Resource Version: 18267402 Self Link: /apis/weblogic.oracle/v8/namespaces/wccns/domains/wccinfra UID: 1a866c30-9b29-4281-bd2b-df80914efdff Spec: Admin Server: Admin Service: Channels: Channel Name: default Node Port: 30701 Server Start State: RUNNING Clusters: Cluster Name: ibr_cluster Replicas: 1 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start Policy: IF_NEEDED Server Start State: RUNNING Cluster Name: ucm_cluster Replicas: 2 Server Pod: Affinity: Pod Anti Affinity: Preferred During Scheduling Ignored During Execution: Pod Affinity Term: Label Selector: Match Expressions: Key: weblogic.clusterName Operator: In Values: $(CLUSTER_NAME) Topology Key: kubernetes.io/hostname Weight: 100 Server Service: Precreate Service: true Server Start Policy: IF_NEEDED Server Start State: RUNNING Data Home: Domain Home: /u01/oracle/user_projects/domains/wccinfra Domain Home Source Type: PersistentVolume Http Access Log In Log Home: true Image: oracle/wccontent_ora_final_it:12.2.1.4.0 Image Pull Policy: IfNotPresent Include Server Out In Pod Log: true Log Home: /u01/oracle/user_projects/domains/logs/wccinfra Log Home Enabled: true Max Cluster Concurrent Startup: 1 Server Pod: Env: Name: JAVA_OPTIONS Value: -Dweblogic.StdoutDebugEnabled=false Name: USER_MEM_ARGS Value: -Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx512m Volume Mounts: Mount Path: /u01/oracle/user_projects/domains Name: weblogic-domain-storage-volume Volumes: Name: weblogic-domain-storage-volume Persistent Volume Claim: Claim Name: wccinfra-domain-pvc Server Start Policy: IF_NEEDED Web Logic Credentials Secret: Name: wccinfra-domain-credentials Status: Clusters: Cluster Name: ibr_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 1 Replicas: 1 Replicas Goal: 1 Cluster Name: ucm_cluster Maximum Replicas: 5 Minimum Replicas: 0 Ready Replicas: 2 Replicas: 2 Replicas Goal: 2 Conditions: Last Transition Time: 2020-11-23T13:58:41.070Z Reason: ServersReady Status: True Type: Available Servers: Desired State: RUNNING Health: Activation Time: 2020-11-25T16:55:24.930Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: pjadam Server Name: AdminServer State: RUNNING Cluster Name: ibr_cluster Desired State: RUNNING Health: Activation Time: 2020-11-30T12:23:27.603Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: pjadam Server Name: ibr_server1 State: RUNNING Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server2 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server3 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server4 Cluster Name: ibr_cluster Desired State: SHUTDOWN Server Name: ibr_server5 Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2020-12-02T14:10:37.992Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: pjadam Server Name: ucm_server1 State: RUNNING Cluster Name: ucm_cluster Desired State: RUNNING Health: Activation Time: 2020-12-01T04:51:19.886Z Overall Health: ok Subsystems: Subsystem Name: ServerRuntime Symptoms: Node Name: pjadam Server Name: ucm_server2 State: RUNNING Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm_server3 Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm_server4 Cluster Name: ucm_cluster Desired State: SHUTDOWN Server Name: ucm_server5 Start Time: 2020-11-23T12:48:13.756Z Events: \u0026lt;none\u0026gt;    In the Status section of the output, the available servers and clusters are listed. Note that if this command is issued soon after the script finishes, there may be no servers available yet, or perhaps only the Administration Server but no Managed Servers. The operator will start up the Administration Server first and wait for it to become ready before starting the Managed Servers.\nVerify the pods Enter the following command to see the pods running the servers:\n$ kubectl get pods -n NAMESPACE Here is an example of the output of this command. You can verify that an Administration Server and Managed Servers for ucm \u0026amp; ibr cluster are running.\n$ kubectl get pod -n wccns NAME READY STATUS RESTARTS AGE rcu 1/1 Running 0 78d wccinfra-adminserver 1/1 Running 0 9d wccinfra-create-fmw-infra-sample-domain-job-l8r9d 0/1 Completed 0 9d wccinfra-ibr-server1 1/1 Running 0 9d wccinfra-ucm-server1 1/1 Running 0 9d wccinfra-ucm-server2 1/1 Running 0 9d Verify the services Enter the following command to see the services for the domain:\n$ kubectl get services -n NAMESPACE Here is an example of the output of this command.\n  Click here to see a sample list of services.   $ kubectl get services -n wccns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE wccinfra-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 9d wccinfra-adminserver-external NodePort 10.104.100.193 \u0026lt;none\u0026gt; 7001:30701/TCP 9d wccinfra-cluster-ibr-cluster ClusterIP 10.98.100.212 \u0026lt;none\u0026gt; 16250/TCP 114s wccinfra-cluster-ucm-cluster ClusterIP 10.108.47.178 \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ibr-server1 ClusterIP None \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server2 ClusterIP 10.97.253.44 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server3 ClusterIP 10.110.183.48 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server4 ClusterIP 10.108.228.158 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ibr-server5 ClusterIP 10.101.29.140 \u0026lt;none\u0026gt; 16250/TCP 9d wccinfra-ucm-server1 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server2 ClusterIP None \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server3 ClusterIP 10.107.61.128 \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server4 ClusterIP 10.109.25.242 \u0026lt;none\u0026gt; 16200/TCP 9d wccinfra-ucm-server5 ClusterIP 10.109.193.26 \u0026lt;none\u0026gt; 16200/TCP 9d    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/appendix/docker-k8s-hardening/",
	"title": "Security hardening",
	"tags": [],
	"description": "Review resources for the Docker and Kubernetes cluster hardening.",
	"content": "Securing a Kubernetes cluster involves hardening on multiple fronts - securing the API servers, etcd, nodes, container images, container run-time, and the cluster network. Apply principles of defense in depth, principle of least privilege, and minimize the attack surface. Use security tools such as Kube-Bench to verify the cluster\u0026rsquo;s security posture. Since Kubernetes is evolving rapidly refer to Kubernetes Security Overview for the latest information on securing a Kubernetes cluster. Also ensure the deployed Docker containers follow the Docker Security guidance.\nThis section provides references on how to securely configure Docker and Kubernetes.\nReferences   Docker hardening\n https://docs.docker.com/engine/security/security/ https://blog.aquasec.com/docker-security-best-practices    Kubernetes hardening\n https://kubernetes.io/docs/concepts/security/overview/ https://kubernetes.io/docs/concepts/security/pod-security-standards/ https://blogs.oracle.com/developers/5-best-practices-for-kubernetes-security    Security best practices for Oracle WebLogic Server Running in Docker and Kubernetes\n https://blogs.oracle.com/weblogicserver/security-best-practices-for-weblogic-server-running-in-docker-and-kubernetes    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/elasticsearch-integration/",
	"title": "Elasticsearch integration for logs",
	"tags": [],
	"description": "Monitor an Oracle WebCenter Sites domain and publish the WebLogic Server logs to Elasticsearch.",
	"content": "1. Integrate Elasticsearch to WebLogic Kubernetes Operator For reference information, see Elasticsearch integration for the WebLogic Kubernetes Operator.\nTo enable elasticsearch integration, you must edit file kubernetes/charts/weblogic-operator/values.yaml before deploying the WebLogic Kubernetes Operator.\n# elkIntegrationEnabled specifies whether or not ELK integration is enabled. elkIntegrationEnabled: true # logStashImage specifies the docker image containing logstash. # This parameter is ignored if 'elkIntegrationEnabled' is false. logStashImage: \u0026quot;logstash:6.6.0\u0026quot; # elasticSearchHost specifies the hostname of where Elasticsearch is running. # This parameter is ignored if 'elkIntegrationEnabled' is false. elasticSearchHost: \u0026quot;elasticsearch.default.svc.cluster.local\u0026quot; # elasticSearchPort specifies the port number of where Elasticsearch is running. # This parameter is ignored if 'elkIntegrationEnabled' is false. elasticSearchPort: 9200 After you\u0026rsquo;ve deployed WebLogic Kubernetes Operator and made the above changes, the weblogic-operator pod will have additional Logstash container. The Logstash container will push the weblogic-operator logs to the configured Elasticsearch server.\n2. Publish WebLogic Server and WebCenter Content Logs using Logstash Pod You can publish the WebLogic Server logs to Elasticsearch Server using Logstash pod. This Logstash pod must have access to the shared domain home. For the WebCenter Content wccinfra, you can use the persistent volume of the domain home in the Logstash pod. The steps to create the Logstash pod are as follows:\nGet the persistent volume details of the domain home of the WebLogic Server(s). The following command will list the persistent volume details in the namespace - \u0026ldquo;wccns\u0026rdquo;:\n$ kubectl get pv -n wccns NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE wccinfra-domain-pv 10Gi RWX Retain Bound wccns/wccinfra-domain-pvc wccinfra-domain-storage-class 33d Create the deployment yaml for Logstash pod. The mounted persistent volume of the domain home will provide access to the WebLogic server logs to Logstash pod. Given below is a sample Logstash deployment yaml.\napiVersion: apps/v1 kind: Deployment metadata: name: logstash-wls namespace: wccns spec: selector: matchLabels: app: \u0026quot;logstash-wls\u0026quot; template: # create pods using pod definition in this template metadata: labels: app: logstash-wls spec: volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc - name: shared-logs emptyDir: {} containers: - name: logstash image: logstash:6.6.0 command: [\u0026quot;/bin/sh\u0026quot;] args: [\u0026quot;/usr/share/logstash/bin/logstash\u0026quot;, \u0026quot;-f\u0026quot;, \u0026quot;/u01/oracle/user_projects/domains/logstash/logstash.conf\u0026quot;] imagePullPolicy: IfNotPresent serverStartPolicy: \u0026quot;NEVER\u0026quot; volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume - name: shared-logs mountPath: /shared-logs ports: - containerPort: 5044 name: logstash Sample Logstash configuration file is located at kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.conf\n$ vi kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.conf input { file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/AdminServer.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ucm_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ibr_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/AdminServer.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ucm_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/logs/wccinfra/ibr_server*.out\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/AdminServer/logs/AdminServer-diagnostic.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/ucm_server*.log\u0026quot; start_position =\u0026gt; beginning } file { path =\u0026gt; \u0026quot;/u01/oracle/user_projects/domains/wccinfra/servers/**/logs/ibr_server*.log\u0026quot; start_position =\u0026gt; beginning } } filter { grok { match =\u0026gt; [ \u0026quot;message\u0026quot;, \u0026quot;\u0026lt;%{DATA:log_timestamp}\u0026gt; \u0026lt;%{WORD:log_level}\u0026gt; \u0026lt;%{WORD:thread}\u0026gt; \u0026lt;%{HOSTNAME:hostname}\u0026gt; \u0026lt;%{HOSTNAME:servername}\u0026gt; \u0026lt;%{DATA:timer}\u0026gt; \u0026lt;\u0026lt;%{DATA:kernel}\u0026gt;\u0026gt; \u0026lt;\u0026gt; \u0026lt;%{DATA:uuid}\u0026gt; \u0026lt;%{NUMBER:timestamp}\u0026gt; \u0026lt;%{DATA:misc}\u0026gt; \u0026lt;%{DATA:log_number}\u0026gt; \u0026lt;%{DATA:log_message}\u0026gt;\u0026quot; ] } } output { elasticsearch { hosts =\u0026gt; [\u0026quot;elasticsearch.default.svc.cluster.local:9200\u0026quot;] } } Here ** means that all ucm_server.log and ibr_server.log from any servers under wccinfra will be pushed to Logstash.\n$ kubectl cp kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.conf wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/logstash/logstash.conf Deploy Logstash pod After you have created the Logstash deployment yaml and Logstash configuration file, deploy Logstash using following command:\n$ kubectl create -f kubernetes/samples/scripts/create-wcc-domain/logstash/logstash.yaml 3. Test the Deployment of Elasticsearch and Kibana The WebLogic Operator also provides a sample deployment of Elasticsearch and Kibana for testing purpose. You can deploy Elasticsearch and Kibana on the Kubernetes cluster as shown below:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/ $ kubectl create -f kubernetes/samples/scripts/elasticsearch-and-kibana/elasticsearch_and_kibana.yaml Get the Kibana dashboard port information as shown below: Wait for pods to start:\n-bash-4.2$ kubectl get pods -w NAME READY STATUS RESTARTS AGE elasticsearch-8bdb7cf54-mjs6s 1/1 Running 0 4m3s kibana-dbf8964b6-n8rcj 1/1 Running 0 4m3s -bash-4.2$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE elasticsearch ClusterIP 10.105.205.157 \u0026lt;none\u0026gt; 9200/TCP,9300/TCP 10d kibana NodePort 10.98.104.41 \u0026lt;none\u0026gt; 5601:30412/TCP 10d kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 42d You can access the Kibana dashboard at http://\u0026lt;your_hostname\u0026gt;:30412/. In our example, the node port would be 30412.\nCreate an Index Pattern in Kibana Create an index pattern wls* in Kibana \u0026gt; Management. After the servers are started, you will see the log data in the Kibana dashboard:\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/configure-load-balancer/voyager/",
	"title": "Voyager",
	"tags": [],
	"description": "Configure the ingress-based Voyager load balancer for Oracle WebCenter Content domain.",
	"content": "Voyager/HAProxy is a popular ingress-based load balancer for production environments. This section provides information about how to install and configure Voyager/HAProxy to load balance Oracle WebCenter Content domain clusters. You can configure Voyager for non-SSL, SSL termination, and end-to-end SSL access of the application URL.\nFollow these steps to set up Voyager as a load balancer for an Oracle WebCenter Content domain in a Kubernetes cluster:\n  Non-SSL and SSL termination\n Install the Voyager load balancer Configure Voyager to manage ingresses Verify non-SSL and SSL access    End-to-end SSL configuration\n Install Voyager load balancer for end-to-end SSL Deploy tls to access the services Verify end-to-end SSL access    Non-SSL and SSL termination Install the Voyager load balancer   Add the AppsCode chart repository:\n$ helm repo add appscode https://charts.appscode.com/stable/ $ helm repo update   Verify that the chart repository has been added:\n$ helm search repo appscode/voyager  NOTE: After updating the Helm repository, the Voyager version listed may be newer that the one appearing here. Check with the Voyager site for the latest supported versions.\n   Install the Voyager operator:\n NOTE: The Voyager version used for the install should match the version found with helm search.\n $ kubectl create ns voyager $ helm install voyager-operator appscode/voyager --version v12.0.0 \\  --namespace voyager \\  --set cloudProvider=baremetal \\  --set apiserver.enableValidatingWebhook=false Wait until the Voyager operator is running.\n  Check the status of the Voyager operator:\n$ kubectl get all -n voyager     Click here to see the sample output.   NAME READY STATUS RESTARTS AGE pod/voyager-operator-788f4cdc65-bzvvs 1/1 Running 0 10d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/voyager-operator ClusterIP 10.110.165.167 \u0026lt;none\u0026gt; 443/TCP,56791/TCP 10d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/voyager-operator 1/1 1 1 10d NAME DESIRED CURRENT READY AGE replicaset.apps/voyager-operator-788f4cdc65 1 1 1 10d replicaset.apps/voyager-operator-dcb77b9b9 0 0 0 10d    See the official installation document for more details.\n  Update the Voyager operator\nAfter the Voyager operator is installed and running, upgrade the Voyager operator using the helm upgrade command, where voyager is the Voyager namespace and wccns is the namespace of the domain.\n  $ helm upgrade voyager-operator appscode/voyager --namespace voyager    Click here to see the sample output.   Release \u0026#34;voyager-operator\u0026#34; has been upgraded. Happy Helming! NAME: voyager-operator LAST DEPLOYED: Thu Feb 4 03:18:39 2021 NAMESPACE: voyager STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: Set cloudProvider for installing Voyager To verify that Voyager has started, run: kubectl get deployment --namespace voyager -l \u0026#34;app.kubernetes.io/name=voyager,app.kubernetes.io/instance=voyager-operator\u0026#34;    Configure Voyager to manage ingresses   Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK , tls is Non-SSL, and domainType is wcc. These values can be overridden by passing values through the command line or can be edited on the sample file values.yaml.\nIf needed, you can update the ingress yaml file to define more path rules (in the spec.rules.host.http.paths section) based on the domain application URLs that need to be accessed. You need to update the template yaml file for the Voyager (ingress-based) load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/voyager-ingress.yaml\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wccinfra-voyager-ingress kubernetes/samples/charts/ingress-per-domain \\  --set type=VOYAGER \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set tls=NONSSL    Click here to check the output of the ingress per domain   NAME: wccinfra-voyager-ingress LAST DEPLOYED: Thu Feb 4 03:32:25 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None      To secure access (SSL) to the Oracle WebCenter Content application, create a certificate and generate secrets:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Deploy ingress-per-domain using Helm for SSL configuration.\nIf needed, you can update the ingress yaml file to define more path rules (in the spec.rules.host.http.paths section) based on the domain application URLs that need to be accessed. You need to update the template yaml file for the Voyager (ingress-based) load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/voyager-ingress.yaml\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wccinfra-voyager-ingress kubernetes/samples/charts/ingress-per-domain \\  --set type=VOYAGER \\  --namespace wccns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set tls=SSL    Click here to see the sample output of the above Commnad.   NAME: wccinfra-voyager-ingress LAST DEPLOYED: Thu Feb 4 03:32:25 2021 NAMESPACE: wccns STATUS: deployed REVISION: 1 TEST SUITE: None      For non-SSL/SSL access to the Oracle WebCenter Content application, get the details of the services deployed by the above ingress:\n$ kubectl describe ingress.voyager.appscode.com/wccinfra-voyager -n wccns     Click here to see the sample output of the services supported by the above deployed ingress.   Sample output:\nName: wccinfra-voyager Namespace: wccns Labels: app.kubernetes.io/managed-by=Helm weblogic.resourceVersion=domain-v2 Annotations: ingress.appscode.com/affinity: cookie ingress.appscode.com/stats: true ingress.appscode.com/type: NodePort meta.helm.sh/release-name: wccinfra-voyager-ingress meta.helm.sh/release-namespace: wccns API Version: voyager.appscode.com/v1beta1 Kind: Ingress Metadata: Creation Timestamp: 2021-02-04T12:37:05Z Generation: 1 Managed Fields: API Version: voyager.appscode.com/v1beta1 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:ingress.appscode.com/affinity: f:ingress.appscode.com/stats: f:ingress.appscode.com/type: f:meta.helm.sh/release-name: f:meta.helm.sh/release-namespace: f:labels: .: f:app.kubernetes.io/managed-by: f:weblogic.resourceVersion: f:spec: .: f:frontendRules: f:rules: f:tls: Manager: Go-http-client Operation: Update Time: 2021-02-04T12:37:05Z Resource Version: 30737661 Self Link: /apis/voyager.appscode.com/v1beta1/namespaces/wccns/ingresses/wccinfra-voyager UID: 80bfab31-21db-4211-b0b3-afa7009bec1b Spec: Frontend Rules: Port: 443 Rules: http-request set-header WL-Proxy-SSL true Rules: Host: * Http: Node Port: 31316 Paths: Backend: Service Name: wccinfra-adminserver Service Port: 7001 Path: /console Backend: Service Name: wccinfra-adminserver Service Port: 7001 Path: /em Backend: Service Name: wccinfra-adminserver Service Port: 7001 Path: /cs Backend: Service Name: wccinfra-cluster-ucm-cluster Service Port: 16200 Path: /adfAuthentication Backend: Service Name: wccinfra-cluster-ibr-cluster Service Port: 16250 Path: /ibr Backend: Service Name: wccinfra-cluster-ibr-cluster Service Port: 16250 Path: /ibr/adfAuthentication Backend: Service Name: wccinfra-cluster-ucm-cluster Service Port: 16200 Path: /weblogic/ready Tls: Hosts: * Secret Name: domain1-tls-cert Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal DeploymentReconcileSuccessful 59m voyager-operator Successfully patched HAProxy Deployment voyager-wccinfra-voyager Normal DeploymentReconcileSuccessful 59m voyager-operator Successfully patched HAProxy Deployment voyager-wccinfra-voyager     To confirm that the load balancer noticed the new ingress and is successfully routing to the domain\u0026rsquo;s server pods, you can send a request to the URL for the \u0026ldquo;WebLogic ReadyApp framework\u0026rdquo; which should return a HTTP 200 status code, as follows:  $ curl -v http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-PORT}/weblogic/ready * About to connect() to ****.com port 31316 (#0) * Trying 100.111.156.246... * Connected to ****.com (100.111.156.246) port 31316 (#0) \u0026gt; GET /weblogic/ready HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Host: *****.com:31316 \u0026gt; Accept: */* \u0026gt; Verify Non-SSL and SSL access After setting up the Voyager (ingress-based) load balancer, verify that the Oracle WebCenter Content domain applications are accessible through the load balancer port 31316 (both SSL and non-SSL). The application URLs for Oracle WebCenter Content domain of type wcc are:\n Note: Port 31316 is the LOADBALANCER-Non-SSLPORT and LOADBALANCER-SSLPORT.\n Non-SSL configuration http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr SSL configuration https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr Uninstalling the chart To uninstall and delete the my-ingress deployment, enter the following command:\n$ helm delete wccinfra-voyager -n wccns End-to-end SSL configuration Install Voyager load balancer for end-to-end SSL Install the Voyager load balancer as described here.\n  Check the status of the Voyager operator.\n$ kubectl get all -n voyager Sample output:\n  NAME READY STATUS RESTARTS AGE pod/voyager-operator-788f4cdc65-bzvvs 1/1 Running 0 10d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/voyager-operator ClusterIP 10.110.165.167 \u0026lt;none\u0026gt; 443/TCP,56791/TCP 10d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/voyager-operator 1/1 1 1 10d NAME DESIRED CURRENT READY AGE replicaset.apps/voyager-operator-788f4cdc65 1 1 1 10d replicaset.apps/voyager-operator-dcb77b9b9 0 0 0 10d  For secured access (SSL) to the Oracle WebCenter Content application, create a certificate and generate Kuberentes secrets: $ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wccns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Deploy tls to access services   Deploy tls to securely access the services. Only one application can be configured with ssl-passthrough. A sample tls file for Voyager is shown below for the service wccinfra-adminserver and port 7001. All the applications running on port 7001 can be securely accessed through this ingress. For each backend service, create different ingresses as Voyager does not support multiple path/rules with annotation ssl-passthrough.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls     Click here to see the content of the file voyager-ucm-tls.yaml   apiVersion: voyager.appscode.com/v1beta1 kind: Ingress metadata: name: voyager-ucm1-ssl namespace: wccns annotations: ingress.appscode.com/type: \u0026#39;NodePort\u0026#39; ingress.appscode.com/stats: \u0026#39;true\u0026#39; ingress.appscode.com/affinity: \u0026#39;cookie\u0026#39; ingress.appscode.com/ssl-passthrough: \u0026#34;true\u0026#34; spec: tls: - secretName: domain1-tls-cert hosts: - \u0026#39;*\u0026#39; rules: - host: \u0026#39;*\u0026#39; http: nodePort: \u0026#39;31318\u0026#39; paths: - path: /cs backend: serviceName: wccinfra-cluster-ucm-cluster servicePort: \u0026#39;16201\u0026#39;    $ kubectl create -f voyager-adminserver-tls.yaml $ kubectl create -f voyager-ucm-tls.yaml $ kubectl create -f voyager-ibr-tls.yaml    Click here to see the services supported by the ingress   kubectl describe ingress.voyager.appscode.com/voyager-ucm-ssl -n wccns Name: voyager-ucm-ssl Namespace: wccns Labels: \u0026lt;none\u0026gt; Annotations: ingress.appscode.com/affinity: cookie ingress.appscode.com/ssl-passthrough: true ingress.appscode.com/stats: true ingress.appscode.com/type: NodePort API Version: voyager.appscode.com/v1beta1 Kind: Ingress Metadata: Creation Timestamp: 2021-02-05T07:35:24Z Generation: 1 Managed Fields: API Version: voyager.appscode.com/v1beta1 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:ingress.appscode.com/affinity: f:ingress.appscode.com/ssl-passthrough: f:ingress.appscode.com/stats: f:ingress.appscode.com/type: f:spec: .: f:rules: f:tls: Manager: kubectl Operation: Update Time: 2021-02-05T07:35:24Z Resource Version: 30897397 Self Link: /apis/voyager.appscode.com/v1beta1/namespaces/wccns/ingresses/voyager-ucm1-ssl UID: 3b50f3c4-4447-477d-9f31-06e1a7b99df0 Spec: Rules: Host: * Http: Node Port: 31318 Paths: Backend: Service Name: wccinfra-cluster-ucm-cluster Service Port: 16201 Path: /cs Tls: Hosts: * Secret Name: domain1-tls-cert Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal DeploymentReconcileSuccessful 50m voyager-operator Successfully patched HAProxy Deployment voyager-voyager-ucm1-ssl Normal DeploymentReconcileSuccessful 40m voyager-operator Successfully patched HAProxy Deployment voyager-voyager-ucm1-ssl    Verify end-to-end SSL access Verify that the Oracle WebCenter Content domain application URLs are accessible through the SSLPORT 31443:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console/ https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs/ https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr Uninstall the Voyager tls $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl delete -f voyager-adminserver-tls.yaml $ kubectl delete -f voyager-adminserver-tls.yaml $ kubectl delete -f voyager-adminserver-tls.yaml "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/appendix/docker-k8s-hardening/",
	"title": "Security hardening",
	"tags": [],
	"description": "Review resources for the Docker and Kubernetes cluster hardening.",
	"content": "Securing a Kubernetes cluster involves hardening on multiple fronts - securing the API servers, etcd, nodes, container images, container run-time, and the cluster network. Apply principles of defense in depth, principle of least privilege, and minimize the attack surface. Use security tools such as Kube-Bench to verify the cluster\u0026rsquo;s security posture. Since Kubernetes is evolving rapidly refer to Kubernetes Security Overview for the latest information on securing a Kubernetes cluster. Also ensure the deployed Docker containers follow the Docker Security guidance.\nThis section provides references on how to securely configure Docker and Kubernetes.\nReferences   Docker hardening\n https://docs.docker.com/engine/security/security/ https://blog.aquasec.com/docker-security-best-practices    Kubernetes hardening\n https://kubernetes.io/docs/concepts/security/overview/ https://kubernetes.io/docs/concepts/security/pod-security-standards/ https://blogs.oracle.com/developers/5-best-practices-for-kubernetes-security    Security best practices for Oracle WebLogic Server Running in Docker and Kubernetes\n https://blogs.oracle.com/weblogicserver/security-best-practices-for-weblogic-server-running-in-docker-and-kubernetes    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/configure-load-balancer/voyager/",
	"title": "Voyager",
	"tags": [],
	"description": "Configure the ingress-based Voyager load balancer for an Oracle WebCenter Portal domain.",
	"content": "Voyager/HAProxy is a popular ingress-based load balancer for production environments. You can install and configure Voyager/HAProxy to load balance Oracle WebCenter Portal domain clusters and configure it for non-SSL, SSL termination, and end-to-end SSL access of the application URL. Follow these steps to set up Voyager as a load balancer for an Oracle WebCenter Portal domain in a Kubernetes cluster:\n  Non-SSL and SSL termination\n Install the Voyager load balancer Configure Voyager to manage ingresses Verify non-SSL and SSL access    End-to-end SSL configuration\n Install Voyager load balancer for end-to-end SSL Deploy tls to access the services Verify end-to-end SSL access    Non-SSL and SSL termination Install the Voyager load balancer   Add the AppsCode chart repository:\n$ helm repo add appscode https://charts.appscode.com/stable/ $ helm repo update   Verify that the chart repository has been added:\n$ helm search repo appscode/voyager  NOTE: After updating the Helm repository, the Voyager version listed may be newer that the one shown here. Check with the Voyager site for the latest supported versions.\n   Install the Voyager operator:\n NOTE: The Voyager version you install must match the version found with the helm search.\n $ kubectl create namespace voyager $ helm install voyager-operator appscode/voyager --version 10.0.0 \\  --namespace voyager \\  --set cloudProvider=baremetal \\  --set apiserver.enableValidatingWebhook=false Wait until the Voyager operator is running.\n  Check the status of the Voyager operator:\n$ kubectl get all -n voyager    Click here to see the sample output.    NAME READY STATUS RESTARTS AGE pod/voyager-operator-b84f95f8f-4szhl 1/1 Running 0 43h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/voyager-operator ClusterIP 10.107.201.155 \u0026lt;none\u0026gt; 443/TCP,56791/TCP 43h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/voyager-operator 1/1 1 1 43h NAME DESIRED CURRENT READY AGE replicaset.apps/voyager-operator-b84f95f8f 1 1 1 43h    See the official installation document for more details.\n  Update the Voyager operator. Once the Voyager operator is installed, and it is running, upgrade it using the helm upgrade command. In this command, voyager is the Voyager namespace and wcpns is the namespace of the domain.\n$ helm upgrade voyager-operator appscode/voyager --namespace voyager    Click here to see the sample output.   Release \u0026quot;voyager-operator\u0026quot; has been upgraded. Happy Helming! NAME: voyager-operator LAST DEPLOYED: Mon Sep 28 11:53:43 2020 NAMESPACE: voyager STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: Set cloudProvider for installing Voyager To verify that Voyager has started, run: kubectl get deployment --namespace voyager -l \u0026quot;app.kubernetes.io/name=voyager,app.kubernetes.io/instance=voyager-operator\u0026quot;      Configure Voyager to manage ingresses   Create an ingress for the domain in the domain namespace by using the sample Helm chart. Here path-based routing is used for ingress. Sample values for default configuration are shown in the file ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/values.yaml. By default, type is TRAEFIK , tls is Non-SSL. You can override these values by passing your values through the command line or edit the existing values in the sample values.yaml file.\nIf needed, you can update the ingress yaml file to define more path rules (in the spec.rules.host.http.paths section) based on the domain application URLs that need to be accessed. You need to update the template yaml file for the Voyager (ingress-based) load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/voyager-ingress.yaml\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcp-voyager-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wcpns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set type=VOYAGER    Click here to check the output of the ingress per domain   NAME: wcp-voyager-ingress LAST DEPLOYED: Mon Jul 20 08:20:27 2020 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None      For secured access (SSL) to the Oracle WebCenter Portal application, create a certificate and generate secrets:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wcpns create secret tls wcpinfra-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt  Note: The value of CN is the host on which this ingress is to be deployed.\n   Deploy ingress-per-domain using Helm for SSL configuration.\nIf needed, you can update the ingress yaml file to define more path rules (in the spec.rules.host.http.paths section) based on the domain application URLs that need to be accessed. You need to update the template yaml file for the Voyager (ingress-based) load balancer located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/templates/voyager-ingress.yaml\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm install wcp-voyager-ingress kubernetes/samples/charts/ingress-per-domain \\  --namespace wcpns \\  --values kubernetes/samples/charts/ingress-per-domain/values.yaml \\  --set type=VOYAGER \\  --set tls=SSL    Click here to see the sample output of the above Commnad.   NAME: wcp-voyager-ingress LAST DEPLOYED: Mon Jul 20 08:20:27 2020 NAMESPACE: wcpns STATUS: deployed REVISION: 1 TEST SUITE: None      For non-SSL access to the Oracle WebCenter Portal application, get the details of the services deployed by the above ingress:\n$ kubectl describe ingress.voyager.appscode.com/wcp-domain-voyager -n wcpns    Click here to see the sample output of the services supported by the above deployed ingress.   Sample output:\nName: wcp-domain-voyager Namespace: wcpns Labels: app.kubernetes.io/managed-by=Helm Annotations: ingress.appscode.com/affinity: cookie ingress.appscode.com/stats: true ingress.appscode.com/type: NodePort meta.helm.sh/release-name: wcp-voyager-ingress meta.helm.sh/release-namespace: wcpns API Version: voyager.appscode.com/v1beta1 Kind: Ingress Metadata: Creation Timestamp: 2021-01-13T08:19:16Z Generation: 1 Managed Fields: API Version: voyager.appscode.com/v1beta1 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:ingress.appscode.com/affinity: f:ingress.appscode.com/stats: f:ingress.appscode.com/type: f:meta.helm.sh/release-name: f:meta.helm.sh/release-namespace: f:labels: .: f:app.kubernetes.io/managed-by: f:spec: .: f:rules: Manager: Go-http-client Operation: Update Time: 2021-01-13T08:19:16Z Resource Version: 340890 Self Link: /apis/voyager.appscode.com/v1beta1/namespaces/wcpns/ingresses/wcp-domain-voyager UID: a06315c2-23ad-4916-a972-cd3555494eb8 Spec: Rules: Host: * Http: Node Port: 30305 Paths: Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8888 Path: /webcenter Backend: Service Name: wcp-domain-adminserver Service Port: 7001 Path: /console Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8888 Path: /rsscrawl Backend: Service Name: wcp-domain-adminserver Service Port: 7001 Path: /em Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ServiceReconcileSuccessful 62s voyager-operator Successfully created NodePort Service voyager-wcp-domain-voyager Normal ConfigMapReconcileSuccessful 62s voyager-operator Successfully created ConfigMap voyager-wcp-domain-voyager Normal RBACSuccessful 62s voyager-operator Successfully created ServiceAccount voyager-wcp-domain-voyager Normal RBACSuccessful 62s voyager-operator Successfully created Role voyager-wcp-domain-voyager Normal RBACSuccessful 62s voyager-operator Successfully created RoleBinding voyager-wcp-domain-voyager Normal DeploymentReconcileSuccessful 62s voyager-operator Successfully created HAProxy Deployment voyager-wcp-domain-voyager Normal StatsServiceReconcileSuccessful 62s voyager-operator Successfully created stats Service voyager-wcp-domain-voyager-stats      For SSL access to the Oracle WebCenter Portal application, get the details of the services by the above deployed ingress:\n$ kubectl describe ingress.voyager.appscode.com/wcp-domain-voyager -n wcpns    Click here to see all the services configured by the above deployed ingress.   Name: wcp-domain-voyager Namespace: wcpns Labels: app.kubernetes.io/managed-by=Helm Annotations: ingress.appscode.com/affinity: cookie ingress.appscode.com/stats: true ingress.appscode.com/type: NodePort meta.helm.sh/release-name: wcp-domain-ingress meta.helm.sh/release-namespace: wcpns API Version: voyager.appscode.com/v1beta1 Kind: Ingress Metadata: Creation Timestamp: 2021-01-15T05:40:20Z Generation: 1 Managed Fields: API Version: voyager.appscode.com/v1beta1 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:ingress.appscode.com/affinity: f:ingress.appscode.com/stats: f:ingress.appscode.com/type: f:meta.helm.sh/release-name: f:meta.helm.sh/release-namespace: f:labels: .: f:app.kubernetes.io/managed-by: f:spec: .: f:frontendRules: f:rules: f:tls: Manager: Go-http-client Operation: Update Time: 2021-01-15T05:40:20Z Resource Version: 704682 Self Link: /apis/voyager.appscode.com/v1beta1/namespaces/wcpns/ingresses/wcp-domain-voyager UID: 1e83c6a6-336f-4e29-b38a-023e00ca5cd5 Spec: Frontend Rules: Port: 443 Rules: http-request set-header WL-Proxy-SSL true Rules: Host: * Http: Node Port: 30305 Paths: Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8888 Path: /webcenter Backend: Service Name: wcp-domain-adminserver Service Port: 7001 Path: /console Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8888 Path: /rsscrawl Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8888 Path: /rest Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8888 Path: /webcenterhelp Backend: Service Name: wcp-domain-adminserver Service Port: 7001 Path: /em Tls: Hosts: * Secret Name: domain1-tls-cert Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ServiceReconcileSuccessful 54s voyager-operator Successfully created NodePort Service voyager-wcp-domain-voyager Normal ConfigMapReconcileSuccessful 54s voyager-operator Successfully created ConfigMap voyager-wcp-domain-voyager Normal RBACSuccessful 54s voyager-operator Successfully created ServiceAccount voyager-wcp-domain-voyager Normal RBACSuccessful 54s voyager-operator Successfully created Role voyager-wcp-domain-voyager Normal RBACSuccessful 54s voyager-operator Successfully created RoleBinding voyager-wcp-domain-voyager Normal DeploymentReconcileSuccessful 54s voyager-operator Successfully created HAProxy Deployment voyager-wcp-domain-voyager Normal StatsServiceReconcileSuccessful 54s voyager-operator Successfully created stats Service voyager-wcp-domain-voyager-stats      Verify Non-SSL and SSL access After setting up the Voyager (ingress-based) load balancer, verify that the Oracle WebCenter Portal domain applications are accessible through the load balancer port 30305 (both SSL and non-SSL). The application URLs for Oracle WebCenter Portal domain are:\n Note: Port 30305 is the LOADBALANCER-Non-SSLPORT and LOADBALANCER-SSLPORT.\n Non-SSL configuration http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenter http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rsscrawl http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rest http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenterhelp SSL configuration https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenter https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rsscrawl https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rest https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenterhelp Uninstall the chart To uninstall and delete the my-ingress deployment, enter the following command:\n$ helm delete wcp-voyager-ingress -n wcpns $ helm delete voyager-operator -n voyager End-to-end SSL configuration Install Voyager load balancer for end-to-end SSL Install the Voyager load balancer as described here.\n  Check the status of the Voyager operator.\n$ kubectl get all -n voyager Sample output:\nNAME READY STATUS RESTARTS AGE pod/voyager-operator-b84f95f8f-4szhl 1/1 Running 0 43h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/voyager-operator ClusterIP 10.107.201.155 \u0026lt;none\u0026gt; 443/TCP,56791/TCP 43h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/voyager-operator 1/1 1 1 43h NAME DESIRED CURRENT READY AGE replicaset.apps/voyager-operator-b84f95f8f 1 1 1 43h   For secured access (SSL) to the Oracle WebCenter Portal application, create a certificate and generate Kuberentes secrets:\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/tls1.key -out /tmp/tls1.crt -subj \u0026#34;/CN=*\u0026#34; $ kubectl -n wcpns create secret tls domain1-tls-cert --key /tmp/tls1.key --cert /tmp/tls1.crt   Deploy tls to access services   Deploy tls to securely access the services. Only one application can be configured with ssl-passthrough. A sample tls file for Voyager is shown below for the service wcp-domain-cluster-wcp-cluster and port 8889. All the applications running on port 8889 can be securely accessed through this ingress. For each backend service, create different ingresses as Voyager does not support multiple path/rules with annotation ssl-passthrough.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls    Click here to see the content of the file voyager-tls.yaml   apiVersion: voyager.appscode.com/v1beta1 kind: Ingress metadata: name: voyager-ssl namespace: wcpns annotations: ingress.appscode.com/type: \u0026#39;NodePort\u0026#39; ingress.appscode.com/stats: \u0026#39;true\u0026#39; ingress.appscode.com/affinity: \u0026#39;cookie\u0026#39; ingress.appscode.com/ssl-passthrough: \u0026#34;true\u0026#34; spec: tls: - secretName: domain1-tls-cert hosts: - \u0026#39;*\u0026#39; rules: - host: \u0026#39;*\u0026#39; http: nodePort: \u0026#39;31443\u0026#39; paths: - path: / backend: serviceName: wcp-domain-cluster-wcp-cluster servicePort: \u0026#39;8889\u0026#39;    $ kubectl create -f voyager-tls.yaml    Click here to see the services supported by the ingress   kubectl describe ingress.voyager.appscode.com/voyager-ssl -n wcpns Name: voyager-ssl Namespace: wcpns Labels: \u0026lt;none\u0026gt; Annotations: ingress.appscode.com/affinity: cookie ingress.appscode.com/ssl-passthrough: true ingress.appscode.com/stats: true ingress.appscode.com/type: NodePort API Version: voyager.appscode.com/v1beta1 Kind: Ingress Metadata: Creation Timestamp: 2020-07-20T04:34:05Z Generation: 1 Managed Fields: API Version: voyager.appscode.com/v1beta1 Fields Type: FieldsV1 fieldsV1: f:metadata: f:annotations: .: f:ingress.appscode.com/affinity: f:ingress.appscode.com/ssl-passthrough: f:ingress.appscode.com/stats: f:ingress.appscode.com/type: f:spec: .: f:rules: f:tls: Manager: kubectl Operation: Update Time: 2020-07-20T04:34:05Z Resource Version: 340071 Self Link: /apis/voyager.appscode.com/v1beta1/namespaces/wcpns/ingresses/voyager-ssl UID: 4a9b2e02-1593-45b3-8ac4-ae1ac0f2832c Spec: Rules: Host: * Http: Node Port: 31443 Paths: Backend: Service Name: wcp-domain-cluster-wcp-cluster Service Port: 8889 Path: / Tls: Hosts: * Secret Name: domain1-tls-cert Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ServiceReconcileSuccessful 7m37s voyager-operator Successfully created NodePort Service voyager-voyager-ssl N ormal ConfigMapReconcileSuccessful 7m37s voyager-operator Successfully created ConfigMap voyager-voyager-ssl Normal RBACSuccessful 7m37s voyager-operator Successfully created ServiceAccount voyager-voyager-ssl Normal RBACSuccessful 7m37s voyager-operator Successfully created Role voyager-voyager-ssl Normal RBACSuccessful 7m37s voyager-operator Successfully created RoleBinding voyager-voyager-ssl Normal DeploymentReconcileSuccessful 7m37s voyager-operator Successfully created HAProxy Deployment voyager-voyager-ssl Normal StatsServiceReconcileSuccessful 7m37s voyager-operator Successfully created stats Service voyager-voyager-ssl-stats Normal DeploymentReconcileSuccessful 3m5s voyager-operator Successfully patched HAProxy Deployment voyager-voyager-ssl      Verify end-to-end SSL access Verify that the Oracle WebCenter Portal domain application URLs are accessible through the SSLPORT 31443:\nhttps://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenter https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rsscrawl https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenterhelp https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rest Uninstall the Voyager tls $ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts/ingress-per-domain/tls $ kubectl delete -f voyager-tls.yaml $ helm delete voyager-operator -n voyager "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/installguide/create-wcp-domain/",
	"title": "Create WebCenter Portal domain",
	"tags": [],
	"description": "Create an Oracle WebCenter Portal domain home on an existing PV or PVC, and create the domain resource YAML file for deploying the generated Oracle WebCenter Portal domain.",
	"content": "Contents  Introduction Prerequisites Prepare the WebCenter Portal Domain Creation Input File Create the WebCenter Portal Domain Initialize the WebCenter Portal Domain Verify the WebCenter Portal Domain Managing WebCenter Portal  Introduction You can use the sample scripts to create a WebCenter Portal domain home on an existing Kubernetes persistent volume (PV) and persistent volume claim (PVC).The scripts also generate the domain YAML file, which helps you start the Kubernetes artifacts of the corresponding domain.\nPrerequisites  Ensure that you have completed all of the steps under prepare-your-environment. Ensure that the database and the WebLogic Kubernetes operator is up.  Prepare the WebCenter Portal Domain Creation Input File If required, you can customize the parameters used for creating a domain in the create-domain-inputs.yaml file.\nPlease note that the sample scripts for the WebCenter Portal domain deployment are available from the previously downloaded repository at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/domain-home-on-pv/.\nMake a copy of the create-domain-inputs.yaml file before updating the default values.\nThe default domain created by the script has the following characteristics:\n An Administration Server named AdminServer listening on port 7001. A configured cluster named wcp-cluster of size 5. Managed Server, named wcpserver, listening on port 8888. Log files that are located in /shared/logs/\u0026lt;domainUID\u0026gt;.  Configuration parameters The following parameters can be provided in the inputs file:\n   Parameter Definition Default     adminPort Port number for the Administration Server inside the Kubernetes cluster. 7001   sslEnabled SSL mode enabling flag false   adminServerSSLPort SSL Port number for the Administration Server inside the Kubernetes cluster. 7002   adminServerName Name of the Administration Server. AdminServer   clusterName Name of the WebLogic cluster instance to generate for the domain. By default the cluster name is wcp-cluster for the WebCenter Portal domain. wcp-cluster   configuredManagedServerCount Number of Managed Server instances for the domain. 5   createDomainFilesDir Directory on the host machine to locate all the files that you need to create a WebLogic domain, including the script that is specified in the createDomainScriptName property. By default, this directory is set to the relative path wlst, and the create script uses the built-in WLST offline scripts in the wlst directory to create the WebLogic domain. An absolute path is also supported to point to an arbitrary directory in the file system. The built-in scripts can be replaced by the user-provided scripts or model files as long as those files are in the specified directory. Files in this directory are put into a Kubernetes config map, which in turn is mounted to createDomainScriptsMountPath, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. wlst   createDomainScriptsMountPath Mount path where the create domain scripts are located inside a pod. The create-domain.sh script creates a Kubernetes job to run the script (specified in the createDomainScriptName property) in a Kubernetes pod that creates a domain home. Files in the createDomainFilesDir directory are mounted to this location in the pod, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. /u01/weblogic   createDomainScriptName Script that the create domain script uses to create a WebLogic domain. The create-domain.sh script creates a Kubernetes job to run this script that creates a domain home. The script is located in the in-pod directory that is specified in the createDomainScriptsMountPath property. If you need to provide your own scripts to create the domain home, instead of using the built-in scripts, you must use this property to set the name of the script to that which you want the create domain job to run. create-domain-job.sh   domainHome Home directory of the WebCenter Portal domain. This field cannot be modified. /u01/oracle/user_projects/domains/wcp-domain   domainPVMountPath Mount path of the domain persistent volume. This field cannot be modified. /u01/oracle/user_projects/domains   domainUID Unique ID that identifies this particular domain. Used as the name of the generated WebLogic domain as well as the name of the Kubernetes domain resource. This ID must be unique across all domains in a Kubernetes cluster. This ID cannot contain any character that is not valid in a Kubernetes service name. wcp-domain   exposeAdminNodePort Boolean indicating if the Administration Server is exposed outside of the Kubernetes cluster. false   exposeAdminT3Channel Boolean indicating if the T3 administrative channel is exposed outside the Kubernetes cluster. false   image WebCenter Portal Docker image. The WebLogic Kubernetes Operator requires WebCenter Portal release 12.2.1.4. Refer to WebCenter Portal Docker Image for details on how to obtain or create the image. oracle/wcportal:12.2.1.4   imagePullPolicy WebLogic Docker image pull policy. Legal values are IfNotPresent, Always, or Never IfNotPresent   imagePullSecretName Name of the Kubernetes secret to access the Docker Store to pull the WebLogic Server Docker image. The presence of the secret is validated when this parameter is specified.    includeServerOutInPodLog Boolean indicating whether to include server.out to the pod\u0026rsquo;s stdout. true   initialManagedServerReplicas Number of Managed Server to initially start for the domain. 2   javaOptions Java options for starting the Administration Server and Managed Servers. A Java option can include references to one or more of the following pre-defined variables to obtain WebLogic domain information: $(DOMAIN_NAME), $(DOMAIN_HOME), $(ADMIN_NAME), $(ADMIN_PORT), and $(SERVER_NAME). -Dweblogic.StdoutDebugEnabled=false   logHome The in-pod location for the domain log, server logs, server out, and Node Manager log files. This field cannot be modified. /u01/oracle/user_projects/logs/wcp-domain   managedServerNameBase Base string used to generate Managed Server names. wcpserver   managedServerPort Port number for each Managed Server. 8888   managedServerSSLPort SSL port number for each Managed Server. 8889   namespace Kubernetes namespace in which to create the domain. wcpns   persistentVolumeClaimName Name of the persistent volume claim created to host the domain home. If not specified, the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-sample-pvc. wcp-domain-domain-pvc   productionModeEnabled Boolean indicating if production mode is enabled for the domain. true   serverStartPolicy Determines which WebLogic Server instances are to be started. Legal values are NEVER, IF_NEEDED, ADMIN_ONLY. IF_NEEDED   t3ChannelPort Port for the T3 channel of the NetworkAccessPoint. 30012   t3PublicAddress Public address for the T3 channel. This should be set to the public address of the Kubernetes cluster. This would typically be a load balancer address. For development environments only: In a single server (all-in-one) Kubernetes deployment, this may be set to the address of the master, or at the very least, it must be set to the address of one of the worker nodes. If not provided, the script will attempt to set it to the IP address of the Kubernetes cluster.   weblogicCredentialsSecretName Name of the Kubernetes secret for the Administration Server\u0026rsquo;s user name and password. If not specified, then the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-credentials. wcpinfra-domain-credentials   weblogicImagePullSecretName Name of the Kubernetes secret for the Docker Store, used to pull the WebLogic Server image.    serverPodCpuRequest, serverPodMemoryRequest, serverPodCpuCLimit, serverPodMemoryLimit The maximum amount of compute resources allowed and minimum amount of compute resources required for each server pod. Please refer to the Kubernetes documentation on Managing Compute Resources for Containers for details. Resource requests and resource limits are not specified. Refer to WebCenter Portal Cluster Sizing Recommendations for more details.   rcuSchemaPrefix The schema prefix to use in the database, for example WCP1. You may wish to make this the same as the domainUID in order to simplify matching domain to their RCU schemas. WCP1   rcuDatabaseURL The database URL. dbhostname:dbport/servicename   rcuCredentialsSecret The Kubernetes secret containing the database credentials. wcpinfra-rcu-credentials   loadBalancerHostName Host name for the final url accessible outside K8S environment. abc.def.com   loadBalancerPortNumber Port for the final url accessible outside K8S environment. 30305   loadBalancerProtocol Protocol for the final url accessible outside K8S environment. http   loadBalancerType Loadbalancer name. Example: Traefik or \u0026quot;\u0026rdquo; traefik   unicastPort Starting range of unicast port that application will use. 50000    You can form the names of the Kubernetes resources in the generated YAML files with the value of these properties specified in the create-domain-inputs.yaml file: adminServerName, clusterName and managedServerNameBase. Characters that are invalid in a Kubernetes service name are converted to valid values in the generated YAML files. For example, an uppercase letter is converted to a lowercase letter and an underscore (\u0026quot;_\u0026quot;) is converted to a hyphen (\u0026quot;-\u0026quot;) .\nThe sample demonstrates how to create a WebCenter Portal domain home and associated Kubernetes resources for a domain that has one cluster only. In addition, the sample provides users with the capability to supply their own scripts to create the domain home for other use cases. You can modify the generated domain YAML file to include more use cases.\nCreate the WebCenter Portal Domain The syntax of the create-domain.sh script is as follows:\n $ ./create-domain.sh \\ -i create-domain-inputs.yaml \\ -o /\u0026lt;path to output-directory\u0026gt; The script performs the following functions:\n Creates a directory for the generated Kubernetes YAML files for this domain if it does not already exist. The path name is /\u0026lt;path to output-directory\u0026gt;/weblogic-domains/\u0026lt;domainUID\u0026gt;.If the directory already exists, remove its content before using this script. Creates a Kubernetes job to start the WebCenter Portal Container utility and run offline WLST scripts that create the domain on the shared storage. Runs and waits for the job to finish. Creates a Kubernetes domain YAML file, domain.yaml, in the directory that is created above. This YAML file can be used to create the Kubernetes resource using the kubectl create -f or kubectl apply -f command:  $ kubectl apply -f ../\u0026lt;path to output-directory\u0026gt;/weblogic-domains/\u0026lt;domainUID\u0026gt;/domain.yaml  Creates a convenient utility script, delete-domain-job.yaml, to clean up the domain home created by the create script.    Run the create-domain.sh sample script, pointing it at the create-domain-inputs.yaml inputs file and an output directory like below:\n$ cd \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/ $ sh create-domain.sh -i create-domain-inputs.yaml -o output Input parameters being used export version=\u0026#34;create-weblogic-sample-domain-inputs-v1\u0026#34; export sslEnabled=\u0026#34;false\u0026#34; export adminPort=\u0026#34;7001\u0026#34; export adminServerSSLPort=\u0026#34;7002\u0026#34; export adminServerName=\u0026#34;AdminServer\u0026#34; export domainUID=\u0026#34;wcp-domain\u0026#34; export domainHome=\u0026#34;/u01/oracle/user_projects/domains/$domainUID\u0026#34; export serverStartPolicy=\u0026#34;IF_NEEDED\u0026#34; export clusterName=\u0026#34;wcp-cluster\u0026#34; export configuredManagedServerCount=\u0026#34;5\u0026#34; export initialManagedServerReplicas=\u0026#34;2\u0026#34; export managedServerNameBase=\u0026#34;wcpserver\u0026#34; export managedServerPort=\u0026#34;8888\u0026#34; export managedServerSSLPort=\u0026#34;8889\u0026#34; export image=\u0026#34;oracle/wcportal:12.2.1.4\u0026#34; export imagePullPolicy=\u0026#34;IfNotPresent\u0026#34; export productionModeEnabled=\u0026#34;true\u0026#34; export weblogicCredentialsSecretName=\u0026#34;wcpinfra-domain-credentials\u0026#34; export includeServerOutInPodLog=\u0026#34;true\u0026#34; export logHome=\u0026#34;/u01/oracle/user_projects/domains/logs/$domainUID\u0026#34; export httpAccessLogInLogHome=\u0026#34;true\u0026#34; export t3ChannelPort=\u0026#34;30012\u0026#34; export exposeAdminT3Channel=\u0026#34;false\u0026#34; export adminNodePort=\u0026#34;30701\u0026#34; export exposeAdminNodePort=\u0026#34;false\u0026#34; export namespace=\u0026#34;wcpns\u0026#34; javaOptions=-Dweblogic.StdoutDebugEnabled=false export persistentVolumeClaimName=\u0026#34;wcp-domain-domain-pvc\u0026#34; export domainPVMountPath=\u0026#34;/u01/oracle/user_projects/domains\u0026#34; export createDomainScriptsMountPath=\u0026#34;/u01/weblogic\u0026#34; export createDomainScriptName=\u0026#34;create-domain-job.sh\u0026#34; export createDomainFilesDir=\u0026#34;wlst\u0026#34; export rcuSchemaPrefix=\u0026#34;WCP1\u0026#34; export rcuDatabaseURL=\u0026#34;oracle-db.wcpns.svc.cluster.local:1521/devpdb.k8s\u0026#34; export rcuCredentialsSecret=\u0026#34;wcpinfra-rcu-credentials\u0026#34; export loadBalancerHostName=\u0026#34;abc.def.com\u0026#34; export loadBalancerPortNumber=\u0026#34;30305\u0026#34; export loadBalancerProtocol=\u0026#34;http\u0026#34; export loadBalancerType=\u0026#34;traefik\u0026#34; export unicastPort=\u0026#34;50000\u0026#34; Generating output/weblogic-domains/wcp-domain/create-domain-job.yaml Generating output/weblogic-domains/wcp-domain/delete-domain-job.yaml Generating output/weblogic-domains/wcp-domain/domain.yaml Checking to see if the secret wcpinfra-domain-credentials exists in namespace wcpns configmap/wcp-domain-create-wcp-infra-sample-domain-job-cm created Checking the configmap wcp-domain-create-wcp-infra-sample-domain-job-cm was created configmap/wcp-domain-create-wcp-infra-sample-domain-job-cm labeled Checking if object type job with name wcp-domain-create-wcp-infra-sample-domain-job exists Deleting wcp-domain-create-wcp-infra-sample-domain-job using output/weblogic-domains/wcp-domain/create-domain-job.yaml job.batch \u0026#34;wcp-domain-create-wcp-infra-sample-domain-job\u0026#34; deleted $loadBalancerType is NOT empty Creating the domain by creating the job output/weblogic-domains/wcp-domain/create-domain-job.yaml job.batch/wcp-domain-create-wcp-infra-sample-domain-job created Waiting for the job to complete... status on iteration 1 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Running status on iteration 2 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Running status on iteration 3 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Running status on iteration 4 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Running status on iteration 5 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Running status on iteration 6 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Running status on iteration 7 of 20 pod wcp-domain-create-wcp-infra-sample-domain-job-b5l6c status is Completed Domain wcp-domain was created and will be started by the WebLogic Kubernetes Operator The following files were generated: output/weblogic-domains/wcp-domain/create-domain-inputs.yaml output/weblogic-domains/wcp-domain/create-domain-job.yaml output/weblogic-domains/wcp-domain/domain.yaml Completed   To monitor the above domain creation logs:\n$ kubectl get pods -n wcpns |grep wcp-domain-create wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 1/1 Running 0 6s $ kubectl get pods -n wcpns | grep wcp-domain-create | awk \u0026#39;{print $1}\u0026#39; | xargs kubectl -n wcpns logs -f SAMPLE OUTPUT:\nThe domain will be created using the script /u01/weblogic/create-domain-script.sh Initializing WebLogic Scripting Tool (WLST) ... Welcome to WebLogic Server Administration Scripting Shell Type help() for help on available commands ================================================================= WebCenter Portal Weblogic Operator Domain Creation Script 12.2.1.4.0 ================================================================= Creating Base Domain... Creating Admin Server... Creating cluster... managed server name is wcpserver1 managed server name is wcpserver2 managed server name is wcpserver3 managed server name is wcpserver4 managed server name is wcpserver5 ['wcpserver1', 'wcpserver2', 'wcpserver3', 'wcpserver4', 'wcpserver5'] Managed servers created... Creating Node Manager... Will create Base domain at /u01/oracle/user_projects/domains/wcp-domain Writing base domain... Base domain created at /u01/oracle/user_projects/domains/wcp-domain Extending Domain... Extending domain at /u01/oracle/user_projects/domains/wcp-domain Database oracle-db.wcpns.svc.cluster.local:1521/devpdb.k8s ExposeAdminT3Channel false with 100.111.157.155:30012 Applying JRF templates... Applying WCPortal templates... Extension Templates added... WC_Portal Managed server deleted... Configuring the Service Table DataSource... fmwDatabase jdbc:oracle:thin:@oracle-db.wcpns.svc.cluster.local:1521/devpdb.k8s Getting Database Defaults... Targeting Server Groups... Set CoherenceClusterSystemResource to defaultCoherenceCluster for server:wcpserver1 Set CoherenceClusterSystemResource to defaultCoherenceCluster for server:wcpserver2 Set CoherenceClusterSystemResource to defaultCoherenceCluster for server:wcpserver3 Set CoherenceClusterSystemResource to defaultCoherenceCluster for server:wcpserver4 Set CoherenceClusterSystemResource to defaultCoherenceCluster for server:wcpserver5 Targeting Cluster ... Set CoherenceClusterSystemResource to defaultCoherenceCluster for cluster:wcp-cluster Set WLS clusters as target of defaultCoherenceCluster:wcp-cluster Preparing to update domain... Jan 12, 2021 10:30:09 AM oracle.security.jps.az.internal.runtime.policy.AbstractPolicyImpl initializeReadStore INFO: Property for read store in parallel: oracle.security.jps.az.runtime.readstore.threads = null Domain updated successfully Domain Creation is done... Successfully Completed   Initialize the WebCenter Portal Domain To start the domain, apply the above domain.yaml:\n$ kubectl apply -f output/weblogic-domains/wcp-domain/domain.yaml domain.weblogic.oracle/wcp-domain created Verify the WebCenter Portal Domain Verify that the domain and servers pods and services are created and in the READY state:\nSample run below:\n-bash-4.2$ kubectl get pods -n wcpns -w NAME READY STATUS RESTARTS\tAGE wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 0/1 Completed 0 15m wcp-domain-adminserver 1/1 Running 0 8m9s wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 0/1 Completed 0 3h6m wcp-domain-wcp-server1 0/1 Running 0 6m5s wcp-domain-wcp-server2 0/1 Running 0 6m4s wcp-domain-wcp-server2 1/1 Running 0 6m18s wcp-domain-wcp-server1 1/1 Running 0 6m54s -bash-4.2$ kubectl get all -n wcpns NAME READY STATUS RESTARTS AGE pod/wcp-domain-adminserver 1/1 Running 0 13m pod/wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 0/1 Completed 0 3h12m pod/wcp-domain-wcp-server1 1/1 Running 0 11m pod/wcp-domain-wcp-server2 1/1 Running 0 11m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/wcp-domain-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 13m service/wcp-domain-cluster-wcp-cluster ClusterIP 10.98.145.173 \u0026lt;none\u0026gt; 8888/TCP 11m service/wcp-domain-wcp-server1 ClusterIP None \u0026lt;none\u0026gt; 8888/TCP 11m service/wcp-domain-wcp-server2 ClusterIP None \u0026lt;none\u0026gt; 8888/TCP 11m NAME COMPLETIONS DURATION AGE job.batch/wcp-domain-create-fmw-infra-sample-domain-job 1/1 16m 3h12m To see the Admin and Managed Servers logs, you can check the pod logs:\n$ kubectl logs -f wcp-domain-adminserver -n wcpns $ kubectl logs -f wcp-domain-wcp-server1 -n wcpns Verify the Pods Use the following command to see the pods running the servers:\n$ kubectl get pods -n NAMESPACE Here is an example of the output of this command:\n-bash-4.2$ kubectl get pods -n wcpns NAME READY STATUS RESTARTS AGE rcu 1/1 Running 1 14d wcp-domain-adminserver 1/1 Running 0 16m wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 0/1 Completed 0 3h14m wcp-domain-wcp-server1 1/1 Running 0 14m wcp-domain-wcp-server2 1/1 Running 0 14m Verify the Services Use the following command to see the services for the domain:\n$ kubectl get services -n NAMESPACE Here is an example of the output of this command:\n-bash-4.2$ kubectl get services -n wcpns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE wcp-domain-adminserver ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 17m wcp-domain-cluster-wcp-cluster ClusterIP 10.98.145.173 \u0026lt;none\u0026gt; 8888/TCP 14m wcp-domain-wcp-server1 ClusterIP None \u0026lt;none\u0026gt; 8888/TCP 14m wcp-domain-wcp-server2 ClusterIP None \u0026lt;none\u0026gt; 8888/TCP 14m Managing WebCenter Portal To stop Managed Servers:\n$ kubectl patch domain wcp-domain -n wcpns --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/clusters/0/replicas\u0026#34;, \u0026#34;value\u0026#34;: 0 }]\u0026#39; To start all configured Managed Servers:\n$ kubectl patch domain wcp-domain -n wcpns --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/clusters/0/replicas\u0026#34;, \u0026#34;value\u0026#34;: 3 }]\u0026#39; -bash-4.2$ kubectl get pods -n wcpns -w NAME READY STATUS RESTARTS\tAGE wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 0/1 Completed 0 15m wcp-domain-adminserver 1/1 Running 0 8m9s wcp-domain-create-fmw-infra-sample-domain-job-8jr6k 0/1 Completed 0 3h6m wcp-domain-wcp-server1 0/1 Running 0 6m5s wcp-domain-wcp-server2 0/1 Running 0 6m4s wcp-domain-wcp-server2 1/1 Running 0 6m18s wcp-domain-wcp-server1 1/1 Running 0 6m54s "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/patch_and_upgrade/upgrade-k8s-cluster/",
	"title": "Upgrade a Kubernetes cluster",
	"tags": [],
	"description": "Upgrade the underlying Kubernetes cluster version in a running WebCenter Content Kubernetes environment.",
	"content": "These instructions describe how to upgrade a Kubernetes cluster created using kubeadm on which an Oracle WebCenter Content domain is deployed. A rolling upgrade approach is used to upgrade nodes (master and worker) of the Kubernetes cluster.\nIt is expected that there will be a down time during the upgrade of the Kubernetes cluster as the nodes need to be drained as part of the upgrade process.\n Prerequisites  Review Prerequisites and ensure that your Kubernetes cluster is ready for upgrade. Make sure your environment meets all prerequisites. Make sure the database used for the WebCenter Content domain deployment is up and running during the upgrade process.  Upgrade the Kubernetes version An upgrade of Kubernetes is supported from one MINOR version to the next MINOR version, or between PATCH versions of the same MINOR. For example, you can upgrade from 1.x to 1.x+1, but not from 1.x to 1.x+2. To upgrade a Kubernetes version, first all the master nodes of the Kubernetes cluster must be upgraded sequentially, followed by the sequential upgrade of each worker node.\n See here for Kubernetes official documentation to upgrade from v1.14.x to v1.15.x. See here for Kubernetes official documentation to upgrade from v1.15.x to v1.16.x. See here for Kubernetes official documentation to upgrade from v1.16.x to v1.17.x. See here for Kubernetes official documentation to upgrade from v1.17.x to v1.18.x.  "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/patch_and_upgrade/",
	"title": "Patch and upgrade",
	"tags": [],
	"description": "",
	"content": "Patch an existing Oracle WebCenter Content image or upgrade the infrastructure, such as upgrading the underlying Kubernetes cluster to a new release and upgrading the WebLogic Kubernetes operator release.\n Patch an image  Create a patched Oracle WebCenter Content image using the WebLogic Image Tool.\n Upgrade an operator release  Upgrade the WebLogic Kubernetes operator release to a newer version.\n Upgrade a Kubernetes cluster  Upgrade the underlying Kubernetes cluster version in a running WebCenter Content Kubernetes environment.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/weblogic-logging-exporter-setup/",
	"title": "Publish logs to Elasticsearch",
	"tags": [],
	"description": "Use the WebLogic Logging Exporter to publish the WebLogic Server logs to Elasticsearch.",
	"content": "The WebLogic Logging Exporter adds a log event handler to WebLogic Server. WebLogic Server logs can be pushed to Elasticsearch in Kubernetes directly by using the Elasticsearch REST API. For more details, see to the WebLogic Logging Exporter project.\nThis sample shows you how to publish WebLogic Server logs to Elasticsearch and view them in Kibana. For publishing operator logs, see this sample.\nPrerequisites This document assumes that you have already set up Elasticsearch and Kibana for logs collection. If you have not, please see this document.\n Download the WebLogic Logging Exporter binaries The pre-built binaries are available on the WebLogic Logging Exporter Releases page.\nDownload:\n weblogic-logging-exporter-1.0.0.jar from the Releases page. snakeyaml-1.25.jar from Maven Central.  These identifiers are used in the sample commands in this document.\n wccns: WebCenter Content domain namespace wccinfra: domainUID wccinfra-adminserver: Administration Server pod name   Copy the JAR Files to the WebLogic Domain Home Copy the weblogic-logging-exporter-1.0.0.jar and snakeyaml-1.25.jar files to the domain home directory in the Administration Server pod.\n$ kubectl cp \u0026lt;file-to-copy\u0026gt; \u0026lt;namespace\u0026gt;/\u0026lt;Administration-Server-pod\u0026gt;:\u0026lt;domainhome\u0026gt; $ kubectl cp weblogic-logging-exporter-1.0.0.jar wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/ $ kubectl cp snakeyaml-1.25.jar wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/ Add a Startup Class to the Domain Configuration In this step, we configure weblogic-logging-exporter JAR as a startup class in the WebLogic servers where we intend to collect the logs.\n  In the WebLogic Server Administration Console, in the left navigation pane, expand Environment, and then select Startup and Shutdown Classes.\n  Add a new startup class. You may choose any descriptive name, however, the class name must be weblogic.logging.exporter.Startup.\n  Target the startup class to each server from which you want to export logs.\n  You can verify this by checking for the update in your config.xml file(/u01/oracle/user_projects/domains/wccinfra/config/config.xml) which should be similar to this example:\n$ kubectl exec -n wccns -it wccinfra-adminserver cat /u01/oracle/user_projects/domains/wccinfra/config/config.xml \u0026lt;startup-class\u0026gt; \u0026lt;name\u0026gt;weblogic-logging-exporter\u0026lt;/name\u0026gt; \u0026lt;target\u0026gt;AdminServer,ucm_cluster,ibr_cluster\u0026lt;/target\u0026gt; \u0026lt;class-name\u0026gt;weblogic.logging.exporter.Startup\u0026lt;/class-name\u0026gt; \u0026lt;/startup-class\u0026gt;   Update the WebLogic Server CLASSPATH   Copy the setDomainEnv.sh file from the pod to a local folder:\n$ kubectl cp wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/bin/setDomainEnv.sh $PWD/setDomainEnv.sh tar: Removing leading `/' from member names Ignore exception: tar: Removing leading '/' from member names\n  Modify setDomainEnv.sh to update the Server Class path, add below code at the end of file:\nCLASSPATH=/u01/oracle/user_projects/domains/wccinfra/weblogic-logging-exporter-1.0.0.jar:/u01/oracle/user_projects/domains/wccinfra/snakeyaml-1.25.jar:${CLASSPATH} export CLASSPATH   Copy back the modified setDomainEnv.sh file to the pod:\n$ kubectl cp setDomainEnv.sh wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/bin/setDomainEnv.sh ``\n  Create a Configuration File for the WebLogic Logging Exporter In this step, we will be creating the configuration file for weblogic-logging-exporter.\n  Specify the Elasticsearch server host and port number in file kubernetes/samples/scripts/create-wcc-domain/utils/weblogic-logging-exporter/WebLogicLoggingExporter.yaml:\nExample:\nweblogicLoggingIndexName: wls publishHost: elasticsearch.default.svc.cluster.local publishPort: 9200 domainUID: wccinfra weblogicLoggingExporterEnabled: true weblogicLoggingExporterSeverity: Notice weblogicLoggingExporterBulkSize: 2 weblogicLoggingExporterFilters: - FilterExpression: NOT(MSGID = 'BEA-000449')   Copy the WebLogicLoggingExporter.yaml file to the domain home directory in the WebLogic Administration Server pod:\n$ kubectl cp kubernetes/samples/scripts/create-wcc-domain/utils/weblogic-logging-exporter/WebLogicLoggingExporter.yaml wccns/wccinfra-adminserver:/u01/oracle/user_projects/domains/wccinfra/config/   Restart All the Servers in the Domain To restart the servers, stop and then start them using the following commands:\nTo STOP the servers: $ kubectl patch domain wccinfra -n wccns --type='json' -p='[{\u0026quot;op\u0026quot;: \u0026quot;replace\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/spec/serverStartPolicy\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;NEVER\u0026quot; }]' To START the servers: $ kubectl patch domain wccinfra -n wccns --type='json' -p='[{\u0026quot;op\u0026quot;: \u0026quot;replace\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/spec/serverStartPolicy\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;IF_NEEDED\u0026quot; }]' After all the servers are restarted, see their server logs to check that the weblogic-logging-exporter class is called, as shown below:\n======================= Weblogic Logging Exporter Startup class called ================== Reading configuration from file name: /u01/oracle/user_projects/domains/wccinfra/config/WebLogicLoggingExporter.yaml Config{weblogicLoggingIndexName='wls', publishHost='elasticsearch.default.svc.cluster.local', publishPort=9200, weblogicLoggingExporterSeverity='Notice', weblogicLoggingExporterBulkSize='1', enabled=true, weblogicLoggingExporterFilters=[ FilterConfig{expression='NOT(MSGID = 'BEA-000449')', servers=[]}], domainUID='wccinfra'} ====================== WebLogic Logging Exporter is ebled ================= publishHost in initialize: elasticsearch.default.svc.cluster.local ================= publishPort in initialize: 9200 ================= url in executePutOrPostOnUrl: http://elasticsearch.default.svc.cluster.local:9200/wls Create an Index Pattern in Kibana Create an index pattern wls* in Kibana \u0026gt; Management. After the servers are started, you will see the log data in the Kibana dashboard:\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/",
	"title": "Administration Guide",
	"tags": [],
	"description": "Describes how to use some common utility tools and configurations to administer  WebCenter Portal domain.",
	"content": "Administer Oracle WebCenter Portal domain in Kubernetes.\n Set up a load balancer  Configure different load balancers for the Oracle WebCenter Portal domain.\n Monitor a domain and publish logs  Monitor Oracle WebCenter Portal and publishing logs to Elasticsearch.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/create-or-update-image/",
	"title": "Create or update an image",
	"tags": [],
	"description": "Create or update an Oracle WebCenter Portal Docker image used for deploying Oracle WebCenter Portal domains. An Oracle WebCenter Portal Docker image can be created using the WebLogic Image Tool or using the Dockerfile approach.",
	"content": "You can build an Oracle WebCenter Portal image for production deployments with patches (bundle or interim) using the WebLogic Image Tool, you must have access to the My Oracle Support (MOS) to download (bundle or interim) patches.\n Create or update an Oracle WebCenter Portal Docker image using the WebLogic Image Tool  Set up the WebLogic Image Tool Create an image Update an image   Create an Oracle WebCenter Portal Docker image using Dockerfile  Create or update an Oracle WebCenter Portal Docker image using the WebLogic Image Tool Using the WebLogic Image Tool, you can create a new Oracle WebCenter Portal Docker image (can include patches as well) or update an existing image with one or more patches (bundle patch and interim patches).\n Recommendations:\n Use create for creating a new Oracle WebCenter Portal Docker image:  without any patches or, containing the Oracle WebCenter Portal binaries, bundle , and interim patches. This is the recommended approach if you have access to the Oracle WebCenter Portal patches because it optimizes the size of the image.   Use update for patching an existing Oracle WebCenter Portal Docker image with a single interim patch. Note that the patched image size may increase considerably due to additional image layers introduced by the patch application tool.    Prerequisites Set up the WebLogic Image Tool Validate the setup WebLogic Image Tool build directory WebLogic Image Tool cache Set up additional build scripts  Prerequisites Verify that your environment meets the following prerequisites:\n Docker client and daemon on the build machine, with minimum Docker version 18.03.1.ce. Bash version 4.0 or later, to enable the command complete feature. JAVA_HOME environment variable set to the appropriate JDK location.  Set up the WebLogic Image Tool To set up the WebLogic Image Tool:\n  Create a working directory and change to it. In these steps, this directory is imagetool-setup.\n$ mkdir imagetool-setup $ cd imagetool-setup   Download the latest version of the WebLogic Image Tool from the releases page.\n  Unzip the release ZIP file to the imagetool-setup directory.\n  Execute the following commands to set up the WebLogic Image Tool on a Linux environment:\n$ cd imagetool-setup/imagetool/bin $ source setup.sh   Validate the setup To validate the setup of the WebLogic Image Tool:\n  Enter the following command to retrieve the version of the WebLogic Image Tool:\n$ imagetool --version   Enter imagetool then press the Tab key to display the available imagetool commands:\n$ imagetool \u0026lt;TAB\u0026gt; cache create help rebase update   WebLogic Image Tool build directory The WebLogic Image Tool creates a temporary Docker context directory, prefixed by wlsimgbuilder_temp, every time the tool runs. Under normal circumstances, this context directory is deleted. However, if the process is aborted or the tool is unable to remove the directory, it is safe for you to delete it manually. By default, the WebLogic Image Tool creates the Docker context directory under the user\u0026rsquo;s home directory. If you prefer to use a different directory for the temporary context, set the environment variable WLSIMG_BLDDIR:\n$ export WLSIMG_BLDDIR=\u0026#34;/path/to/buid/dir\u0026#34; WebLogic Image Tool cache The WebLogic Image Tool maintains a local file cache store. This store is used to look up where the Java, WebLogic Server installers, and WebLogic Server patches reside in the local file system. By default, the cache store is located in the user\u0026rsquo;s $HOME/cache directory. Under this directory, the lookup information is stored in the .metadata file. All automatically downloaded patches also reside in this directory. You can change the default cache store location by setting the environment variable WLSIMG_CACHEDIR:\n$ export WLSIMG_CACHEDIR=\u0026#34;/path/to/cachedir\u0026#34; Set up additional build scripts To create an Oracle WebCenter Portal Docker image using the WebLogic Image Tool, additional container scripts for Oracle WebCenter Portal domains are required.\n  Clone the docker-images repository to set up those scripts. In these steps, this directory is DOCKER_REPO:\n$ cd imagetool-setup $ git clone https://github.com/oracle/docker-images.git   Copy the additional WebLogic Image Tool build files from the operator source repository to the imagetool-setup location:\n$ mkdir -p imagetool-setup/docker-images/OracleWebCenterPortal/imagetool/12.2.1.4.0 $ cd imagetool-setup/docker-images/OracleWebCenterPortal/imagetool/12.2.1.4.0 $ cp -rf ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/imagetool-scripts/* .    Note: To create the image, continue with the following steps. To update the image, see update an image.\n Create an image After setting up the WebLogic Image Tool and configuring the required build scripts, create a new Oracle WebCenter Portal Docker image using the WebLogic Image Tool as described ahead.\nDownload the Oracle WebCenter Portal installation binaries and patches You must download the required Oracle WebCenter Portal installation binaries and patches listed below from the Oracle Software Delivery Cloud and save them in a directory of your choice. In these steps, the directory is download location.\nThe installation binaries and patches required for release 21.2.3 are:\n  JDK:\n jdk-8u281-linux-x64.tar.gz    Fusion Middleware Infrastructure installer:\n fmw_12.2.1.4.0_infrastructure.jar    WCP installers:\n fmw_12.2.1.4.0_wcportal.jar    Fusion Middleware Infrastructure patches:\n p28186730_139425_Generic.zip (OPatch) p32253037_122140_Generic.zip(WLS) p31544353_122140_Linux-x86-64.zip(WLS ADR Patch) p32124456_122140_Generic.zip(Bundle patch for Oracle Coherence Version 12.2.1.4.7) p31666198_122140_Generic.zip(OPSS Bundle Patch 12.2.1.4.200724) p32357288_122140_Generic.zip(ADF BUNDLE PATCH 12.2.1.4.210107)    WCP patches:\n p32224021_122140_Generic.zip(WCP BUNDLE PATCH 12.2.1.4.201126) p31852495_122140_Generic.zip(WEBCENTER CORE BUNDLE PATCH 12.2.1.4.200905))    Update required build files The following files in the code repository location \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterPortal/imagetool/12.2.1.4.0 are used for creating the image:\n additionalBuildCmds.txt buildArgs    In the buildArgs file, update all occurrences of %DOCKER_REPO% with the docker-images repository location, which is the complete path of \u0026lt;imagetool-setup-location\u0026gt;/docker-images.\nFor example, update:\n%DOCKER_REPO%/OracleWebCenterPortal/imagetool/12.2.1.4.0/\nto:\n\u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterPortal/imagetool/12.2.1.4.0/\n  Similarly, update the placeholders %JDK_VERSION% and %BUILDTAG% with appropriate values.\n  Update the response file \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleFMWInfrastructure/dockerfiles/12.2.1.4/install.file to add the parameter INSTALL_TYPE=\u0026quot;Fusion Middleware Infrastructure\u0026quot; in the [GENERIC] section.\n  Create the image   Add a JDK package to the WebLogic Image Tool cache:\n$ imagetool cache addInstaller --type jdk --version 8u281 --path \u0026lt;download location\u0026gt;/jdk-8u281-linux-x64.tar.gz   Add the downloaded installation binaries to the WebLogic Image Tool cache:\n$ imagetool cache addInstaller --type fmw --version 12.2.1.4.0 --path \u0026lt;download location\u0026gt;/fmw_12.2.1.4.0_infrastructure.jar $ imagetool cache addInstaller --type wcp --version 12.2.1.4.0 --path \u0026lt;download location\u0026gt;/fmw_12.2.1.4.0_wcportal.jar   Add the downloaded OPatch patch to the WebLogic Image Tool cache:\n$ imagetool cache addEntry --key 28186730_13.9.4.2.5 --value \u0026lt;download location\u0026gt;/p28186730_139425_Generic.zip   Append the --opatchBugNumber flag and the OPatch patch key to the create command in the buildArgs file:\n--opatchBugNumber 28186730_13.9.4.2.5   Add the downloaded product patches to the WebLogic Image Tool cache:\n$ imagetool cache addEntry --key 32253037_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p32253037_122140_Generic.zip $ imagetool cache addEntry --key 32124456_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p32124456_122140_Generic.zip $ imagetool cache addEntry --key 32357288_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p32357288_122140_Generic.zip $ imagetool cache addEntry --key 32224021_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p32224021_122140_Generic.zip $ imagetool cache addEntry --key 31666198_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p31666198_122140_Generic.zip $ imagetool cache addEntry --key 31544353_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p31544353_122140_Linux-x86-64.zip $ imagetool cache addEntry --key 31852495_12.2.1.4.0 --value \u0026lt;download location\u0026gt;/p31852495_122140_Generic.zip   Append the --patches flag and the product patch keys to the create command in the buildArgs file. The --patches list must be a comma-separated collection of patch --key values used in the imagetool cache addEntry commands above.\nSample --patches list for the product patches added in to the cache:\n--patches 32253037_12.2.1.4.0,32124456_12.2.1.4.0,32357288_12.2.1.4.0,32224021_12.2.1.4.0 Example buildArgs file after appending the OPatch patch and product patches:\ncreate --jdkVersion=8u281 --type wcp --version=12.2.1.4.0 --tag=oracle/wcportal:12.2.1.4 --pull --additionalBuildCommands \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterPortal/imagetool/12.2.1.4.0/additionalBuildCmds.txt --additionalBuildFiles \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterPortal/dockerfiles/12.2.1.4/container-scripts --opatchBugNumber 28186730_13.9.4.2.5 --patches 32253037_12.2.1.4.0,32124456_12.2.1.4.0,32357288_12.2.1.4.0,32224021_12.2.1.4.0,31666198_12.2.1.4.0,31544353_12.2.1.4.0,31852495_12.2.1.4.0  Note: In the buildArgs file:\n --jdkVersion value must match the --version value used in the imagetool cache addInstaller command for --type jdk. --version value must match the --version value used in the imagetool cache addInstaller command for --type wcp. --pull always pulls the latest base Linux image oraclelinux:7-slim from the Docker registry. This flag can be removed if you want to use the Linux image oraclelinux:7-slim, which is already available on the host where the WCP image is created.   Refer to this page for the complete list of options available with the WebLogic Image Tool create command.\n  Create the Oracle WebCenter Portal image:\n$ imagetool @\u0026lt;absolute path to buildargs file\u0026gt;  Note: Make sure that the absolute path to the buildargs file is prepended with a @ character, as shown in the example above.\n For example:\n$ imagetool @\u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterPortal/imagetool/12.2.1.4.0/buildArgs    Click here to see the sample Dockerfile generated with the imagetool command.    ########## BEGIN DOCKERFILE ########## # # Copyright (c) 2019, 2021, Oracle and/or its affiliates. # # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # FROM ghcr.io/oracle/oraclelinux:7-slim as os_update LABEL com.oracle.weblogic.imagetool.buildid=\u0026quot;dabe3ff7-ec35-4b8d-b62a-c3c02fed5571\u0026quot; USER root RUN yum -y --downloaddir=/tmp/imagetool install gzip tar unzip libaio jq hostname procps sudo zip \\ \u0026amp;\u0026amp; yum -y --downloaddir=/tmp/imagetool clean all \\ \u0026amp;\u0026amp; rm -rf /var/cache/yum/* \\ \u0026amp;\u0026amp; rm -rf /tmp/imagetool ## Create user and group RUN if [ -z \u0026quot;$(getent group oracle)\u0026quot; ]; then hash groupadd \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; groupadd oracle || exit -1 ; fi \\ \u0026amp;\u0026amp; if [ -z \u0026quot;$(getent passwd oracle)\u0026quot; ]; then hash useradd \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; useradd -g oracle oracle || exit -1; fi \\ \u0026amp;\u0026amp; mkdir -p /u01 \\ \u0026amp;\u0026amp; chown oracle:oracle /u01 \\ \u0026amp;\u0026amp; chmod 775 /u01 # Install Java FROM os_update as jdk_build LABEL com.oracle.weblogic.imagetool.buildid=\u0026quot;dabe3ff7-ec35-4b8d-b62a-c3c02fed5571\u0026quot; ENV JAVA_HOME=/u01/jdk COPY --chown=oracle:oracle jdk-8u251-linux-x64.tar.gz /tmp/imagetool/ USER oracle RUN tar xzf /tmp/imagetool/jdk-8u251-linux-x64.tar.gz -C /u01 \\ \u0026amp;\u0026amp; $(test -d /u01/jdk* \u0026amp;\u0026amp; mv /u01/jdk* /u01/jdk || mv /u01/graal* /u01/jdk) \\ \u0026amp;\u0026amp; rm -rf /tmp/imagetool \\ \u0026amp;\u0026amp; rm -f /u01/jdk/javafx-src.zip /u01/jdk/src.zip # Install Middleware FROM os_update as wls_build LABEL com.oracle.weblogic.imagetool.buildid=\u0026quot;dabe3ff7-ec35-4b8d-b62a-c3c02fed5571\u0026quot; ENV JAVA_HOME=/u01/jdk \\ ORACLE_HOME=/u01/oracle \\ OPATCH_NO_FUSER=true RUN mkdir -p /u01/oracle \\ \u0026amp;\u0026amp; mkdir -p /u01/oracle/oraInventory \\ \u0026amp;\u0026amp; chown oracle:oracle /u01/oracle/oraInventory \\ \u0026amp;\u0026amp; chown oracle:oracle /u01/oracle COPY --from=jdk_build --chown=oracle:oracle /u01/jdk /u01/jdk/ COPY --chown=oracle:oracle fmw_12.2.1.4.0_infrastructure.jar fmw.rsp /tmp/imagetool/ COPY --chown=oracle:oracle fmw_12.2.1.4.0_wcportal.jar wcp.rsp /tmp/imagetool/ COPY --chown=oracle:oracle oraInst.loc /u01/oracle/ COPY --chown=oracle:oracle p28186730_139425_Generic.zip /tmp/imagetool/opatch/ COPY --chown=oracle:oracle patches/* /tmp/imagetool/patches/ USER oracle RUN echo \u0026quot;INSTALLING MIDDLEWARE\u0026quot; \\ \u0026amp;\u0026amp; echo \u0026quot;INSTALLING fmw\u0026quot; \\ \u0026amp;\u0026amp; \\ /u01/jdk/bin/java -Xmx1024m -jar /tmp/imagetool/fmw_12.2.1.4.0_infrastructure.jar -silent ORACLE_HOME=/u01/oracle \\ -responseFile /tmp/imagetool/fmw.rsp -invPtrLoc /u01/oracle/oraInst.loc -ignoreSysPrereqs -force -novalidation \\ \u0026amp;\u0026amp; echo \u0026quot;INSTALLING wcp\u0026quot; \\ \u0026amp;\u0026amp; \\ /u01/jdk/bin/java -Xmx1024m -jar /tmp/imagetool/fmw_12.2.1.4.0_wcportal.jar -silent ORACLE_HOME=/u01/oracle \\ -responseFile /tmp/imagetool/wcp.rsp -invPtrLoc /u01/oracle/oraInst.loc -ignoreSysPrereqs -force -novalidation \\ \u0026amp;\u0026amp; chmod -R g+r /u01/oracle RUN cd /tmp/imagetool/opatch \\ \u0026amp;\u0026amp; /u01/jdk/bin/jar -xf /tmp/imagetool/opatch/p28186730_139425_Generic.zip \\ \u0026amp;\u0026amp; /u01/jdk/bin/java -jar /tmp/imagetool/opatch/6880880/opatch_generic.jar -silent -ignoreSysPrereqs -force -novalidation oracle_home=/u01/oracle # Apply all patches provided at the same time RUN /u01/oracle/OPatch/opatch napply -silent -oh /u01/oracle -phBaseDir /tmp/imagetool/patches \\ \u0026amp;\u0026amp; test $? -eq 0 \\ \u0026amp;\u0026amp; /u01/oracle/OPatch/opatch util cleanup -silent -oh /u01/oracle \\ || (cat /u01/oracle/cfgtoollogs/opatch/opatch*.log \u0026amp;\u0026amp; exit 1) FROM os_update as final_build ARG ADMIN_NAME ARG ADMIN_HOST ARG ADMIN_PORT ARG MANAGED_SERVER_PORT ENV ORACLE_HOME=/u01/oracle \\ JAVA_HOME=/u01/jdk \\ PATH=${PATH}:/u01/jdk/bin:/u01/oracle/oracle_common/common/bin:/u01/oracle/wlserver/common/bin:/u01/oracle LABEL com.oracle.weblogic.imagetool.buildid=\u0026quot;dabe3ff7-ec35-4b8d-b62a-c3c02fed5571\u0026quot; COPY --from=jdk_build --chown=oracle:oracle /u01/jdk /u01/jdk/ COPY --from=wls_build --chown=oracle:oracle /u01/oracle /u01/oracle/ USER oracle WORKDIR /u01/oracle #ENTRYPOINT /bin/bash ENV ORACLE_HOME=/u01/oracle \\ SCRIPT_FILE=/u01/oracle/container-scripts/* \\ USER_MEM_ARGS=\u0026quot;-Djava.security.egd=file:/dev/./urandom\u0026quot; \\ PATH=$PATH:/usr/java/default/bin:/u01/oracle/oracle_common/common/bin:/u01/oracle/wlserver/common/bin:/u01/oracle/container-scripts USER root RUN env \u0026amp;\u0026amp; \\ mkdir -p /u01/oracle/container-scripts \u0026amp;\u0026amp; \\ mkdir -p /u01/oracle/logs \u0026amp;\u0026amp; \\ mkdir -p /u01/esHome/esNode \u0026amp;\u0026amp; \\ chown oracle:oracle -R /u01 $VOLUME_DIR \u0026amp;\u0026amp; \\ chmod a+xr /u01 COPY --chown=oracle:oracle files/container-scripts/ /u01/oracle/container-scripts/ RUN chmod +xr $SCRIPT_FILE \u0026amp;\u0026amp; \\ rm /u01/oracle/oracle_common/lib/ons.jar /u01/oracle/oracle_common/modules/oracle.jdbc/simplefan.jar USER oracle EXPOSE $WCPORTAL_PORT $ADMIN_PORT WORKDIR ${ORACLE_HOME} CMD [\u0026quot;/u01/oracle/container-scripts/configureOrStartAdminServer.sh\u0026quot;] ########## END DOCKERFILE ##########      Check the created image using the docker images command:\n$ docker images | grep wcportal   Update an image After setting up the WebLogic Image Tool and configuring the build scripts, use the WebLogic Image Tool to update an existing Oracle WebCenter Portal Docker image:\n  Enter the following command to add the OPatch patch to the WebLogic Image Tool cache:\n$ imagetool cache addEntry --key 28186730_13.9.4.2.5 --value \u0026lt;downloaded-patches-location\u0026gt;/p28186730_139425_Generic.zip   Execute the imagetool cache addEntry command for each patch to add the required patch(es) to the WebLogic Image Tool cache. For example, to add patch p30761841_122140_Generic.zip:\n$ imagetool cache addEntry --key=32224021_12.2.1.4.0 --value \u0026lt;downloaded-patches-location\u0026gt;/p32224021_122140_Generic.zip   Provide the following arguments to the WebLogic Image Tool update command:\n –-fromImage - Identify the image that needs to be updated. In the example below, the image to be updated is oracle/wcportal:12.2.1.4. –-patches - Multiple patches can be specified as a comma-separated list. --tag - Specify the new tag to be applied for the image being built.  Refer here for the complete list of options available with the WebLogic Image Tool update command.\n Note: The WebLogic Image Tool cache should have the latest OPatch zip. The WebLogic Image Tool updates the OPatch if it is not already updated in the image.\n Examples   Click here to see the example of update command:    $ imagetool update --fromImage oracle/wcportal:12.2.1.4 --tag=wcportal:12.2.1.4-32224021 --patches=32224021_12.2.1.4.0 [INFO ] Image Tool build ID: 50f9b9aa-596c-4bae-bdff-c47c16b4c928 [INFO ] Temporary directory used for docker build context: /scratch/asirasag/imagetoolcache/builddir/wlsimgbuilder_temp5130105621506307568 [INFO ] Using patch 28186730_13.9.4.2.5 from cache: /home/asirasag/imagetool-setup/jars/p28186730_139425_Generic.zip [INFO ] Updating OPatch in final image from version 13.9.4.2.1 to version 13.9.4.2.5 [WARNING] Skipping patch conflict check, no support credentials provided [WARNING] No credentials provided, skipping validation of patches [INFO ] Using patch 32224021_12.2.1.4 from cache: /home/asirasag/imagetool-setup/jars/p32224021_122140_Generic.zip [INFO ] docker cmd = docker build --no-cache --force-rm --tag wcportal:12.2.1.4-32224021 --build-arg http_proxy=http://www-proxy.us.oracle.com:80 --build-arg https_proxy=http://www-proxy.us.oracle.com:80 --build-arg no_proxy=localhost,127.0.0.0/8,.us.oracle.com,.oraclecorp.com,/var/run/docker.sock,100.111.157.155 /scratch/asirasag/imagetoolcache/builddir/wlsimgbuilder_temp5130105621506307568 Sending build context to Docker daemon 192.4MB Step 1/9 : FROM oracle/wcportal:12.2.1.4 as final_build ---\u0026gt; 5592ff7e5a02 Step 2/9 : USER root ---\u0026gt; Running in 0b3ff2600f11 Removing intermediate container 0b3ff2600f11 ---\u0026gt; faad3a32f39c Step 3/9 : ENV OPATCH_NO_FUSER=true ---\u0026gt; Running in 2beab0bfe88b Removing intermediate container 2beab0bfe88b ---\u0026gt; 6fd9e1664818 Step 4/9 : LABEL com.oracle.weblogic.imagetool.buildid=\u0026quot;50f9b9aa-596c-4bae-bdff-c47c16b4c928\u0026quot; ---\u0026gt; Running in 9a5f8fc172c9 Removing intermediate container 9a5f8fc172c9 ---\u0026gt; 499620a1f857 Step 5/9 : USER oracle ---\u0026gt; Running in fe28af056858 Removing intermediate container fe28af056858 ---\u0026gt; 3507971c35d5 Step 6/9 : COPY --chown=oracle:oracle p28186730_139425_Generic.zip /tmp/imagetool/opatch/ ---\u0026gt; c44c3c7b17f7 Step 7/9 : RUN cd /tmp/imagetool/opatch \u0026amp;\u0026amp; /u01/jdk/bin/jar -xf /tmp/imagetool/opatch/p28186730_139425_Generic.zip \u0026amp;\u0026amp; /u01/jdk/bin/java -jar /tmp/imagetool/opatch/6880880/opatch_generic.jar -silent -ignoreSysPrereqs -force -novalidation oracle_home=/u01/oracle \u0026amp;\u0026amp; rm -rf /tmp/imagetool ---\u0026gt; Running in 8380260fe62d Launcher log file is /tmp/OraInstall2021-04-08_05-18-14AM/launcher2021-04-08_05-18-14AM.log. Extracting the installer . . . . Done Checking if CPU speed is above 300 MHz. Actual 2195.098 MHz Passed Checking swap space: must be greater than 512 MB. Actual 14999 MB Passed Checking if this platform requires a 64-bit JVM. Actual 64 Passed (64-bit not required) Checking temp space: must be greater than 300 MB. Actual 152772 MB Passed Preparing to launch the Oracle Universal Installer from /tmp/OraInstall2021-04-08_05-18-14AM Installation Summary Disk Space : Required 34 MB, Available 152,736 MB Feature Sets to Install: Next Generation Install Core 13.9.4.0.1 OPatch 13.9.4.2.5 OPatch Auto OPlan 13.9.4.2.5 Session log file is /tmp/OraInstall2021-04-08_05-18-14AM/install2021-04-08_05-18-14AM.log Loading products list. Please wait. 1% 40% Loading products. Please wait. 98% 99% Updating Libraries Starting Installations 1% 94% 95% 96% Install pending Installation in progress Component : oracle.glcm.logging 1.6.4.0.0 Copying files for oracle.glcm.logging 1.6.4.0.0 Component : oracle.glcm.comdev 7.8.4.0.0 Copying files for oracle.glcm.comdev 7.8.4.0.0 Component : oracle.glcm.dependency 1.8.4.0.0 Copying files for oracle.glcm.dependency 1.8.4.0.0 Component : oracle.glcm.xmldh 3.4.4.0.0 Copying files for oracle.glcm.xmldh 3.4.4.0.0 Component : oracle.glcm.wizard 7.8.4.0.0 Copying files for oracle.glcm.wizard 7.8.4.0.0 Component : oracle.glcm.opatch.common.api 13.9.4.0.0 Copying files for oracle.glcm.opatch.common.api 13.9.4.0.0 Component : oracle.nginst.common 13.9.4.0.0 Copying files for oracle.nginst.common 13.9.4.0.0 Component : oracle.nginst.core 13.9.4.0.0 Copying files for oracle.nginst.core 13.9.4.0.0 Component : oracle.glcm.encryption 2.7.4.0.0 Copying files for oracle.glcm.encryption 2.7.4.0.0 Component : oracle.swd.opatch 13.9.4.2.5 Copying files for oracle.swd.opatch 13.9.4.2.5 Component : oracle.glcm.osys.core 13.9.1.0.0 Copying files for oracle.glcm.osys.core 13.9.1.0.0 Component : oracle.glcm.oplan.core 13.9.4.2.0 Copying files for oracle.glcm.oplan.core 13.9.4.2.0 Install successful Post feature install pending Post Feature installing Feature Set : glcm_common_lib Feature Set : glcm_common_logging_lib Post Feature installing glcm_common_lib Post Feature installing glcm_common_logging_lib Feature Set : commons-cli_1.3.1.0.0 Post Feature installing commons-cli_1.3.1.0.0 Feature Set : oracle.glcm.opatch.common.api.classpath Post Feature installing oracle.glcm.opatch.common.api.classpath Feature Set : glcm_encryption_lib Post Feature installing glcm_encryption_lib Feature Set : oracle.glcm.osys.core.classpath Post Feature installing oracle.glcm.osys.core.classpath Feature Set : oracle.glcm.oplan.core.classpath Post Feature installing oracle.glcm.oplan.core.classpath Feature Set : oracle.glcm.opatchauto.core.classpath Post Feature installing oracle.glcm.opatchauto.core.classpath Feature Set : oracle.glcm.opatchauto.core.binary.classpath Post Feature installing oracle.glcm.opatchauto.core.binary.classpath Feature Set : oracle.glcm.opatchauto.core.actions.classpath Post Feature installing oracle.glcm.opatchauto.core.actions.classpath Feature Set : oracle.glcm.opatchauto.core.wallet.classpath Post Feature installing oracle.glcm.opatchauto.core.wallet.classpath Post feature install complete String substitutions pending String substituting Component : oracle.glcm.logging 1.6.4.0.0 String substituting oracle.glcm.logging 1.6.4.0.0 Component : oracle.glcm.comdev 7.8.4.0.0 String substituting oracle.glcm.comdev 7.8.4.0.0 Component : oracle.glcm.dependency 1.8.4.0.0 String substituting oracle.glcm.dependency 1.8.4.0.0 Component : oracle.glcm.xmldh 3.4.4.0.0 String substituting oracle.glcm.xmldh 3.4.4.0.0 Component : oracle.glcm.wizard 7.8.4.0.0 String substituting oracle.glcm.wizard 7.8.4.0.0 Component : oracle.glcm.opatch.common.api 13.9.4.0.0 String substituting oracle.glcm.opatch.common.api 13.9.4.0.0 Component : oracle.nginst.common 13.9.4.0.0 String substituting oracle.nginst.common 13.9.4.0.0 Component : oracle.nginst.core 13.9.4.0.0 String substituting oracle.nginst.core 13.9.4.0.0 Component : oracle.glcm.encryption 2.7.4.0.0 String substituting oracle.glcm.encryption 2.7.4.0.0 Component : oracle.swd.opatch 13.9.4.2.5 String substituting oracle.swd.opatch 13.9.4.2.5 Component : oracle.glcm.osys.core 13.9.1.0.0 String substituting oracle.glcm.osys.core 13.9.1.0.0 Component : oracle.glcm.oplan.core 13.9.4.2.0 String substituting oracle.glcm.oplan.core 13.9.4.2.0 String substitutions complete Link pending Linking in progress Component : oracle.glcm.logging 1.6.4.0.0 Linking oracle.glcm.logging 1.6.4.0.0 Component : oracle.glcm.comdev 7.8.4.0.0 Linking oracle.glcm.comdev 7.8.4.0.0 Component : oracle.glcm.dependency 1.8.4.0.0 Linking oracle.glcm.dependency 1.8.4.0.0 Component : oracle.glcm.xmldh 3.4.4.0.0 Linking oracle.glcm.xmldh 3.4.4.0.0 Component : oracle.glcm.wizard 7.8.4.0.0 Linking oracle.glcm.wizard 7.8.4.0.0 Component : oracle.glcm.opatch.common.api 13.9.4.0.0 Linking oracle.glcm.opatch.common.api 13.9.4.0.0 Component : oracle.nginst.common 13.9.4.0.0 Linking oracle.nginst.common 13.9.4.0.0 Component : oracle.nginst.core 13.9.4.0.0 Linking oracle.nginst.core 13.9.4.0.0 Component : oracle.glcm.encryption 2.7.4.0.0 Linking oracle.glcm.encryption 2.7.4.0.0 Component : oracle.swd.opatch 13.9.4.2.5 Linking oracle.swd.opatch 13.9.4.2.5 Component : oracle.glcm.osys.core 13.9.1.0.0 Linking oracle.glcm.osys.core 13.9.1.0.0 Component : oracle.glcm.oplan.core 13.9.4.2.0 Linking oracle.glcm.oplan.core 13.9.4.2.0 Linking in progress Link successful Setup pending Setup in progress Component : oracle.glcm.logging 1.6.4.0.0 Setting up oracle.glcm.logging 1.6.4.0.0 Component : oracle.glcm.comdev 7.8.4.0.0 Setting up oracle.glcm.comdev 7.8.4.0.0 Component : oracle.glcm.dependency 1.8.4.0.0 Setting up oracle.glcm.dependency 1.8.4.0.0 Component : oracle.glcm.xmldh 3.4.4.0.0 Setting up oracle.glcm.xmldh 3.4.4.0.0 Component : oracle.glcm.wizard 7.8.4.0.0 Setting up oracle.glcm.wizard 7.8.4.0.0 Component : oracle.glcm.opatch.common.api 13.9.4.0.0 Setting up oracle.glcm.opatch.common.api 13.9.4.0.0 Component : oracle.nginst.common 13.9.4.0.0 Setting up oracle.nginst.common 13.9.4.0.0 Component : oracle.nginst.core 13.9.4.0.0 Setting up oracle.nginst.core 13.9.4.0.0 Component : oracle.glcm.encryption 2.7.4.0.0 Setting up oracle.glcm.encryption 2.7.4.0.0 Component : oracle.swd.opatch 13.9.4.2.5 Setting up oracle.swd.opatch 13.9.4.2.5 Component : oracle.glcm.osys.core 13.9.1.0.0 Setting up oracle.glcm.osys.core 13.9.1.0.0 Component : oracle.glcm.oplan.core 13.9.4.2.0 Setting up oracle.glcm.oplan.core 13.9.4.2.0 Setup successful Save inventory pending Saving inventory 97% Saving inventory complete 98% Configuration complete Component : glcm_common_logging_lib Saving the inventory glcm_common_logging_lib Component : glcm_encryption_lib Component : oracle.glcm.opatch.common.api.classpath Saving the inventory oracle.glcm.opatch.common.api.classpath Saving the inventory glcm_encryption_lib Component : cieCfg_common_rcu_lib Component : glcm_common_lib Saving the inventory cieCfg_common_rcu_lib Saving the inventory glcm_common_lib Component : oracle.glcm.logging Saving the inventory oracle.glcm.logging Component : cieCfg_common_lib Saving the inventory cieCfg_common_lib Component : svctbl_lib Saving the inventory svctbl_lib Component : com.bea.core.binxml_dependencies Saving the inventory com.bea.core.binxml_dependencies Component : svctbl_jmx_client Saving the inventory svctbl_jmx_client Component : cieCfg_wls_shared_lib Saving the inventory cieCfg_wls_shared_lib Component : rcuapi_lib Saving the inventory rcuapi_lib Component : rcu_core_lib Saving the inventory rcu_core_lib Component : cieCfg_wls_lib Saving the inventory cieCfg_wls_lib Component : cieCfg_wls_external_lib Saving the inventory cieCfg_wls_external_lib Component : cieCfg_wls_impl_lib Saving the inventory cieCfg_wls_impl_lib Component : rcu_dependencies_lib Saving the inventory rcu_dependencies_lib Component : oracle.fmwplatform.fmwprov_lib Saving the inventory oracle.fmwplatform.fmwprov_lib Component : fmwplatform-wlst-dependencies Saving the inventory fmwplatform-wlst-dependencies Component : oracle.fmwplatform.ocp_lib Saving the inventory oracle.fmwplatform.ocp_lib Component : oracle.fmwplatform.ocp_plugin_lib Saving the inventory oracle.fmwplatform.ocp_plugin_lib Component : wlst.wls.classpath Saving the inventory wlst.wls.classpath Component : maven.wls.classpath Saving the inventory maven.wls.classpath Component : com.oracle.webservices.fmw.ws-assembler Saving the inventory com.oracle.webservices.fmw.ws-assembler Component : sdpmessaging_dependencies Saving the inventory sdpmessaging_dependencies Component : sdpclient_dependencies Saving the inventory sdpclient_dependencies Component : com.oracle.jersey.fmw.client Saving the inventory com.oracle.jersey.fmw.client Component : com.oracle.webservices.fmw.client Saving the inventory com.oracle.webservices.fmw.client Component : oracle.jrf.wls.classpath Saving the inventory oracle.jrf.wls.classpath Component : oracle.jrf.wlst Saving the inventory oracle.jrf.wlst Component : fmwshare-wlst-dependencies Saving the inventory fmwshare-wlst-dependencies Component : oracle.fmwshare.pyjar Saving the inventory oracle.fmwshare.pyjar Component : com.oracle.webservices.wls.jaxws-owsm-client Saving the inventory com.oracle.webservices.wls.jaxws-owsm-client Component : glcm_common_logging_lib Component : glcm_common_lib Saving the inventory glcm_common_lib Component : glcm_encryption_lib Saving the inventory glcm_encryption_lib Component : oracle.glcm.opatch.common.api.classpath Saving the inventory oracle.glcm.opatch.common.api.classpath Component : cieCfg_common_rcu_lib Saving the inventory cieCfg_common_rcu_lib Saving the inventory glcm_common_logging_lib Component : oracle.glcm.logging Saving the inventory oracle.glcm.logging Component : cieCfg_common_lib Saving the inventory cieCfg_common_lib Component : svctbl_lib Saving the inventory svctbl_lib Component : com.bea.core.binxml_dependencies Saving the inventory com.bea.core.binxml_dependencies Component : svctbl_jmx_client Saving the inventory svctbl_jmx_client Component : cieCfg_wls_shared_lib Saving the inventory cieCfg_wls_shared_lib Component : rcuapi_lib Saving the inventory rcuapi_lib Component : rcu_core_lib Saving the inventory rcu_core_lib Component : cieCfg_wls_lib Saving the inventory cieCfg_wls_lib Component : cieCfg_wls_external_lib Saving the inventory cieCfg_wls_external_lib Component : cieCfg_wls_impl_lib Saving the inventory cieCfg_wls_impl_lib Component : soa_com.bea.core.binxml_dependencies Saving the inventory soa_com.bea.core.binxml_dependencies Component : glcm_common_logging_lib Saving the inventory glcm_common_logging_lib Component : glcm_common_lib Saving the inventory glcm_common_lib Component : glcm_encryption_lib Saving the inventory glcm_encryption_lib Component : oracle.glcm.opatch.common.api.classpath Component : oracle.glcm.oplan.core.classpath Saving the inventory oracle.glcm.oplan.core.classpath Saving the inventory oracle.glcm.opatch.common.api.classpath The install operation completed successfully. Logs successfully copied to /u01/oracle/.inventory/logs. Removing intermediate container 8380260fe62d ---\u0026gt; d57be7ffa162 Step 8/9 : COPY --chown=oracle:oracle patches/* /tmp/imagetool/patches/ ---\u0026gt; dd421aae5aaf Step 9/9 : RUN /u01/oracle/OPatch/opatch napply -silent -oh /u01/oracle -phBaseDir /tmp/imagetool/patches \u0026amp;\u0026amp; test $? -eq 0 \u0026amp;\u0026amp; /u01/oracle/OPatch/opatch util cleanup -silent -oh /u01/oracle || (cat /u01/oracle/cfgtoollogs/opatch/opatch*.log \u0026amp;\u0026amp; exit 1) ---\u0026gt; Running in 323e7ae70339 Oracle Interim Patch Installer version 13.9.4.2.5 Copyright (c) 2021, Oracle Corporation. All rights reserved. Oracle Home : /u01/oracle Central Inventory : /u01/oracle/.inventory from : /u01/oracle/oraInst.loc OPatch version : 13.9.4.2.5 OUI version : 13.9.4.0.0 Log file location : /u01/oracle/cfgtoollogs/opatch/opatch2021-04-08_05-20-25AM_1.log OPatch detects the Middleware Home as \u0026quot;/u01/oracle\u0026quot; Verifying environment and performing prerequisite checks... OPatch continues with these patches: 32224021 Do you want to proceed? [y|n] Y (auto-answered by -silent) User Responded with: Y All checks passed. Please shutdown Oracle instances running out of this ORACLE_HOME on the local system. (Oracle Home = '/u01/oracle') Is the local system ready for patching? [y|n] Y (auto-answered by -silent) User Responded with: Y Backing up files... Applying interim patch '32224021' to OH '/u01/oracle' ApplySession: Optional component(s) [ oracle.webcenter.sca, 12.2.1.4.0 ] , [ oracle.webcenter.sca, 12.2.1.4.0 ] , [ oracle.webcenter.ucm, 12.2.1.4.0 ] , [ oracle.webcenter.ucm, 12.2.1.4.0 ] not present in the Oracle Home or a higher version is found. Patching component oracle.webcenter.portal, 12.2.1.4... Patching component oracle.webcenter.portal, 12.2.1.4... Patching component oracle.rcu.webcenter.portal, 12.2.1.0... Patching component oracle.rcu.webcenter.portal, 12.2.1.0... Patch 32224021 successfully applied. Log file location: /u01/oracle/cfgtoollogs/opatch/opatch2021-04-08_05-20-25AM_1.log OPatch succeeded. Oracle Interim Patch Installer version 13.9.4.2.5 Copyright (c) 2021, Oracle Corporation. All rights reserved. Oracle Home : /u01/oracle Central Inventory : /u01/oracle/.inventory from : /u01/oracle/oraInst.loc OPatch version : 13.9.4.2.5 OUI version : 13.9.4.0.0 Log file location : /u01/oracle/cfgtoollogs/opatch/opatch2021-04-08_05-27-11AM_1.log OPatch detects the Middleware Home as \u0026quot;/u01/oracle\u0026quot; Invoking utility \u0026quot;cleanup\u0026quot; OPatch will clean up 'restore.sh,make.txt' files and 'scratch,backup' directories. You will be still able to rollback patches after this cleanup. Do you want to proceed? [y|n] Y (auto-answered by -silent) User Responded with: Y Backup area for restore has been cleaned up. For a complete list of files/directories deleted, Please refer log file. OPatch succeeded. Removing intermediate container 323e7ae70339 ---\u0026gt; 0e7c514dcf7b Successfully built 0e7c514dcf7b Successfully tagged wcportal:12.2.1.4-32224021 [INFO ] Build successful. Build time=645s. Image tag=wcportal:12.2.1.4-32224021      Click here to see the example Dockerfile generated by the WebLogic Image Tool with the --dryRun option:    $ imagetool update --fromImage oracle/wcportal:12.2.1.4 --tag=wcportal:12.2.1.4-30761841 --patches=30761841_12.2.1.4.0 --dryRun [INFO ] Image Tool build ID: a473ba32-84b6-4374-9425-9e92ac90ee87 [INFO ] Temporary directory used for docker build context: /scratch/asirasag/imagetoolcache/builddir/wlsimgbuilder_temp874401188519547557 [INFO ] Using patch 28186730_13.9.4.2.5 from cache: /home/asirasag/imagetool-setup/jars/p28186730_139425_Generic.zip [INFO ] Updating OPatch in final image from version 13.9.4.2.1 to version 13.9.4.2.5 [WARNING] Skipping patch conflict check, no support credentials provided [WARNING] No credentials provided, skipping validation of patches [INFO ] Using patch 32224021_12.2.1.4 from cache: /home/asirasag/imagetool-setup/jars/p32224021_122140_Generic.zip [INFO ] docker cmd = docker build --no-cache --force-rm --tag wcportal:12.2.1.4-32224021 --build-arg http_proxy=http://www-proxy.us.oracle.com:80 --build-arg https_proxy=http://www-proxy.us.oracle.com:80 --build-arg no_proxy=localhost,127.0.0.0/8,.us.oracle.com,.oraclecorp.com,/var/run/docker.sock,100.111.157.155 /scratch/asirasag/imagetoolcache/builddir/wlsimgbuilder_temp874401188519547557 ########## BEGIN DOCKERFILE ########## # # Copyright (c) 2019, 2021, Oracle and/or its affiliates. # # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # FROM oracle/wcportal:12.2.1.4 as final_build USER root ENV OPATCH_NO_FUSER=true LABEL com.oracle.weblogic.imagetool.buildid=\u0026quot;a473ba32-84b6-4374-9425-9e92ac90ee87\u0026quot; USER oracle COPY --chown=oracle:oracle p28186730_139425_Generic.zip /tmp/imagetool/opatch/ RUN cd /tmp/imagetool/opatch \\ \u0026amp;\u0026amp; /u01/jdk/bin/jar -xf /tmp/imagetool/opatch/p28186730_139425_Generic.zip \\ \u0026amp;\u0026amp; /u01/jdk/bin/java -jar /tmp/imagetool/opatch/6880880/opatch_generic.jar -silent -ignoreSysPrereqs -force -novalidation oracle_home=/u01/oracle \\ \u0026amp;\u0026amp; rm -rf /tmp/imagetool COPY --chown=oracle:oracle patches/* /tmp/imagetool/patches/ # Apply all patches provided at the same time RUN /u01/oracle/OPatch/opatch napply -silent -oh /u01/oracle -phBaseDir /tmp/imagetool/patches \\ \u0026amp;\u0026amp; test $? -eq 0 \\ \u0026amp;\u0026amp; /u01/oracle/OPatch/opatch util cleanup -silent -oh /u01/oracle \\ || (cat /u01/oracle/cfgtoollogs/opatch/opatch*.log \u0026amp;\u0026amp; exit 1) ########## END DOCKERFILE ##########      Check the built image using the docker images command:\n$ docker images | grep wcportal wcportal 12.2.1.4-30761841 2ef2a67a685b About a minute ago 3.58GB $   Create an Oracle WebCenter Portal Docker image using Dockerfile For test and development purposes, you can create an Oracle WebCenter Portal image using the Dockerfile. Consult the README file for important prerequisite steps, such as building or pulling the Server JRE Docker image, Oracle Fusion Middleware Infrastructure Docker image and downloading the Oracle WebCenter Portal installer and bundle patch binaries.\nA prebuilt Oracle Fusion Middleware Infrastructure image, container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4, is available at container-registry.oracle.com. We recommend that you pull and rename this image to build the Oracle WebCenter Portal image.\n$ docker pull container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4 $ docker tag container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4 oracle/fmw-infrastructure:12.2.1.4 To build an Oracle Fusion Middleware Infrastructure image and on top of that the Oracle WebCenter Portal image as a layer, follow these steps:\n  Make a local clone of the sample repository:\n$ git clone https://github.com/oracle/docker-images   Download the Oracle WebCenter Portal installer from the Oracle Technology Network or e-delivery.\n Note: Copy the installer binaries to the same location as the Dockerfile.\n   Create the Oracle WebCenter Portal image by running the provided script:\n$ cd docker-images/OracleWebCenterPortal/dockerfiles $ ./buildDockerImage.sh -v 12.2.1.4 -s The image produced is named oracle/wcportal:12.2.1.4. The samples and instructions assume the Oracle WebCenter Portal image is named oracle/wcportal:12.2.1.4. You must rename your image to match this name, or update the samples to refer to the image you created.\n  "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/manage-wcportal-domains/configure-load-balancer/apachewebtier/",
	"title": "Apache webtier",
	"tags": [],
	"description": "Configure the Apache webtier load balancer for an Oracle WebCenter Portal domain.",
	"content": "To load balance Oracle WebCenter Portal domain clusters, you can install Apache webtier and configure it for non-SSL and SSL termination access of the application URL. Follow these steps to set up Apache webtier as a load balancer for an Oracle WebCenter Portal domain in a Kubernetes cluster:\n Build the Apache webtier image Create the Apache plugin configuration file Prepare the certificate and private key Install the Apache webtier Helm chart Verify domain application URL access Uninstall Apache webtier  Build the Apache webtier image To build the Apache webtier Docker image, refer to the sample.\nCreate the Apache plugin configuration file  The configuration file named custom_mod_wl_apache.conf should have all the URL routing rules for the Oracle WebCenter Portal applications deployed in the domain that needs to be accessible externally. Update this file with values based on your environment. The file content is similar to below.    Click here to see the sample content of the configuration file custom_mod_wl_apache.conf for wcp-domain domain   $ cat \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/charts/apache-samples/custom-sample/custom_mod_wl_apache.conf #Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. # # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # \u0026lt;IfModule mod_weblogic.c\u0026gt; WebLogicHost \u0026lt;WEBLOGIC_HOST\u0026gt; WebLogicPort 7001 \u0026lt;/IfModule\u0026gt; # Directive for weblogic admin Console deployed on Weblogic Admin Server \u0026lt;Location /console\u0026gt; SetHandler weblogic-handler WebLogicHost wcp-domain-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; \u0026lt;Location /em\u0026gt; SetHandler weblogic-handler WebLogicHost wcp-domain-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; \u0026lt;Location /webcenter\u0026gt; WLSRequest On WebLogicCluster wcp-domain-cluster-wcp-cluster:8888 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /rsscrawl\u0026gt; WLSRequest On WebLogicCluster wcp-domain-cluster-wcp-cluster:8888 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /rest\u0026gt; WLSRequest On WebLogicCluster wcp-domain-cluster-wcp-cluster:8888 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /webcenterhelp\u0026gt; WLSRequest On WebLogicCluster wcp-domain-cluster-wcp-cluster:8888 PathTrim /weblogic1 \u0026lt;/Location\u0026gt;     Update persistentVolumeClaimName in \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/charts/apache-samples/custom-sample/input.yamlwith Persistence Volume which contains your own custom_mod_wl_apache.conf file. Use the PV/PVC created at the time of preparing environment, Copy the custom_mod_wl_apache.conf file to existing PersistantVolume.  Prepare the certificate and private key   (For the SSL termination configuration only) Run the following commands to generate your own certificate and private key using openssl.\n$ cd \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/charts/apache-samples/custom-sample $ export VIRTUAL_HOST_NAME=WEBLOGIC_HOST $ export SSL_CERT_FILE=WEBLOGIC_HOST.crt $ export SSL_CERT_KEY_FILE=WEBLOGIC_HOST.key $ sh certgen.sh  NOTE: Replace WEBLOGIC_HOST with the name of the host on which Apache webtier is to be installed.\n   Click here to see the output of the certifcate generation   $ls certgen.sh custom_mod_wl_apache.conf custom_mod_wl_apache.conf_orig input.yaml README.md $ sh certgen.sh Generating certs for WEBLOGIC_HOST Generating a 2048 bit RSA private key ........................+++ .......................................................................+++ unable to write \u0026#39;random state\u0026#39; writing new private key to \u0026#39;apache-sample.key\u0026#39; ----- $ ls certgen.sh custom_mod_wl_apache.conf_orig WEBLOGIC_HOST.info config.txt input.yaml WEBLOGIC_HOST.key custom_mod_wl_apache.conf WEBLOGIC_HOST.crt README.md      Prepare input values for the Apache webtier Helm chart.\nRun the following commands to prepare the input value file for the Apache webtier Helm chart.\n$ base64 -i ${SSL_CERT_FILE} | tr -d \u0026#39;\\n\u0026#39; $ base64 -i ${SSL_CERT_KEY_FILE} | tr -d \u0026#39;\\n\u0026#39; $ touch input.yaml Update virtualHostName with the value of the WEBLOGIC_HOST in file \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/charts/apache-samples/custom-sample/input.yaml\n  Click here to see the snapshot of the sample input.yaml file   $ cat apache-samples/custom-sample/input.yaml # Use this to provide your own Apache webtier configuration as needed; simply define this # path and put your own custom_mod_wl_apache.conf file under this path. persistentVolumeClaimName: wcp-domain-domain-pvc # The VirtualHostName of the Apache HTTP server. It is used to enable custom SSL configuration. virtualHostName: \u0026lt;WEBLOGIC_HOST\u0026gt;      Install the Apache webtier Helm chart   Install the Apache webtier Helm chart to the domain wcpns namespace with the specified input parameters:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts $ kubectl create namespace apache-webtier $ helm install apache-webtier --values apache-samples/custom-sample/input.yaml --namespace wcpns apache-webtier --set image=oracle/apache:12.2.1.3   Check the status of the Apache webtier:\n$ kubectl get all -n wcpns | grep apache Sample output of the status of the apache webtier:\npod/apache-webtier-apache-webtier-65f69dc6bc-zg5pj 1/1 Running 0 22h service/apache-webtier-apache-webtier NodePort 10.108.29.98 \u0026lt;none\u0026gt; 80:30305/TCP,4433:30443/TCP 22h deployment.apps/apache-webtier-apache-webtier 1/1 1 1 22h replicaset.apps/apache-webtier-apache-webtier-65f69dc6bc 1 1 1 22h   Verify domain application URL access Once the Apache webtier load balancer is up, verify that the domain applications are accessible through the load balancer port 30305/30443. The application URLs for domain of type wcp are:\n Note: Port 30305 is the LOADBALANCER-Non-SSLPORT and Port 30443 is LOADBALANCER-SSLPORT.\n Non-SSL configuration http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenter http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/webcenterhelp http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rest http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/rsscrawl SSL configuration https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenter https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rsscrawl https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/webcenterhelp https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/rest Uninstall Apache webtier $ helm delete apache-webtier -n wcpns "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/appendix/additional-configuration/",
	"title": "Additional Configuration",
	"tags": [],
	"description": "Describes how to create connections to Oracle WebCenter Content Server to enable content integration within Oracle WebCenter Portal.",
	"content": "Creating a Connection to Oracle WebCenter Content Server To enable content integration within Oracle WebCenter Portal create a connection to Oracle WebCenter Content Server using JAX-WS. Follow the steps in the documentation link to create the connection.\n Note: If the Oracle WebCenter Content Server is configured with SSL, before creating the connection, the SSL certificate should be imported into any location under mount path of domain persistent volume to avoid loss of certificate due pod restart.\n Import SSL Certificate Import the certificate using below sample command, update the keystore location to a directory under mount path of the domain persistent volume :\n$ kubectl exec -it wcp-domain-adminserver -n wcpns /bin/bash $ cd $JAVA_HOME/bin $ ./keytool -importcert -alias collab_cert -file /filepath/sslcertificate/contentcert.crt -keystore /u01/oracle/user_projects/domains/wcp-domain/DemoTrust.jks Update the TrustStore To update the truststore location edit domain.yaml file, append -Djavax.net.ssl.trustStore to the spec.serverPod.env.JAVA_OPTIONS environment variable value. The truststore location used in -Djavax.net.ssl.trustStore option should be same as keystore location where the SSL certificate has been imported.\nserverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026#34;-Dweblogic.StdoutDebugEnabled=true -Dweblogic.ssl.Enabled=true -Dweblogic.security.SSL.ignoreHostnameVerification=true -Djavax.net.ssl.trustStore=/u01/oracle/user_projects/domains/wcp-domain/DemoTrust.jks\u0026#34; - name: USER_MEM_ARGS value: \u0026#34;-Djava.security.egd=file:/dev/./urandom -Xms256m -Xmx1024m \u0026#34; volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wcp-domain-domains-pvc volumeMounts: - mountPath: /u01/oracle/user_projects/domains name: weblogic-domain-storage-volume Apply the domain.yaml file to restart the Oracle WebCenter Portal domain.\n$ kubectl apply -f domain.yaml "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/configure-load-balancer/apache/",
	"title": "Apache webtier",
	"tags": [],
	"description": "Configure the Apache webtier load balancer for Oracle WebCenter Content domain.",
	"content": "This section provides information about how to install and configure Apache webtier to load balance Oracle WebCenter Content domain clusters. You can configure Apache webtier for non-SSL and SSL termination access of the application URL.\nFollow these steps to set up Apache webtier as a load balancer for an Oracle WebCenter Content domain in a Kubernetes cluster:\n Build the Apache webtier image Create the Apache plugin configuration file Prepare the certificate and private key Install the Apache webtier Helm chart Verify domain application URL access Uninstall Apache webtier  Build the Apache webtier image Refer to the sample, to build the Apache webtier Docker image.\nCreate the Apache plugin configuration file  The configuration file named custom_mod_wl_apache.conf should have all the URL routing rules for the Oracle WebCenter Content application deployed in the domain that needs to be accessible externally. Update this file with values based on your environment. The file content is similar to below mentioned sample.    Click here to see the sample content of the configuration file custom_mod_wl_apache.conf for Oracle WebCenter Content domain   # Copyright (c) 2018, 2020, Oracle Corporation and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. \u0026lt;IfModule mod_weblogic.c\u0026gt; WebLogicHost \u0026lt;WEBLOGIC_HOST\u0026gt; WebLogicPort 7001 \u0026lt;/IfModule\u0026gt; # Directive for weblogic admin Console deployed on Weblogic Admin Server \u0026lt;Location /console\u0026gt; SetHandler weblogic-handler WebLogicHost wccinfra-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; \u0026lt;Location /em\u0026gt; SetHandler weblogic-handler WebLogicHost wccinfra-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; \u0026lt;Location /weblogic/ready\u0026gt; SetHandler weblogic-handler WebLogicHost wccinfra-adminserver WebLogicPort 7001 \u0026lt;/Location\u0026gt; # Directive for all application deployed on weblogic cluster with a prepath defined by LOCATION variable # For example, if the LOCAITON is set to \u0026#39;/weblogic\u0026#39;, all applications deployed on the cluster can be accessed via # http://myhost:myport/weblogic/application_end_url # where \u0026#39;myhost\u0026#39; is the IP of the machine that runs the Apache web tier, and # \u0026#39;myport\u0026#39; is the port that the Apache web tier is publicly exposed to. # Note that LOCATION cannot be set to \u0026#39;/\u0026#39; unless this is the only Location module configured. \u0026lt;Location /cs\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ucm-cluster:16200 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /adfAuthentication\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ucm-cluster:16200 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /ibr\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ibr-cluster:16250 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; \u0026lt;Location /ibr/adfAuthentication\u0026gt; WLSRequest On WebLogicCluster wccinfra-cluster-ibr-cluster:16250 PathTrim /weblogic1 \u0026lt;/Location\u0026gt; # Directive for all application deployed on weblogic cluster with a prepath defined by LOCATION2 variable # For example, if the LOCAITON2 is set to \u0026#39;/weblogic2\u0026#39;, all applications deployed on the cluster can be accessed via # http://myhost:myport/weblogic2/application_end_url # where \u0026#39;myhost\u0026#39; is the IP of the machine that runs the Apache web tier, and # \u0026#39;myport\u0026#39; is the port that the Apache webt ier is publicly exposed to. #\u0026lt;Location /weblogic2\u0026gt; #WLSRequest On #WebLogicCluster domain2-cluster-cluster-1:8021 #PathTrim /weblogic2 #\u0026lt;/Location\u0026gt;     Update persistentVolumeClaimName with your PV-claim-name which contains your custom_mod_wl_apache.conf in file kubernetes/samples/charts/apache-samples/custom-sample/input.yaml.  Prepare the certificate and private key   (For the SSL termination configuration only) Run the following commands to generate your own certificate and private key using openssl.\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ cd kubernetes/samples/charts/apache-samples/custom-sample $ export VIRTUAL_HOST_NAME=WEBLOGIC_HOST $ export SSL_CERT_FILE=WEBLOGIC_HOST.crt $ export SSL_CERT_KEY_FILE=WEBLOGIC_HOST.key $ sh certgen.sh  NOTE: Replace WEBLOGIC_HOST with the host name on which Apache webtier is to be installed.\n   Click here to see the output of the certifcate generation   $ls certgen.sh custom_mod_wl_apache.conf custom_mod_wl_apache.conf_orig input.yaml README.md $ sh certgen.sh Generating certs for WEBLOGIC_HOST Generating a 2048 bit RSA private key ........................+++ .......................................................................+++ unable to write \u0026#39;random state\u0026#39; writing new private key to \u0026#39;apache-sample.key\u0026#39; ----- $ ls certgen.sh custom_mod_wl_apache.conf_orig WEBLOGIC_HOST.info config.txt input.yaml WEBLOGIC_HOST.key custom_mod_wl_apache.conf WEBLOGIC_HOST.crt README.md      Prepare input values for the Apache webtier Helm chart.\nRun the following commands to prepare the input value file for the Apache webtier Helm chart.\n$ base64 -i ${SSL_CERT_FILE} | tr -d \u0026#39;\\n\u0026#39; $ base64 -i ${SSL_CERT_KEY_FILE} | tr -d \u0026#39;\\n\u0026#39; $ touch input.yaml Update virtualHostName with the value of the WEBLOGIC_HOST in file kubernetes/samples/charts/apache-samples/custom-sample/input.yaml\n  Click here to see the snapshot of the sample input.yaml file   $ cat apache-samples/custom-sample/input.yaml # Use this to provide your own Apache webtier configuration as needed; simply define this # path and put your own custom_mod_wl_apache.conf file under this path. persistentVolumeClaimName: \u0026lt;pv-claim-name\u0026gt; # The VirtualHostName of the Apache HTTP server. It is used to enable custom SSL configuration. virtualHostName: \u0026lt;WEBLOGIC_HOST\u0026gt;      Install the Apache webtier Helm chart   Install the Apache webtier Helm chart to the domain wccns namespace with the specified input parameters:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/charts $ kubectl create namespace apache-webtier $ helm install apache-webtier --values apache-samples/custom-sample/input.yaml --namespace wccns apache-webtier --set image=oracle/apache:12.2.1.3   Check the status of the Apache webtier:\n$ kubectl get all -n wccns | grep apache Sample output of the status of the apache webtier:\n  pod/apache-webtier-new-apache-webtier-65d8d7c59f-k27wf 1/1 Running 0 9d service/apache-webtier-new-apache-webtier NodePort 10.108.12.143 \u0026lt;none\u0026gt; 80:30505/TCP,4433:30453/TCP 9d deployment.apps/apache-webtier-new-apache-webtier 1/1 1 1 9d replicaset.apps/apache-webtier-new-apache-webtier-65d8d7c59f 1 1 1 9d Verify domain application URL access Post the Apache webtier load balancer is up, verify that the domain applications are accessible through the load balancer port 30505/30453. The application URLs for domain of type wcc are:\n Note: Port 30505 is the LOADBALANCER-Non-SSLPORT and Port 30453 is LOADBALANCER-SSLPORT.\n Non-SSL configuration http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/weblogic/ready http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/console http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/em http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/cs http://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-Non-SSLPORT}/ibr SSL configuration https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/weblogic/ready https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/console https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/em https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/cs https://${LOADBALANCER-HOSTNAME}:${LOADBALANCER-SSLPORT}/ibr Uninstall Apache webtier $ helm delete apache-webtier -n wccns "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/installguide/configure-wcp-search/",
	"title": "Configure WebCenter Portal For Search",
	"tags": [],
	"description": "Set up search functionality in Oracle WebCenter Portal using Elasticsearch.",
	"content": " Introduction Set Up Persistent Volume and Persistent Volume Claim Create a Secret Headless Service LoadBalancer LoadBalancer Validation Elasticsearch Cluster Deployment Validation  Introduction Elasticsearch is a highly scalable search engine. It allows you to store, search, and analyze big volumes of data quickly and provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON document.\nSet Up Persistent Volume and Persistent Volume Claim Create a Kubernetes PV and PVC (Persistent Volume and Persistent Volume Claim) to store Elasticsearch data. To create PV and PVC, use the deployment YAML configuration file located at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-es-cluster/es-pvpvc.yaml.\napiVersion: v1 kind: PersistentVolume metadata: name: es-data-pv namespace: wcpns spec: storageClassName: es-data-pv-storage-class capacity: storage: 10Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain hostPath: path: \u0026#34;/scratch/esdata\u0026#34; --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-data-pvc namespace: wcpns spec: storageClassName: es-data-pv-storage-class accessModes: - ReadWriteMany resources: requests: storage: 10Gi To create PV \u0026amp; PVC run the below command:\n$ kubectl apply -f es-pvpvc.yaml Create a Secret To grant access to Oracle WebCenter Portal, create a Kubernetes secret using the deployment YAML configuration file located at \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-es-cluster/es-secret.yaml\napiVersion: v1 kind: Secret metadata: name: es-secret namespace: wcpns data: # base64 encoded strings wls-admin: d2VibG9naWM= wls-admin-pwd: d2VsY29tZTE= search-admin: d2NjcmF3bGFkbWlu search-admin-pwd: d2VsY29tZTE= Where: wls-admin :Oracle WebCenter Admin UserName wls-admin-pwd :Oracle WebCenter Admin Password search-admin :ElasticSearch Username search-admin-pwd : ElasticSearch Password  To create Kubernetes Secret run the below command:\n$ kubectl apply -f es-secret.yaml Headless Service Each node in Elasticsearch cluster can communicate using a headless service. Create a headless service using the deployment YAML configuration file located at \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-es-cluster/es-service.yaml to establish cluster communication.\napiVersion: v1 kind: Service metadata: name: es-svc namespace: wcpns labels: service: elasticsearch spec: # headless service clusterIP: None ports: - port: 9200 name: http - port: 9300 name: transport selector: service: elasticsearch To create Headless Service run below command:\n$ kubectl apply -f es-service.yaml LoadBalancer To access the Elasticsearch service outside of the Kubernetes cluster, create an external loadbalancer. Then access the Elasticsearch service by using the external IP of loadbalancer, create a loadbalancer using the deployment YAML configuration file located at \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-es-cluster/es-loadbalancer.yaml.\napiVersion: v1 kind: Service metadata: name: es-loadbalancer namespace: wcpns labels: type: external spec: type: LoadBalancer selector: service: elasticsearch ports: - name: http port: 9200 targetPort: 9200 To create a loadbalancer run below command:\n$ kubectl apply -f es-loadbalancer.yaml LoadBalancer Validation Once the loadbalancer is successfully deployed, validate it by running the following command:\n$ kubectl get svc -n wcpns -l type=external Make a note of the external IP from the above command and use this below sample URL to access Elasticsearch cluster health : http://externalIP:9200/_cluster/health\nElasticsearch Cluster Using the Kubernetes StatefulSet controller create an Elasticsearch Cluster comprising of three node using the deployment YAML configuration file located at \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-es-cluster/es-statefulset.yaml\napiVersion: apps/v1 kind: StatefulSet metadata: name: es-statefulset namespace: wcpns labels: service: elasticsearch spec: serviceName: es-svc replicas: 1 selector: matchLabels: service: elasticsearch template: metadata: labels: service: elasticsearch spec: initContainers: - name: increase-the-vm-max-map-count image: busybox command: - sysctl - -w - vm.max_map_count=262144 securityContext: privileged: true - name: increase-the-ulimit image: busybox command: - sh - -c - ulimit -n 65536 securityContext: privileged: true volumes: - name: es-node persistentVolumeClaim: claimName: es-data-pvc - name: wcp-domain persistentVolumeClaim: claimName: wcp-domain-domain-pvc containers: - name: es-container image: oracle/wcportal:12.2.1.4 imagePullPolicy: IfNotPresent command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;/u01/oracle/container-scripts/configureOrStartElasticsearch.sh\u0026#34; ] readinessProbe: httpGet: path: / port: 9200 httpHeaders: - name: Authorization value: Basic d2NjcmF3bGFkbWluOndlbGNvbWUx initialDelaySeconds: 150 periodSeconds: 30 timeoutSeconds: 10 successThreshold: 1 failureThreshold: 10 lifecycle: preStop: exec: command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;/u01/oracle/container-scripts/elasticsearchPreStopHandler.sh\u0026#34; ] ports: - containerPort: 9200 name: http - containerPort: 9300 name: tcp env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: UNICAST_HOST_LIST value: \u0026#34;es-svc\u0026#34; - name: ADMIN_USERNAME valueFrom: secretKeyRef: name: es-secret key: wls-admin - name: ADMIN_PASSWORD valueFrom: secretKeyRef: name: es-secret key: wls-admin-pwd - name: SEARCH_APP_USERNAME valueFrom: secretKeyRef: name: es-secret key: search-admin - name: SEARCH_APP_USER_PASSWORD valueFrom: secretKeyRef: name: es-secret key: search-admin-pwd - name: ADMIN_SERVER_CONTAINER_NAME value: wcp-domain-adminserver - name: ADMIN_PORT value: \u0026#34;7001\u0026#34; - name: ES_CLUSTER_NAME value: es-cluster - name: DOMAIN_NAME value: wcp-domain - name: CONFIGURE_ES_CONNECTION value: \u0026#34;true\u0026#34; - name: LOAD_BALANCER_IP value: \u0026#34;es-loadbalancer.wcpns.svc.cluster.local\u0026#34; volumeMounts: - name: es-node mountPath: /u01/esHome/esNode - name: wcp-domain mountPath: /u01/oracle/user_projects/domains  Note: The values used for ADMIN_PORT and Image name should be same as values passed to create-domain.sh job while creating domain.\n To create a es-statefulset run below command:\n$ kubectl apply -f es-statefulset.yaml  Note: After setting up Elasticsearch cluster restart all the instance of Oracle WebCenter Portal server.\n Deployment Validation Validate the deployment by running the following command:\n$ kubectl get pods -n wcpns -l service=elasticsearch "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/installguide/additional-steps-to-launch-native-binaries/",
	"title": "Launch Oracle Webcenter Content Native Applications in Containers",
	"tags": [],
	"description": "How to launch Oracle WebCenter Content native binaries from inside containerized environment.",
	"content": "This section provides the steps required to use product native binaries with user interfaces.\nIssue with Launching Headful User Interfaces for Oracle WebCenter Content Native Binaries Oracle WebCenter Content (UCM) provide a set of native binaries with headful UIs, which are located inside the persistent volume, as part of the domain. WebCenter Content container images are, by default, created with Oracle slim linux image, which doesn\u0026rsquo;t come with all the packages pre-installed to support headful applications with UIs to be launched. With current Oracle WebCenter Content container images, running native applications fails, being unable to launch UIs.\nThe following sections document the solution, by providing a set of instructions, enabling users to run UCM native applications with UIs.\nThese instructions are divided in two parts -\n Steps to update the existing container image Steps to launch native apps using VNC sessions  Steps to Update out-of-the-box Oracle WebCenter Content Container Image Using WebLogic Image Tool This section describes the method to update image with a OS package using WebLogic Image Tool. Please refer this for setting up the WebLogic Image Tool.\nAdditional Build Commands The installation of required OS packages in the image, can be done using yum command in additional build command option available in WebLogic Image Tool. Here is the sample additionalBuildCmds.txt file, to be used, to install required Linux packages (libXext.x86_64, libXrender.x86_64 and libXtst.x86_64).\n[final-build-commands] USER root RUN yum -y --downloaddir=/tmp/imagetool install libXext libXrender libXtst \\ \u0026amp;\u0026amp; yum -y --downloaddir=/tmp/imagetool clean all \\ \u0026amp;\u0026amp; rm -rf /var/cache/yum/* \\ \u0026amp;\u0026amp; rm -rf /tmp/imagetool USER oracle  Note: It is important to change the user to oracle, otherwise the user during the container execution will be root.\n Build arguments The arguments required for updating the image can be passed as file to the WebLogic Image Tool.\n'update' is the sub command to Image Tool for updating an existing docker image. '--fromImage' option provides the existing docker image that has to be updated. '--tag' option should be provided with the new tag for the updated image. '--additionalBuildCommands' option should be provided with the above created additional build commands file.  Below is a sample build argument (buildArgs) file, to be used for updating the image,\n update --fromImage \u0026lt;existing_WCContent_image_without_dependent_packages\u0026gt; --tag \u0026lt;name_of_updated_WCContent_image_to_be_built\u0026gt; --additionalBuildCommands ./additionalBuildCmds.txt Update Oracle WebCenter Content Container Image Now we can execute the WebLogic Image Tool to update the out-of-the-box image, using the build-argument file described above -\n$ imagetool @buildArgs WebLogic Image Tool provides multiple options for updating the image. For detailed information on the update options, please refer to this document.\nUpdating the image does not modify the \u0026lsquo;CMD\u0026rsquo; from the source image unless it is modified in the additional build commands.\n$ docker inspect -f '{{.Config.Cmd}}' \u0026lt;name_of_updated_Wccontent_image\u0026gt; [/u01/oracle/container-scripts/createDomainandStartAdmin.sh] Steps to launch Oracle WebCenter Content native applications using VNC sessions. Once updated image is successfully built and available on all required nodes, do the following: a. Update the domain.yaml file with updated image name and apply the domain.yaml file.\n$ kubectl apply -f domain.yaml b. After applying the modified domain.yaml, pods will get restarted and start running with updated image with required packages.\n$ kubectl get pods -n \u0026lt;namespace_being_used_for_wccontent_domain\u0026gt; c. Create VNC sessions on the master node to launch native apps. These are the steps to be followed using the VNC session.\nd. Run this command on each VNC session:\n$ xhost + \u0026lt;HOST-IP or HOST-NAME of the node, on which POD is deployed\u0026gt;  Note: The above command works for multi-node clusters (in which master node and worker nodes are deployed on different hosts and pods are distributed among worker nodes, running on different hosts). In case of single node clusters (where there is only master node and no worker nodes and all pods are deployed on the host, on which master node is running), one needs to use container/pod’s IP instead of the master-node’s HOST-IP itself.\n To obtain the container IP, follow the command mentioned in step g, from within that container\u0026rsquo;s shell.\n$ xhost + \u0026lt;IP of the container, from which binaries are to be run \u0026gt; e. Get into the pod\u0026rsquo;s (for example, wccinfra-ucm-server1) shell:\n$ kubectl exec -n wccns -it wccinfra-ucm-server1 -- /bin/bash f. Traverse to the binaries location:\n$ cd /u01/oracle/user_projects/domains/wccinfra/ucm/cs/bin g. Get the container IP:\n$ hostname -i h. Set DISPLAY variable within the container:\n$ export DISPLAY=\u0026lt;HOST-IP/HOST-NAME of the master node, where VNC session was created\u0026gt;:vnc-session display-id i. Launch any native UCM application, from within the container, like this:\n$ ./SystemProperties If the application has an UI, it will get launched now.\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/create-or-update-image/",
	"title": "Create or update an image",
	"tags": [],
	"description": "Create or update an Oracle WebCenter Content Docker image used for deploying Oracle WebCenter Content domains. An Oracle WebCenter Content Docker image can be created using the WebLogic Image Tool or using the Dockerfile approach.",
	"content": "If you have access to the My Oracle Support (MOS), and there is a need to build a new image with a patch (bundle or interim), it is recommended to use the WebLogic Image Tool to build an Oracle WebCenter Content image for production deployments.\n Create or update an Oracle WebCenter Content Docker image using the WebLogic Image Tool  Set up the WebLogic Image Tool Create an image Update an image   Create an Oracle WebCenter Content Docker image using Dockerfile  Create or update an Oracle WebCenter Content Docker image using the WebLogic Image Tool Using the WebLogic Image Tool, you can create a new Oracle WebCenter Content Docker image (can include patches as well) or update an existing image with one or more patches (bundle patch and interim patches).\n Recommendations:\n Use create for creating a new Oracle WebCenter Content Docker image either:  without any patches or, containing the Oracle WebCenter Content binaries, bundle patch and interim patches. This is the recommended approach if you have access to the Oracle WebCenter Content patches because it optimizes the size of the image.   Use update for patching an existing Oracle WebCenter Content Docker image with a single interim patch. Note that the patched image size may increase considerably due to additional image layers introduced by the patch application tool.   Set up the WebLogic Image Tool  Prerequisites Set up the WebLogic Image Tool Validate setup WebLogic Image Tool build directory WebLogic Image Tool cache Set up additional build scripts  Prerequisites Verify that your environment meets the following prerequisites:\n Docker client and daemon on the build machine, with minimum Docker version 18.03.1.ce. Bash version 4.0 or later, to enable the command complete feature. JAVA_HOME environment variable set to the appropriate JDK location.  Set up the WebLogic Image Tool To set up the WebLogic Image Tool:\n  Create a working directory and change to it. In these steps, this directory is imagetool-setup.\n$ mkdir imagetool-setup $ cd imagetool-setup   Download the latest version of the WebLogic Image Tool from the releases page.\n  Unzip the release ZIP file to the imagetool-setup directory.\n  Execute the following commands to set up the WebLogic Image Tool on a Linux environment:\n$ cd imagetool-setup/imagetool/bin $ source setup.sh   Validate setup To validate the setup of the WebLogic Image Tool:\n  Enter the following command to retrieve the version of the WebLogic Image Tool:\n$ imagetool --version   Enter imagetool then press the Tab key to display the available imagetool commands:\n$ imagetool \u0026lt;TAB\u0026gt; cache create help rebase update   WebLogic Image Tool build directory The WebLogic Image Tool creates a temporary Docker context directory, prefixed by wlsimgbuilder_temp, every time the tool runs. Under normal circumstances, this context directory will be deleted. However, if the process is aborted or the tool is unable to remove the directory, it is safe for you to delete it manually. By default, the WebLogic Image Tool creates the Docker context directory under the user\u0026rsquo;s home directory. If you prefer to use a different directory for the temporary context, set the environment variable WLSIMG_BLDDIR:\n$ export WLSIMG_BLDDIR=\u0026#34;/path/to/buid/dir\u0026#34; WebLogic Image Tool cache The WebLogic Image Tool maintains a local file cache store. This store is used to look up where the Java, WebLogic Server installers, and WebLogic Server patches reside in the local file system. By default, the cache store is located in the user\u0026rsquo;s $HOME/cache directory. Under this directory, the lookup information is stored in the .metadata file. All automatically downloaded patches also reside in this directory. You can change the default cache store location by setting the environment variable WLSIMG_CACHEDIR:\n$ export WLSIMG_CACHEDIR=\u0026#34;/path/to/cachedir\u0026#34; Set up additional build scripts Creating an Oracle WebCenter Content Docker image using the WebLogic Image Tool requires additional container scripts for Oracle WebCenter Content domains.\n  Clone the docker-images repository to set up those scripts. In these steps, this directory is DOCKER_REPO:\n$ cd imagetool-setup $ git clone https://github.com/oracle/docker-images.git   Copy the additional WebLogic Image Tool build files from the operator source repository to the imagetool-setup location:\n$ mkdir -p imagetool-setup/docker-images/WebCenterContent/imagetool/12.2.1.4.0 $ cd imagetool-setup/docker-images/WebCenterContent/imagetool/12.2.1.4.0 $ cp -rf ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/imagetool-scripts/* .   Create an image After setting up the WebLogic Image Tool and required build scripts, follow these steps to use the WebLogic Image Tool to create a new Oracle WebCenter Content Docker image.\nDownload the Oracle WebCenter Content installation binaries and patches You must download the required Oracle WebCenter Content installation binaries and patches as listed below from the Oracle Software Delivery Cloud and save them in a directory of your choice. In these steps, this directory is download location.\n  Click here to see the sample list of installation binaries and patches:     JDK:\n jdk-8u251-linux-x64.tar.gz    Fusion MiddleWare Infrastructure installer:\n fmw_12.2.1.4.0_infrastructure_generic.jar    WebCenter Content installers:\n fmw_12.2.1.4.0_wccontent.jar    Fusion MiddleWare Infrastructure patches:\n p28186730_139424_Generic-23574493.zip (Opatch)    WebCenter Content patches:\n p31390302_122140_Generic.zip (wcc)       Note: This is a sample list of patches. You must get the appropriate list of patches for your Oracle WebCenter Content image.\n Update required build files The following files available in the code repository location \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/imagetool/12.2.1.4.0 are used for creating the image.\n additionalBuildCmds.txt buildArgs    In the buildArgs file, update all the occurrences of %DOCKER_REPO% with the docker-images repository location, which is the complete path of imagetool-setup/docker-images.\nFor example, update:\n%DOCKER_REPO%/OracleWebCenterContent/imagetool/12.2.1.4.0/\nto:\n\u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/imagetool/12.2.1.4.0/\n  Similarly, update the placeholders %JDK_VERSION% and %BUILDTAG% with appropriate values.\n  Create the image   Add a JDK package to the WebLogic Image Tool cache:\n$ imagetool cache addInstaller --type jdk --version 8u251 --path \u0026lt;download location\u0026gt;/jdk-8u251-linux-x64.tar.gz   Add the downloaded installation binaries to the WebLogic Image Tool cache:\n$ imagetool cache addInstaller --type fmw --version 12.2.1.4.0 --path \u0026lt;download location\u0026gt;/fmw_12.2.1.4.0_infrastructure.jar $ imagetool cache addInstaller --type wcc --version 12.2.1.4.0 --path \u0026lt;download location\u0026gt;/fmw_12.2.1.4.0_wccontent.jar   Add the downloaded patches to the WebLogic Image Tool cache:\n  Click here to see the commands to add patches in to the cache:   ``` bash $ imagetool cache addEntry --key 31390302_12.2.1.4.0 --path \u0026lt;download location\u0026gt;/p31390302_122140_Generic.zip $ imagetool cache addEntry --key 28186730_13.9.4.2.4 --path \u0026lt;download location\u0026gt;/p28186730_139424_Generic-23574493.zip ```      Update the patches list to buildArgs.\nTo the create command in the buildArgs file, append the Oracle WebCenter Content patches list using the --patches flag and Opatch patch using the --opatchBugNumber flag. Sample options for the list of patches above are:\n--patches 31754672_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.4 Example buildArgs file after appending product\u0026rsquo;s list of patches and Opatch patch:\ncreate --jdkVersion=8u251 --type WCC --version=12.2.1.4.0 --tag=oracle/wccontent_create_1015:12.2.1.4.0 --pull --chown oracle:root --additionalBuildCommands \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/imagetool/12.2.1.4.0/additionalBuildCmds.txt --additionalBuildFiles \u0026lt;imagetool-setup-location\u0026gt;/docker-images/OracleWebCenterContent/dockerfiles/12.2.1.4.0/container-scripts --patches 31754672_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.4 Refer to this page for the complete list of options available with the WebLogic Image Tool create command.\n  Enter the following command to create the Oracle WebCenter Content image:\n$ imagetool @\u0026lt;absolute path to `buildargs` file\u0026gt;\u0026#34;     Click here to see the sample Dockerfile generated with the imagetool command.   ########## BEGIN DOCKERFILE ########## # # Copyright (c) 2019, 2021, Oracle and/or its affiliates. # # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. # # FROM ghcr.io/oracle/oraclelinux:7-slim as os_update LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; USER root RUN yum -y --downloaddir=/tmp/imagetool install gzip tar unzip libaio jq hostname \\  \u0026amp;\u0026amp; yum -y --downloaddir=/tmp/imagetool clean all \\  \u0026amp;\u0026amp; rm -rf /var/cache/yum/* \\  \u0026amp;\u0026amp; rm -rf /tmp/imagetool ## Create user and group RUN if [ -z \u0026#34;$(getent group root)\u0026#34; ]; then hash groupadd \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; groupadd root || exit -1 ; fi \\  \u0026amp;\u0026amp; if [ -z \u0026#34;$(getent passwd oracle)\u0026#34; ]; then hash useradd \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; useradd -g root oracle || exit -1; fi \\  \u0026amp;\u0026amp; mkdir -p /u01 \\  \u0026amp;\u0026amp; chown oracle:root /u01 \\  \u0026amp;\u0026amp; chmod 775 /u01 # Install Java FROM os_update as jdk_build LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; ENV JAVA_HOME=/u01/jdk COPY --chown=oracle:root jdk-8u251-linux-x64.tar.gz /tmp/imagetool/ USER oracle RUN tar xzf /tmp/imagetool/jdk-8u251-linux-x64.tar.gz -C /u01 \\  \u0026amp;\u0026amp; $(test -d /u01/jdk* \u0026amp;\u0026amp; mv /u01/jdk* /u01/jdk || mv /u01/graal* /u01/jdk) \\  \u0026amp;\u0026amp; rm -rf /tmp/imagetool \\  \u0026amp;\u0026amp; rm -f /u01/jdk/javafx-src.zip /u01/jdk/src.zip # Install Middleware FROM os_update as wls_build LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; ENV JAVA_HOME=/u01/jdk \\  ORACLE_HOME=/u01/oracle \\  OPATCH_NO_FUSER=true RUN mkdir -p /u01/oracle \\  \u0026amp;\u0026amp; mkdir -p /u01/oracle/oraInventory \\  \u0026amp;\u0026amp; chown oracle:root /u01/oracle/oraInventory \\  \u0026amp;\u0026amp; chown oracle:root /u01/oracle COPY --from=jdk_build --chown=oracle:root /u01/jdk /u01/jdk/ COPY --chown=oracle:root fmw_12.2.1.4.0_infrastructure_generic.jar fmw.rsp /tmp/imagetool/ COPY --chown=oracle:root fmw_12.2.1.4.0_wccontent.jar wcc.rsp /tmp/imagetool/ COPY --chown=oracle:root oraInst.loc /u01/oracle/ USER oracle RUN echo \u0026#34;INSTALLING MIDDLEWARE\u0026#34; \\  \u0026amp;\u0026amp; echo \u0026#34;INSTALLING fmw\u0026#34; \\  \u0026amp;\u0026amp; \\  /u01/jdk/bin/java -Xmx1024m -jar /tmp/imagetool/fmw_12.2.1.4.0_infrastructure_generic.jar -silent ORACLE_HOME=/u01/oracle \\  -responseFile /tmp/imagetool/fmw.rsp -invPtrLoc /u01/oracle/oraInst.loc -ignoreSysPrereqs -force -novalidation \\  \u0026amp;\u0026amp; echo \u0026#34;INSTALLING wcc\u0026#34; \\  \u0026amp;\u0026amp; \\  /u01/jdk/bin/java -Xmx1024m -jar /tmp/imagetool/fmw_12.2.1.4.0_wccontent.jar -silent ORACLE_HOME=/u01/oracle \\  -responseFile /tmp/imagetool/wcc.rsp -invPtrLoc /u01/oracle/oraInst.loc -ignoreSysPrereqs -force -novalidation \\  \u0026amp;\u0026amp; chmod -R g+r /u01/oracle FROM os_update as final_build ARG ADMIN_NAME ARG ADMIN_HOST ARG ADMIN_PORT ARG MANAGED_SERVER_PORT ENV ORACLE_HOME=/u01/oracle \\  JAVA_HOME=/u01/jdk \\  PATH=${PATH}:/u01/jdk/bin:/u01/oracle/oracle_common/common/bin:/u01/oracle/wlserver/common/bin:/u01/oracle LABEL com.oracle.weblogic.imagetool.buildid=\u0026#34;f46ab190-077e-4ed7-b747-7bb170fe592c\u0026#34; COPY --from=jdk_build --chown=oracle:root /u01/jdk /u01/jdk/ COPY --from=wls_build --chown=oracle:root /u01/oracle /u01/oracle/ USER oracle WORKDIR /u01/oracle #ENTRYPOINT /bin/bash ENV ORACLE_HOME=/u01/oracle \\  VOLUME_DIR=/u01/oracle/user_projects \\  SCRIPT_FILE=/u01/oracle/container-scripts/* \\  USER_MEM_ARGS=\u0026#34;-Djava.security.egd=file:/dev/./urandom\u0026#34; \\  PATH=$PATH:$JAVA_HOME/bin:$ORACLE_HOME/oracle_common/common/bin:/u01/oracle/wlserver/common/bin:/u01/oracle/container-scripts USER root RUN mkdir -p $VOLUME_DIR \u0026amp;\u0026amp; \\  mkdir -p /u01/oracle/container-scripts \u0026amp;\u0026amp; \\  mkdir -p /u01/oracle/silent-install-files-tmp/config \u0026amp;\u0026amp; \\  mkdir -p /u01/oracle/logs \u0026amp;\u0026amp; \\  chown oracle:root -R /u01 $VOLUME_DIR \u0026amp;\u0026amp; \\  chmod a+xr /u01 COPY --chown=oracle:root files/container-scripts/ /u01/oracle/container-scripts/ RUN chmod +xr $SCRIPT_FILE USER oracle EXPOSE $UCM_PORT $UCM_INTRADOC_PORT $IBR_INTRADOC_PORT $IBR_PORT $ADMIN_PORT WORKDIR ${ORACLE_HOME} CMD [\u0026#34;/u01/oracle/container-scripts/createDomainandStartAdmin.sh\u0026#34;] ########## END DOCKERFILE ##########      Check the created image using the docker images command:\n$ docker images | grep wcc   Update an image After setting up the WebLogic Image Tool and required build scripts, use the WebLogic Image Tool to update an existing Oracle WebCenter Content Docker image:\n  Enter the following command for each patch to add the required patch(es) to the WebLogic Image Tool cache:\n$ cd \u0026lt;imagetool-setup\u0026gt; $ imagetool cache addEntry --key=30761841_12.2.1.4.0 --value \u0026lt;downloaded-patches-location\u0026gt;/p30761841_122140_Generic.zip [INFO ] Added entry 30761841_12.2.1.4.0=\u0026lt;downloaded-patches-location\u0026gt;/p30761841_122140_Generic.zip   Provide the following arguments to the WebLogic Image Tool update command:\n –-fromImage - Identify the image that needs to be updated. In the example below, the image to be updated is wccontent:12.2.1.4.0. –-patches - Multiple patches can be specified as a comma-separated list. --tag - Specify the new tag to be applied for the image being built.  Refer here for the complete list of options available with the WebLogic Image Tool update command.\n Note: The WebLogic Image Tool cache should have the latest OPatch zip. The WebLogic Image Tool will update the OPatch if it is not already updated in the image.\n Examples     Click here to see the example `update` command:    # If you are using a pre-built Oracle WebCenter Content image, obtained from My Oracle Support, then please use this command: $ imagetool update --fromImage oracle/wccontent:12.2.1.4.0 --tag=oracle/wccontent_update_1015:12.2.1.4.0 --patches=31754672_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.4 # In case, you chose to build an Oracle WebCenter Content image, please use the command given below: $ imagetool update --chown oracle:root --fromImage oracle/wccontent:12.2.1.4.0 --tag=oracle/wccontent_update_1015:12.2.1.4.0 --patches=31754672_12.2.1.4.0 --opatchBugNumber=28186730_13.9.4.2.4     Check the built image using the docker images command: $ docker images | grep wcc   Create an Oracle WebCenter Content Docker image using Dockerfile For test and development purposes, you can create an Oracle WebCenter Content image using the Dockerfile. Consult the README file for important prerequisite steps, such as building or pulling the Server JRE Docker image, Oracle FMW Infrastructure Docker image, and downloading the Oracle WebCenter Content installer and bundle patch binaries.\nA prebuilt Oracle Fusion Middleware Infrastructure image, container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4-210407, is available at container-registry.oracle.com. We recommend that you pull and rename this image to build the Oracle WebCenter Content image.\n$ docker pull container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4-210407 $ docker tag container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4-210407 oracle/fmw-infrastructure:12.2.1.4.0 Follow these steps to build an Oracle WebCenter Content image :\n  Make a local clone of the sample repository:\n$ git clone https://github.com/oracle/docker-images   Download the Oracle WebCenter Content installer from the Oracle Technology Network or e-delivery.\n Note: Copy the installer binaries to the same location as the Dockerfile.\n   Create the Oracle WebCenter Content image by running the provided script:\n$ cd docker-images/OracleWebCenterContent/dockerfiles $ ./buildDockerImage.sh -v 12.2.1.4 -s The image produced will be named oracle/wccontent:12.2.1.4. The samples and instructions assume the Oracle WebCenter Content image is named wccontent:12.2.1.4.0. You must rename your image to match this name, or update the samples to refer to the image you created.\n$ docker tag oracle/wccontent:12.2.1.4 wccontent:12.2.1.4.0   "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/adminguide/logging-fluentd-setup/",
	"title": "Publish logs to Elasticsearch Using Fluentd",
	"tags": [],
	"description": "Configure a WebLogic domain to use Fluentd to send log information to Elasticsearch.",
	"content": "Introduction This page describes to how to configure a WebLogic domain to use Fluentd to send log information to Elasticsearch. Here’s the general mechanism for how this works:\n fluentd runs as a separate container in the Administration Server and Managed Server pods The log files reside on a volume that is shared between the weblogic-server and fluentd containers fluentd tails the domain logs files and exports them to Elasticsearch A ConfigMap contains the filter and format rules for exporting log records.  Create fluentd configuration Create a ConfigMap named fluentd-config in the namespace of the domain. The ConfigMap contains the parsing rules and Elasticsearch configuration. Here’s an explanation of some elements defined in the ConfigMap:\n The @type tail indicates that tail will be used to obtain updates to the log file The path of the log file is obtained from the LOG_PATH environment variable that is defined in the fluentd container The tag value of log records is obtained from the DOMAIN_UID environment variable that is defined in the fluentd container The parse section defines how to interpret and tag each element of a log record The match section contains the configuration information for connecting to Elasticsearch and defines the index name of each record to be the domainUID  Here is a sample configmap for fluentd configuration,\n  Click here to see sample configmap for fluentd configuration `fluentd_configmap.yaml`.   apiVersion: v1 kind: ConfigMap metadata: labels: weblogic.domainUID: wccinfra weblogic.resourceVersion: domain-v2 name: fluentd-config namespace: wccns data: fluentd.conf: | \u0026lt;match fluent.**\u0026gt; @type null \u0026lt;/match\u0026gt; \u0026lt;source\u0026gt; @type tail path \u0026quot;#{ENV['LOG_PATH']}\u0026quot; pos_file /tmp/server.log.pos read_from_head true tag \u0026quot;#{ENV['DOMAIN_UID']}\u0026quot; # multiline_flush_interval 20s \u0026lt;parse\u0026gt; @type multiline format_firstline /^####/ format1 /^####\u0026lt;(?\u0026lt;timestamp\u0026gt;(.*?))\u0026gt;/ format2 / \u0026lt;(?\u0026lt;level\u0026gt;(.*?))\u0026gt;/ format3 / \u0026lt;(?\u0026lt;subSystem\u0026gt;(.*?))\u0026gt;/ format4 / \u0026lt;(?\u0026lt;serverName\u0026gt;(.*?))\u0026gt;/ format5 / \u0026lt;(?\u0026lt;serverName2\u0026gt;(.*?))\u0026gt;/ format6 / \u0026lt;(?\u0026lt;threadName\u0026gt;(.*?))\u0026gt;/ format7 / \u0026lt;(?\u0026lt;info1\u0026gt;(.*?))\u0026gt;/ format8 / \u0026lt;(?\u0026lt;info2\u0026gt;(.*?))\u0026gt;/ format9 / \u0026lt;(?\u0026lt;info3\u0026gt;(.*?))\u0026gt;/ format10 / \u0026lt;(?\u0026lt;sequenceNumber\u0026gt;(.*?))\u0026gt;/ format11 / \u0026lt;(?\u0026lt;severity\u0026gt;(.*?))\u0026gt;/ format12 / \u0026lt;(?\u0026lt;messageID\u0026gt;(.*?))\u0026gt;/ format13 / \u0026lt;(?\u0026lt;message\u0026gt;(.*?))\u0026gt;/ \u0026lt;/parse\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;match **\u0026gt; @type elasticsearch host \u0026quot;#{ENV['ELASTICSEARCH_HOST']}\u0026quot; port \u0026quot;#{ENV['ELASTICSEARCH_PORT']}\u0026quot; user \u0026quot;#{ENV['ELASTICSEARCH_USER']}\u0026quot; password \u0026quot;#{ENV['ELASTICSEARCH_PASSWORD']}\u0026quot; index_name \u0026quot;#{ENV['DOMAIN_UID']}\u0026quot; \u0026lt;/match\u0026gt;    Create the ConfigMap using the following command\n$kubectl create -f fluentd_configmap.yaml Mount fluentd configuration - Configmap as volume in the WebLogic container. Edit the domain definition and configure a volume for the ConfigMap containing the fluentd configuration.\n$kubectl edit domain -n wccns Below sample yaml code add Configmap as volume,\n volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: wccinfra-domain-pvc - configMap: defaultMode: 420 name: fluentd-config name: fluentd-config-volume Add fluentd container to WebLogic Server pods Add a \u0026ldquo;fluentd container yaml\u0026rdquo; to the domain under serverPod: section that will run fluentd in the Administration Server and Managed Server pods.\nNotice the container definition:\n Defines a LOG_PATH environment variable that points to the log location of WebLogic servers. Defines ELASTICSEARCH_HOST, ELASTICSEARCH_PORT, ELASTICSEARCH_USER, and ELASTICSEARCH_PASSWORD environment variables. Has volume mounts for the fluentd-config ConfigMap and the volume containing the domain logs.  $kubectl edit domain -n wccns    Click here to see sample fluentd container yaml `fluentd container`.   containers: - args: - -c - /etc/fluent.conf env: - name: DOMAIN_UID valueFrom: fieldRef: fieldPath: metadata.labels['weblogic.domainUID'] - name: SERVER_NAME valueFrom: fieldRef: fieldPath: metadata.labels['weblogic.serverName'] - name: LOG_PATH value: /u01/oracle/user_projects/domains/logs/wccinfra/$(SERVER_NAME).log - name: FLUENTD_CONF value: fluentd.conf - name: FLUENT_ELASTICSEARCH_SED_DISABLE value: \u0026quot;true\u0026quot; - name: ELASTICSEARCH_HOST value: elasticsearch.default.svc.cluster.local - name: ELASTICSEARCH_PORT value: \u0026quot;9200\u0026quot; - name: ELASTICSEARCH_USER value: elastic - name: ELASTICSEARCH_PASSWORD value: changeme image: fluent/fluentd-kubernetes-daemonset:v1.3.3-debian-elasticsearch-1.3 imagePullPolicy: IfNotPresent name: fluentd resources: {} volumeMounts: - mountPath: /fluentd/etc/fluentd.conf name: fluentd-config-volume subPath: fluentd.conf - mountPath: /u01/oracle/user_projects name: weblogic-domain-storage-volume    Restart WebLogic Servers To restart the servers, edit the domain and change serverStartPolicy to NEVER for the WebLogic servers to shutdown\n$kubectl edit domain -n wccns After all the servers are shutdown edit domain again and set serverStartPolicy to IF_NEEDED for the servers to start again.\nCreate index pattern in Kibana Create an index pattern \u0026ldquo;wls*\u0026rdquo; in Kibana \u0026gt; Management. After the server starts, you will be able to see the log data in the Kibana dashboard,\n"
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/cleanup-domain-setup/",
	"title": "Uninstall an Oracle WebCenter Portal domain",
	"tags": [],
	"description": "Clean up the Oracle WebCenter Portal domain setup.",
	"content": "To clean up the Oracle WebCenter Portal domain setup, follow the steps below.\nDelete the Generated Domain Home To remove a domain home that you generated by running the create-domain.sh script in your production or testing environment, use the delete-domain-job.yaml file located at, \u0026lt;$WORKDIR\u0026gt;/weblogic-kubernetes-operator/kubernetes/samples/scripts/create-wcp-domain/domain-home-on-pv/output/weblogic-domains/wcp-domain\u0026gt; directory.\n$ kubectl create -f delete-domain-job.yaml Clean Up the create-domain-job script After Execution Failure To clean up the create-domain-job script:\n  Get the create domain job and configmaps:\n$ kubectl get configmaps,jobs -n wcpns |grep \u0026#34;create-domain-job\u0026#34;   Delete the job and configmap:\n$ kubectl delete job job.batch/wcp-domain-create-fmw-infra-sample-domain-job -n wcpns $ kubectl delete configmap wcp-domain-create-fmw-infra-sample-domain-job-cm -n wcpns   Delete the contents of the PV, if any:\n$ sudo rm -rf /scratch/kubevolume   "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/cleanup-domain-setup/",
	"title": "Uninstall",
	"tags": [],
	"description": "Clean up the Oracle WebCenter Content domain setup.",
	"content": "Learn how to clean up the Oracle WebCenter Content domain setup.\nStop all Administration and Managed server pods First stop the all pods related to a domain. This can be done by patching domain \u0026ldquo;serverStartPolicy\u0026rdquo; to \u0026ldquo;NEVER\u0026rdquo;. Here is the sample command for the same.\n$ kubectl patch domain wcc-domain-name -n wcc-namespace --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/serverStartPolicy\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NEVER\u0026#34; }]\u0026#39; For example:\nkubectl patch domain wccinfra -n wccns --type=\u0026#39;json\u0026#39; -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/serverStartPolicy\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;NEVER\u0026#34; }]\u0026#39; Remove the domain   Remove the domain\u0026rsquo;s ingress (for example, Traefik ingress) using Helm:\n$ helm uninstall wcc-domain-ingress -n sample-domain1-ns For example:\n$ helm uninstall wccinfra-traefik -n wccns   Remove the domain resources by using the sample delete-weblogic-domain-resources.sh script present at ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/delete-domain:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/delete-domain $ ./delete-weblogic-domain-resources.sh -d sample-domain1 For example:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator/kubernetes/samples/scripts/delete-domain $ ./delete-weblogic-domain-resources.sh -d wccinfra   Use kubectl to confirm that the server pods and domain resource are deleted:\n$ kubectl get pods -n sample-domain1-ns $ kubectl get domains -n sample-domain1-ns For example:\n$ kubectl get pods -n wccns $ kubectl get domains -n wccns   Drop the RCU schemas Follow these steps to drop the RCU schemas created for Oracle WebCenter Content domain.\nRemove the domain namespace   Configure the installed ingress load balancer (for example, Traefik) to stop managing the ingresses in the domain namespace:\n$ helm upgrade traefik-operator traefik/traefik \\  --namespace traefik \\  --reuse-values \\  --set \u0026#34;kubernetes.namespaces={traefik}\u0026#34; \\  --wait   Configure the operator to stop managing the domain:\n$ helm upgrade sample-weblogic-operator \\  kubernetes/charts/weblogic-operator \\  --namespace sample-weblogic-operator-ns \\  --reuse-values \\  --set \u0026#34;domainNamespaces={}\u0026#34; \\  --wait For example:\n$ cd ${WORKDIR}/weblogic-kubernetes-operator $ helm upgrade weblogic-kubernetes-operator \\  kubernetes/charts/weblogic-operator \\  --namespace opns \\  --reuse-values \\  --set \u0026#34;domainNamespaces={}\u0026#34; \\  --wait   Delete the domain namespace:\n$ kubectl delete namespace sample-domain1-ns For example:\n$ kubectl delete namespace wccns   Remove the operator   Remove the operator:\n$ helm uninstall sample-weblogic-operator -n sample-weblogic-operator-ns For example:\n$ helm uninstall weblogic-kubernetes-operator -n opns   Remove the operator\u0026rsquo;s namespace:\n$ kubectl delete namespace sample-weblogic-operator-ns For example:\n$ kubectl delete namespace opns   Remove the load balancer   Remove the installed ingress based load balancer (for example, Traefik):\n$ helm uninstall traefik -n traefik   Remove the Traefik namespace:\n$ kubectl delete namespace traefik   Delete the domain home To remove the domain home that is generated using the create-domain.sh script, with appropriate privileges manually delete the contents of the storage attached to the domain home persistent volume (PV).\nFor example, for the domain\u0026rsquo;s persistent volume of type host_path:\n$ rm -rf /scratch/k8s_dir/WCC "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/",
	"title": "Oracle WebCenter Content",
	"tags": [],
	"description": "The Oracle WebLogic Server Kubernetes Operator (the “operator”) supports deployment of Oracle WebCenter Content servers such as Oracle WebCenter Content(Content Server) and Oracle WebCenter Content(Inbound Refinery Server). Follow the instructions in this guide to set up Oracle WebCenter Content domain on Kubernetes.",
	"content": "In this release, Oracle WebCenter Content domain is supported using the “domain on a persistent volume” model only, where the domain home is located in a persistent volume (PV).\nThe operator has several key features to assist you with deploying and managing Oracle WebCenter Content domain in a Kubernetes environment. You can:\n Create Oracle WebCenter Content instances(Oracle WebCenter Content server \u0026amp; Oracle WebCenter Content Inbounnd Refinery server) in a Kubernetes persistent volume (PV). This PV can reside in an NFS file system or other Kubernetes volume types. Start servers based on declarative startup parameters and desired states. Expose the Oracle WebCenter Content services and composites for external access. Scale Oracle WebCenter Content domains by starting and stopping Managed Servers on demand, or by integrating with a REST API. Publish operator and WebLogic Server logs to Elasticsearch and interact with them in Kibana. Monitor the Oracle WebCenter Content instance using Prometheus and Grafana.  Current production release The current supported production release of the Oracle WebLogic Server Kubernetes Operator, for Oracle WebCenter Content domain deployment is 3.1.1.\nRecent changes See the Release Notes for recent changes for Oracle WebCenter Content domain deployment on Kubernetes.\nLimitations See here for limitations in this release.\nAbout this documentation This documentation includes sections targeted to different audiences. To help you find what you are looking for easily, please consult this table of contents:\n  Quick Start explains how to quickly get an Oracle WebCenter Content instance running, using the defaults. Note that this is only for development and test purposes.\n  Install Guide and Administration Guide provide detailed information about all aspects of using the Kubernetes operator including:\n Installing and configuring the operator. Using the operator to create and manage Oracle WebCenter Content domain. Configuring Kubernetes load balancers. Configuring Custom SSL certificates. Configuring Elasticsearch and Kibana to access the operator and WebLogic Server log files. Deploying composite applications for Oracle WebCenter Content. Patching an Oracle WebCenter Content Docker image. Removing/deleting domain. And much more!    Additional reading Oracle WebCenter Content domain deployment on Kubernetes leverages the Oracle WebLogic Server Kubernetes operator framework.\n To develop an understanding of the operator, including design, architecture, domain life cycle management, and configuration overrides, review the operator documentation. To learn more about the Oracle WebCenter Content architecture and components, see Understanding Oracle WebCenter Content.  "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/appendix/",
	"title": "Appendix",
	"tags": [],
	"description": "",
	"content": "This section provides information on miscellaneous tasks related to the Oracle WebCenter Portal deployment on Kubernetes.\n Domain resource sizing  Describes the resourse sizing information for the Oracle WebCenter Portal domain setup on Kubernetes cluster.\n Quick start deployment on-premise  Describes how to quickly get an Oracle WebCenter Portal domain instance running (using the defaults, nothing special) for development and test purposes.\n Security hardening  Review resources for the Docker and Kubernetes cluster hardening.\n Additional Configuration  Describes how to create connections to Oracle WebCenter Content Server to enable content integration within Oracle WebCenter Portal.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wccontent-domains/appendix/",
	"title": "Appendix",
	"tags": [],
	"description": "",
	"content": "This section provides information on miscellaneous tasks related to Oracle WebCenter Content domain deployment on Kubernetes.\n Domain resource sizing  Describes the resourse sizing information for Oracle WebCenter Content domain setup on Kubernetes cluster.\n Quick start deployment guide  Describes how to quickly get an Oracle WebCenter Content domain instance running (using the defaults, nothing special) for development and test purposes.\n Security hardening  Review resources for the Docker and Kubernetes cluster hardening.\n "
},
{
	"uri": "/fmw-kubernetes/21.2.3/wcportal-domains/",
	"title": "Oracle WebCenter Portal",
	"tags": [],
	"description": "The WebLogic Kubernetes operator (the “operator”) supports deployment of Oracle WebCenter Portal. Follow the instructions in this guide to set up Oracle WebCenter Portal domain on Kubernetes.",
	"content": "With the WebLogic Kubernetes operator (operator), you can deploy your Oracle WebCenter Portal on Kubernetes.\nIn this release, Oracle WebCenter Portal domain is based on the “domain on a persistent volume” model, where the domain home is located in a persistent volume.\nThe operator has several key features to assist you with deploying and managing the Oracle WebCenter Portal domain in a Kubernetes environment. You can:\n Create Oracle WebCenter Portal instances in a Kubernetes PV. This PV can reside in an Network File System (NFS) or other Kubernetes volume types. Start servers based on declarative startup parameters and desired states. Expose the Oracle WebCenter Portal services for external access. Scale Oracle WebCenter Portal domain by starting and stopping Managed Servers on demand, or by integrating with a REST API. Publish operator and WebLogic Server logs to Elasticsearch and interact with them in Kibana. Monitor the Oracle WebCenter Portal instance using Prometheus and Grafana.  Current release The current production release for the Oracle WebCenter Portal domain deployment on Kubernetes is 21.2.3. This release uses the WebLogic Kubernetes Operator version 3.1.1.\nRecent changes and known issues See the Release Notes for recent changes and known issues with the Oracle WebCenter Portal domain deployment on Kubernetes.\nAbout this documentation This documentation includes sections targeted to different audiences. To help you find what you are looking for more easily, please use this table of contents:\n  Quick Start explains how to quickly get an Oracle WebCenter Portal domain instance running, using the defaults, nothing special. Note that this is only for development and test purposes.\n  Install Guide and Administration Guide provide detailed information about all aspects of using the Kubernetes operator including:\n Installing and configuring the operator Using the operator to create and manage Oracle WebCenter Portal domain Configuring WebCenter Portal for Search Configuring Kubernetes load balancers Configuring Prometheus and Grafana to monitor WebCenter Portal Configuring Logging using ElasticSearch    "
},
{
	"uri": "/fmw-kubernetes/21.2.3/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/fmw-kubernetes/21.2.3/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]